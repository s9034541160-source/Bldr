"""
ENTERPRISE RAG 3.0: VLM Processor –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ç–∞–±–ª–∏—Ü –∏ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
"""

import os
import logging
from typing import Dict, List, Optional, Tuple
from PIL import Image
import torch
from transformers import BlipProcessor, BlipForConditionalGeneration
from transformers import LayoutLMv3Processor, LayoutLMv3ForTokenClassification
import cv2
import numpy as np
from pdf2image import convert_from_path
import pytesseract

logger = logging.getLogger(__name__)

class VLMProcessor:
    """ENTERPRISE RAG 3.0: Vision-Language Model –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤"""
    
    def __init__(self, device: str = "auto"):
        # ‚¨ÖÔ∏è –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –ü–†–ê–í–ö–ê: VLM –Ω–∞ CUDA –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏!
        self.device = self._get_device(device)  # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ CUDA –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–æ
        self.blip_processor = None
        self.blip_model = None
        self.layout_processor = None
        self.layout_model = None
        
        # CUDA –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏!
        logger.info(f"[VLM] VLM device: {self.device}")
        self._load_models()
    
    def _get_device(self, device: str) -> str:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –¥–ª—è VLM"""
        if device == "auto":
            if torch.cuda.is_available():
                return "cuda"
            elif torch.backends.mps.is_available():
                return "mps"
            else:
                return "cpu"
        return device
    
    def _optimize_gpu_memory(self):
        """–û–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ—Ç GPU –ø–∞–º—è—Ç—å –¥–ª—è RTX 4060"""
        
        if torch.cuda.is_available():
            # –û—á–∏—â–∞–µ–º –∫—ç—à
            torch.cuda.empty_cache()
            
            # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –ø–∞–º—è—Ç—å (90% –æ—Ç 8GB = 7.2GB)
            torch.cuda.set_per_process_memory_fraction(0.9)
            
            # –í–∫–ª—é—á–∞–µ–º –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
            torch.backends.cudnn.benchmark = True
            torch.backends.cudnn.deterministic = False
            
            logger.info("GPU memory optimized for RTX 4060")
    
    def _load_models(self):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç VLM –º–æ–¥–µ–ª–∏"""
        try:
            logger.info(f"Loading VLM models on {self.device} (VLM –Ω–∞ CUDA –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏!)")
            
            # BLIP –¥–ª—è –æ–ø–∏—Å–∞–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
            self.blip_processor = BlipProcessor.from_pretrained("Salesforce/blip-image-captioning-base")
            self.blip_model = BlipForConditionalGeneration.from_pretrained(
                "Salesforce/blip-image-captioning-base",
                torch_dtype=torch.float16  # ‚¨ÖÔ∏è CUDA –∏—Å–ø–æ–ª—å–∑—É–µ—Ç float16
            )
            self.blip_model.to(self.device)  # ‚¨ÖÔ∏è –ù–∞ CUDA –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏!
            
            # LayoutLMv3 –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
            self.layout_processor = LayoutLMv3Processor.from_pretrained("microsoft/layoutlmv3-base")
            
            # VLM –Ω–∞ CUDA –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏!
            self.layout_model = LayoutLMv3ForTokenClassification.from_pretrained(
                "microsoft/layoutlmv3-base",
                trust_remote_code=True,
                torch_dtype=torch.float16  # ‚¨ÖÔ∏è –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û float16 –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å BLIP!
            ).to(self.device)
            
            # üí• –ü–†–ò–ù–£–î–ò–¢–ï–õ–¨–ù–ê–Ø –ü–†–û–í–ï–†–ö–ê –¢–ò–ü–û–í: –û–±–µ –º–æ–¥–µ–ª–∏ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å float16!
            if hasattr(self.blip_model, 'dtype'):
                logger.info(f"[VLM_DEBUG] BLIP dtype: {self.blip_model.dtype}")
            if hasattr(self.layout_model, 'dtype'):
                logger.info(f"[VLM_DEBUG] LayoutLMv3 dtype: {self.layout_model.dtype}")
            
            # –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º float16 –¥–ª—è –æ–±–µ–∏—Ö –º–æ–¥–µ–ª–µ–π
            self.blip_model = self.blip_model.half()
            self.layout_model = self.layout_model.half()
            logger.info(f"[VLM_DEBUG] –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω float16 –¥–ª—è –æ–±–µ–∏—Ö –º–æ–¥–µ–ª–µ–π")
            
            logger.info(f"VLM models loaded successfully on {self.device}")
            
        except Exception as e:
            logger.error(f"Failed to load VLM models: {e}")
            self.blip_processor = None
            self.blip_model = None
            self.layout_processor = None
            self.layout_model = None
    
    def is_available(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å VLM"""
        return (self.blip_processor is not None and 
                self.blip_model is not None and
                self.layout_processor is not None and
                self.layout_model is not None)
    
    def extract_tables_from_pdf(self, pdf_path: str) -> List[Dict]:
        """ENTERPRISE: –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–∞–±–ª–∏—Ü –∏–∑ PDF —Å –ø–æ–º–æ—â—å—é VLM"""
        
        if not self.is_available():
            logger.warning("VLM not available, using fallback")
            return self._fallback_table_extraction(pdf_path)
        
        try:
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º PDF –≤ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            images = convert_from_path(pdf_path, dpi=300)
            tables = []
            
            # –ó–∞—â–∏—Ç–∞ –æ—Ç –ø—É—Å—Ç–æ–≥–æ PDF
            if not images or len(images) == 0:
                logger.warning(f"‚ö†Ô∏è PDF {pdf_path} has no pages or failed to convert")
                return []
            
            for page_num, image in enumerate(images):
                # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–∞–∂–¥—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É —Å –∑–∞—â–∏—Ç–æ–π
                try:
                    page_tables = self._analyze_page_for_tables(image, page_num)
                    tables.extend(page_tables)
                except Exception as e:
                    logger.error(f"üõë Critical error on page {page_num}, skipping: {e}")
                    continue  # –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É –¥—Ä—É–≥–∏—Ö —Å—Ç—Ä–∞–Ω–∏—Ü
            
            return tables
            
        except Exception as e:
            logger.error(f"VLM table extraction failed: {e}")
            return self._fallback_table_extraction(pdf_path)
    
    def _analyze_page_for_tables(self, image: Image.Image, page_num: int) -> List[Dict]:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Å—Ç—Ä–∞–Ω–∏—Ü—É –Ω–∞ –Ω–∞–ª–∏—á–∏–µ —Ç–∞–±–ª–∏—Ü —Å –∑–∞—â–∏—Ç–æ–π –æ—Ç CUDA –æ—à–∏–±–æ–∫"""
        
        try:
            # 1. –ó–∞—â–∏—Ç–∞ –æ—Ç –ø—É—Å—Ç–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            if image.size[0] == 0 or image.size[1] == 0:
                logger.warning(f"‚ö†Ô∏è Page {page_num} skipped: Empty image dimensions")
                return []
            
            # –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ô –§–ò–ö–°: –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–µ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è CUDA –æ—à–∏–±–æ–∫
            inputs = self.layout_processor(
                image, 
                return_tensors="pt",
                max_length=512,  # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –¥–æ 512 —Ç–æ–∫–µ–Ω–æ–≤
                truncation=True,  # –û–±—Ä–µ–∑–∫–∞ –¥–ª–∏–Ω–Ω—ã—Ö –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π
                padding=True
            )
            inputs = {k: v.to(self.device) for k, v in inputs.items()}
            
            # 2. –ó–∞—â–∏—Ç–∞ –æ—Ç –Ω—É–ª–µ–≤—ã—Ö —Ç–µ–Ω–∑–æ—Ä–æ–≤
            for key, tensor in inputs.items():
                if tensor.numel() == 0:
                    logger.warning(f"‚ö†Ô∏è Page {page_num} skipped: Empty tensor {key}")
                    return []
            
            # 3. –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –ó–ê–©–ò–¢–ê: –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–ª–∏–Ω—ã —Ç–æ–∫–µ–Ω–æ–≤
            input_ids = inputs.get('input_ids', None)
            if input_ids is not None:
                token_count = input_ids.shape[1]
                if token_count > 512:
                    logger.warning(f"‚ö†Ô∏è Page {page_num} has {token_count} tokens (>{512}), truncating to prevent CUDA error")
                    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –æ–±—Ä–µ–∑–∫–∞ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
                    if token_count > 512:
                        inputs['input_ids'] = input_ids[:, :512]
                        if 'attention_mask' in inputs:
                            inputs['attention_mask'] = inputs['attention_mask'][:, :512]
            
            # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Å –∑–∞—â–∏—Ç–æ–π –æ—Ç CUDA –æ—à–∏–±–æ–∫
            with torch.no_grad():
                outputs = self.layout_model(**inputs)
                predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–∞–±–ª–∏—Ü—ã
            tables = self._extract_tables_from_predictions(image, predictions, page_num)
            
            return tables
            
        except RuntimeError as e:
            # 3. –ù–∏–∑–∫–æ—É—Ä–æ–≤–Ω–µ–≤–∞—è –∑–∞—â–∏—Ç–∞: PyTorch –æ–±–æ—Ä–∞—á–∏–≤–∞–µ—Ç CUDA-–æ—à–∏–±–∫–∏ –≤ RuntimeError
            if "device-side assert triggered" in str(e) or "srcSelectDimSize" in str(e):
                logger.error(f"üõë CUDA assertion failed on page {page_num}. Skipping page: {e}")
                return []
            raise e  # –ï—Å–ª–∏ —ç—Ç–æ –Ω–µ CUDA-–æ—à–∏–±–∫–∞, –ø–µ—Ä–µ–±—Ä–∞—Å—ã–≤–∞–µ–º –µ–µ
        except Exception as e:
            logger.error(f"Page analysis failed: {e}")
            return []
    
    def _extract_tables_from_predictions(self, image: Image.Image, predictions: torch.Tensor, page_num: int) -> List[Dict]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–∞–±–ª–∏—Ü—ã –∏–∑ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –º–æ–¥–µ–ª–∏"""
        
        tables = []
        
        # –ü—Ä–æ—Å—Ç–∞—è –ª–æ–≥–∏–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ç–∞–±–ª–∏—Ü
        # –í —Ä–µ–∞–ª—å–Ω–æ–π —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ –∑–¥–µ—Å—å –±—ã–ª–∞ –±—ã –±–æ–ª–µ–µ —Å–ª–æ–∂–Ω–∞—è –ª–æ–≥–∏–∫–∞
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º OpenCV –¥–ª—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
        cv_image = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)
        
        # –ò—â–µ–º –ø—Ä—è–º–æ—É–≥–æ–ª—å–Ω–∏–∫–∏ (–ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–µ —Ç–∞–±–ª–∏—Ü—ã)
        gray = cv2.cvtColor(cv_image, cv2.COLOR_BGR2GRAY)
        edges = cv2.Canny(gray, 50, 150)
        contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        for i, contour in enumerate(contours):
            # –§–∏–ª—å—Ç—Ä—É–µ–º –ø–æ —Ä–∞–∑–º–µ—Ä—É
            area = cv2.contourArea(contour)
            if area > 1000:  # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –ø–ª–æ—â–∞–¥—å
                x, y, w, h = cv2.boundingRect(contour)
                
                # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç –∏–∑ –æ–±–ª–∞—Å—Ç–∏
                roi = image.crop((x, y, x + w, y + h))
                text = pytesseract.image_to_string(roi, lang='rus')
                
                if self._is_table_content(text):
                    tables.append({
                        'page': page_num,
                        'position': (x, y, w, h),
                        'content': text.strip(),
                        'confidence': 0.8,
                        'detection_method': 'VLM_LAYOUT',
                        'metadata': {
                            'data_type': 'TABLE',
                            'structured': True,
                            'vlm_processed': True
                        }
                    })
        
        return tables
    
    def _is_table_content(self, text: str) -> bool:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Ç–µ–∫—Å—Ç —Ç–∞–±–ª–∏—Ü–µ–π"""
        
        # –ü—Ä–æ—Å—Ç—ã–µ —ç–≤—Ä–∏—Å—Ç–∏–∫–∏
        lines = text.strip().split('\n')
        if len(lines) < 3:
            return False
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –Ω–∞–ª–∏—á–∏–µ —Å—Ç–æ–ª–±—Ü–æ–≤
        has_columns = any('|' in line or '\t' in line for line in lines)
        has_numbers = any(char.isdigit() for char in text)
        
        return has_columns or has_numbers
    
    def _fallback_table_extraction(self, pdf_path: str) -> List[Dict]:
        """Fallback –º–µ—Ç–æ–¥ –±–µ–∑ VLM"""
        
        logger.info("Using fallback table extraction")
        return []
    
    def analyze_document_structure(self, pdf_path: str) -> Dict:
        """ENTERPRISE: –ü–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–æ–∫—É–º–µ–Ω—Ç–∞ —Å VLM —Å –∑–∞—â–∏—Ç–æ–π –æ—Ç CUDA –æ—à–∏–±–æ–∫"""
        
        if not self.is_available():
            return {'vlm_available': False, 'tables': [], 'structure': 'fallback'}
        
        try:
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–∞–±–ª–∏—Ü—ã —Å –∑–∞—â–∏—Ç–æ–π –æ—Ç CUDA –æ—à–∏–±–æ–∫
            tables = self.extract_tables_from_pdf(pdf_path)
            
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –æ–±—â—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É
            structure_analysis = {
                'vlm_available': True,
                'tables': tables,
                'total_tables': len(tables),
                'structure_complexity': self._calculate_structure_complexity(tables),
                'analysis_method': 'VLM_LAYOUT'
            }
            
            return structure_analysis
            
        except RuntimeError as e:
            # –°–ø–µ—Ü–∏–∞–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ CUDA –æ—à–∏–±–æ–∫
            if "device-side assert triggered" in str(e) or "srcSelectDimSize" in str(e):
                logger.error(f"üõë CUDA assertion failed in document analysis. Skipping VLM: {e}")
                return {'vlm_available': False, 'tables': [], 'structure': 'cuda_error'}
            raise e  # –ï—Å–ª–∏ —ç—Ç–æ –Ω–µ CUDA-–æ—à–∏–±–∫–∞, –ø–µ—Ä–µ–±—Ä–∞—Å—ã–≤–∞–µ–º –µ–µ
        except Exception as e:
            logger.error(f"VLM structure analysis failed: {e}")
            return {'vlm_available': False, 'tables': [], 'structure': 'error'}
    
    def _calculate_structure_complexity(self, tables: List[Dict]) -> float:
        """–†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç —Å–ª–æ–∂–Ω–æ—Å—Ç—å —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ VLM –∞–Ω–∞–ª–∏–∑–∞"""
        
        if not tables:
            return 0.0
        
        # –ü—Ä–æ—Å—Ç–∞—è –º–µ—Ç—Ä–∏–∫–∞ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏
        total_area = sum(t.get('position', (0, 0, 0, 0))[2] * t.get('position', (0, 0, 0, 0))[3] for t in tables)
        avg_confidence = sum(t.get('confidence', 0) for t in tables) / len(tables)
        
        complexity = min(1.0, (len(tables) * 0.3 + avg_confidence * 0.7))
        return round(complexity, 3)
