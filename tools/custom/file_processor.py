#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
File Processor Tool
–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–∞–π–ª–æ–≤
"""

import os
import json
from pathlib import Path
from typing import Dict, Any, List
from core.tools.base_tool import ToolManifest, ToolParam, ToolParamType

def execute(params: Dict[str, Any]) -> Dict[str, Any]:
    """
    –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–æ–≤ —Å —Ä–∞–∑–ª–∏—á–Ω—ã–º–∏ –æ–ø–µ—Ä–∞—Ü–∏—è–º–∏
    """
    try:
        operation = params.get('operation', 'analyze')
        files = params.get('files', [])
        output_format = params.get('output_format', 'json')
        
        if not files:
            return {
                'status': 'error',
                'error': 'No files provided'
            }
        
        results = []
        
        for file_info in files:
            if isinstance(file_info, dict):
                file_path = file_info.get('name', '')
            else:
                file_path = str(file_info)
            
            file_result = process_single_file(file_path, operation)
            results.append(file_result)
        
        # –°–æ–∑–¥–∞–µ–º –≤—ã—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏
        output_file = create_output_file(results, output_format)
        
        return {
            'status': 'success',
            'data': {
                'processed_files': len(results),
                'operation': operation,
                'results': results
            },
            'files': [output_file],
            'result_type': 'file',
            'result_title': f'–û–±—Ä–∞–±–æ—Ç–∫–∞ {len(results)} —Ñ–∞–π–ª–æ–≤',
            'result_content': f'–£—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ {len(results)} —Ñ–∞–π–ª–æ–≤ –æ–ø–µ—Ä–∞—Ü–∏–µ–π "{operation}"'
        }
        
    except Exception as e:
        return {
            'status': 'error',
            'error': str(e)
        }

def process_single_file(file_path: str, operation: str) -> Dict[str, Any]:
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞"""
    
    try:
        file_path = Path(file_path)
        
        if not file_path.exists():
            return {
                'file': str(file_path),
                'status': 'error',
                'error': 'File not found'
            }
        
        file_size = file_path.stat().st_size
        file_extension = file_path.suffix.lower()
        
        result = {
            'file': str(file_path),
            'size': file_size,
            'extension': file_extension,
            'operation': operation,
            'status': 'success'
        }
        
        if operation == 'analyze':
            result.update(analyze_file(file_path))
        elif operation == 'convert':
            result.update(convert_file(file_path))
        elif operation == 'compress':
            result.update(compress_file(file_path))
        elif operation == 'extract_text':
            result.update(extract_text_from_file(file_path))
        
        return result
        
    except Exception as e:
        return {
            'file': str(file_path),
            'status': 'error',
            'error': str(e)
        }

def analyze_file(file_path: Path) -> Dict[str, Any]:
    """–ê–Ω–∞–ª–∏–∑ —Ñ–∞–π–ª–∞"""
    return {
        'analysis': {
            'is_text': file_path.suffix.lower() in ['.txt', '.md', '.py', '.js', '.html', '.css'],
            'is_image': file_path.suffix.lower() in ['.jpg', '.jpeg', '.png', '.gif', '.bmp'],
            'is_document': file_path.suffix.lower() in ['.pdf', '.doc', '.docx', '.xls', '.xlsx'],
            'is_archive': file_path.suffix.lower() in ['.zip', '.rar', '.7z', '.tar', '.gz']
        }
    }

def convert_file(file_path: Path) -> Dict[str, Any]:
    """–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è —Ñ–∞–π–ª–∞"""
    return {
        'conversion': {
            'target_format': 'converted',
            'status': 'ready_for_conversion'
        }
    }

def compress_file(file_path: Path) -> Dict[str, Any]:
    """–°–∂–∞—Ç–∏–µ —Ñ–∞–π–ª–∞"""
    return {
        'compression': {
            'original_size': file_path.stat().st_size,
            'compression_ratio': 0.7,
            'estimated_compressed_size': int(file_path.stat().st_size * 0.7)
        }
    }

def extract_text_from_file(file_path: Path) -> Dict[str, Any]:
    """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∏–∑ —Ñ–∞–π–ª–∞"""
    try:
        if file_path.suffix.lower() == '.txt':
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            return {
                'text_extraction': {
                    'text_length': len(content),
                    'preview': content[:200] + '...' if len(content) > 200 else content
                }
            }
        else:
            return {
                'text_extraction': {
                    'status': 'unsupported_format',
                    'message': f'Text extraction not supported for {file_path.suffix}'
                }
            }
    except Exception as e:
        return {
            'text_extraction': {
                'status': 'error',
                'error': str(e)
            }
        }

def create_output_file(results: List[Dict[str, Any]], output_format: str) -> str:
    """–°–æ–∑–¥–∞–Ω–∏–µ –≤—ã—Ö–æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏"""
    
    output_dir = Path('exports')
    output_dir.mkdir(exist_ok=True)
    
    if output_format == 'json':
        output_file = output_dir / 'file_processing_results.json'
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
    else:
        output_file = output_dir / 'file_processing_results.txt'
        with open(output_file, 'w', encoding='utf-8') as f:
            for result in results:
                f.write(f"File: {result.get('file', 'Unknown')}\n")
                f.write(f"Status: {result.get('status', 'Unknown')}\n")
                f.write(f"Size: {result.get('size', 0)} bytes\n")
                f.write("-" * 50 + "\n")
    
    return str(output_file)

# –ú–∞–Ω–∏—Ñ–µ—Å—Ç –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞
manifest = ToolManifest(
    name="file_processor",
    version="1.0.0",
    title="üìÅ –û–±—Ä–∞–±–æ—Ç—á–∏–∫ —Ñ–∞–π–ª–æ–≤",
    description="–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–∞–π–ª–æ–≤: –∞–Ω–∞–ª–∏–∑, –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è, —Å–∂–∞—Ç–∏–µ, –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞. –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã –∏ —Ä–∞–∑–ª–∏—á–Ω—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã.",
    category="data_management",
    ui_placement="dashboard",
    enabled=True,
    system=False,
    entrypoint="tools.custom.file_processor:execute",
    params=[
        ToolParam(
            name="files",
            type=ToolParamType.FILE,
            required=True,
            description="–§–∞–π–ª—ã –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏",
            ui={
                "multiple": True,
                "directory": False
            }
        ),
        ToolParam(
            name="operation",
            type=ToolParamType.ENUM,
            required=True,
            default="analyze",
            description="–¢–∏–ø –æ–ø–µ—Ä–∞—Ü–∏–∏",
            enum=[
                {"value": "analyze", "label": "–ê–Ω–∞–ª–∏–∑ —Ñ–∞–π–ª–æ–≤"},
                {"value": "convert", "label": "–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è"},
                {"value": "compress", "label": "–°–∂–∞—Ç–∏–µ"},
                {"value": "extract_text", "label": "–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞"}
            ]
        ),
        ToolParam(
            name="output_format",
            type=ToolParamType.ENUM,
            required=False,
            default="json",
            description="–§–æ—Ä–º–∞—Ç –≤—ã—Ö–æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞",
            enum=[
                {"value": "json", "label": "JSON"},
                {"value": "txt", "label": "–¢–µ–∫—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª"}
            ]
        )
    ],
    outputs=[]
)
