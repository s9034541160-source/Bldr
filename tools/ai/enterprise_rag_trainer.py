# namespace:ai
from typing import Any, Dict, List
import time
import os
import sys
from pathlib import Path
from core.tools.base_tool import ToolManifest, ToolInterface, ToolParam, ToolParamType

# –°–æ–∑–¥–∞–µ–º Pydantic –º–æ–¥–µ–ª–∏ –¥–ª—è —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–æ–≥–æ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è
coordinator_interface = ToolInterface(
    purpose="–ü—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ RAG —Å–∏—Å—Ç–µ–º—ã —Å –ø–æ–ª–Ω—ã–º –ø–∞–π–ø–ª–∞–π–Ω–æ–º –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤, –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Å—Ç—Ä—É–∫—Ç—É—Ä—ã, –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ –≤–µ–∫—Ç–æ—Ä–Ω—É—é –∏ –≥—Ä–∞—Ñ–æ–≤—É—é –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö",
    input_requirements={
        "base_dir": ToolParam(
            name="base_dir",
            type=ToolParamType.STRING,
            required=False,
            description="–ë–∞–∑–æ–≤–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å –¥–æ–∫—É–º–µ–Ω—Ç–∞–º–∏ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏"
        ),
        "max_files": ToolParam(
            name="max_files",
            type=ToolParamType.NUMBER,
            required=False,
            description="–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–∞–π–ª–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏"
        ),
        "force_cuda": ToolParam(
            name="force_cuda",
            type=ToolParamType.BOOLEAN,
            required=False,
            default=True,
            description="–ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ CUDA –¥–ª—è SBERT"
        ),
        "reset_databases": ToolParam(
            name="reset_databases",
            type=ToolParamType.BOOLEAN,
            required=False,
            default=False,
            description="–°–±—Ä–æ—Å–∏—Ç—å –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö –ø–µ—Ä–µ–¥ –æ–±—É—á–µ–Ω–∏–µ–º"
        ),
        "include_file_organization": ToolParam(
            name="include_file_organization",
            type=ToolParamType.BOOLEAN,
            required=False,
            default=True,
            description="–í–∫–ª—é—á–∏—Ç—å –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—é —Ñ–∞–π–ª–æ–≤ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º"
        ),
        "chunking_strategy": ToolParam(
            name="chunking_strategy",
            type=ToolParamType.ENUM,
            required=False,
            default="smart",
            description="–°—Ç—Ä–∞—Ç–µ–≥–∏—è —Ä–∞–∑–±–∏–µ–Ω–∏—è –Ω–∞ —á–∞–Ω–∫–∏",
            enum=[
                {"value": "smart", "label": "–£–º–Ω–æ–µ —Ä–∞–∑–±–∏–µ–Ω–∏–µ (1 –ø—É–Ω–∫—Ç = 1 —á–∞–Ω–∫)"},
                {"value": "fixed", "label": "–§–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ä–∞–∑–º–µ—Ä"},
                {"value": "semantic", "label": "–°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–µ —Ä–∞–∑–±–∏–µ–Ω–∏–µ"}
            ]
        ),
        "processing_mode": ToolParam(
            name="processing_mode",
            type=ToolParamType.ENUM,
            required=False,
            default="comprehensive",
            description="–†–µ–∂–∏–º –æ–±—Ä–∞–±–æ—Ç–∫–∏",
            enum=[
                {"value": "fast", "label": "–ë—ã—Å—Ç—Ä–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞"},
                {"value": "comprehensive", "label": "–ö–æ–º–ø–ª–µ–∫—Å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞"},
                {"value": "expert", "label": "–≠–∫—Å–ø–µ—Ä—Ç–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞"}
            ]
        )
    },
    execution_flow=[
        "1. –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è RAG —Ç—Ä–µ–Ω–µ—Ä–∞ —Å CUDA –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π",
        "2. –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ Qdrant –∏ Neo4j –±–∞–∑–∞–º –¥–∞–Ω–Ω—ã—Ö",
        "3. –°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ —Å –¥–æ–∫—É–º–µ–Ω—Ç–∞–º–∏",
        "4. –í–∞–ª–∏–¥–∞—Ü–∏—è –∏ –ø—Ä–æ–≤–µ—Ä–∫–∞ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ —Ñ–∞–π–ª–æ–≤",
        "5. –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ (PDF, DOCX, Excel)",
        "6. –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∏–ø–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∏ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã",
        "7. –ê–Ω–∞–ª–∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã —Å –ø–æ–º–æ—â—å—é SBERT",
        "8. –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π —Ä–∞–±–æ—Ç",
        "9. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π –≤ Neo4j",
        "10. –£–º–Ω–æ–µ —Ä–∞–∑–±–∏–µ–Ω–∏–µ –Ω–∞ —á–∞–Ω–∫–∏",
        "11. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ Qdrant",
        "12. –û—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è —Ñ–∞–π–ª–æ–≤ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º",
        "13. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞ –æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞—Ö"
    ],
    output_format={
        "structure": {
            "status": "success/error",
            "data": {
                "training_summary": "object - —Å–≤–æ–¥–∫–∞ –ø–æ –æ–±—É—á–µ–Ω–∏—é",
                "files_processed": "number - –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤",
                "chunks_created": "number - –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ–∑–¥–∞–Ω–Ω—ã—Ö —á–∞–Ω–∫–æ–≤",
                "works_extracted": "number - –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏–∑–≤–ª–µ—á–µ–Ω–Ω—ã—Ö —Ä–∞–±–æ—Ç",
                "dependencies_saved": "number - –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π",
                "file_path": "string - –ø—É—Ç—å –∫ –æ—Ç—á–µ—Ç—É"
            },
            "execution_time": "float in seconds"
        },
        "result_fields": {
            "training_summary": "object - –¥–µ—Ç–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ–±—É—á–µ–Ω–∏—è",
            "files_processed": "number - –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —É—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤",
            "chunks_created": "number - –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ–∑–¥–∞–Ω–Ω—ã—Ö –≤–µ–∫—Ç–æ—Ä–Ω—ã—Ö —á–∞–Ω–∫–æ–≤",
            "works_extracted": "number - –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏–∑–≤–ª–µ—á–µ–Ω–Ω—ã—Ö —Ä–∞–±–æ—Ç",
            "dependencies_saved": "number - –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π",
            "file_path": "string - –ø—É—Ç—å –∫ –¥–µ—Ç–∞–ª—å–Ω–æ–º—É –æ—Ç—á–µ—Ç—É"
        }
    },
    usage_guidelines={
        "for_coordinator": [
            "–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è RAG —Å–∏—Å—Ç–µ–º—ã –Ω–∞ –Ω–æ–≤—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ö",
            "–£–∫–∞–∑—ã–≤–∞–π—Ç–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é —Å –¥–æ–∫—É–º–µ–Ω—Ç–∞–º–∏ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏",
            "–ù–∞—Å—Ç—Ä–∞–∏–≤–∞–π—Ç–µ —Ä–µ–∂–∏–º –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π",
            "–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ CUDA –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è –æ–±—Ä–∞–±–æ—Ç–∫–∏"
        ],
        "for_models": [
            "–ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –¥–µ—Ç–∞–ª—å–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –æ–±—É—á–µ–Ω–∏—è",
            "–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ training_summary –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤",
            "–ü—Ä–æ–≤–µ—Ä—è–π—Ç–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ –∏ —á–∞–Ω–∫–æ–≤",
            "–†–µ–∑—É–ª—å—Ç–∞—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç –≤—Å–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞"
        ]
    },
    integration_notes={
        "dependencies": ["Qdrant", "Neo4j", "SBERT", "CUDA", "File system"],
        "performance": "–î–ª–∏—Ç–µ–ª—å–Ω–∞—è –æ–ø–µ—Ä–∞—Ü–∏—è: 10-60 –º–∏–Ω—É—Ç –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –æ–±—ä–µ–º–∞",
        "reliability": "–û—á–µ–Ω—å –≤—ã—Å–æ–∫–∞—è - –ø—Ä–æ–≤–µ—Ä–µ–Ω–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω –æ–±—Ä–∞–±–æ—Ç–∫–∏",
        "scalability": "–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∫—É —Ç—ã—Å—è—á –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤"
    }
)

manifest = ToolManifest(
    name="enterprise_rag_trainer",
    version="1.0.0",
    title="üß† Enterprise RAG Trainer",
    description="–ü—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ RAG —Å–∏—Å—Ç–µ–º—ã —Å –ø–æ–ª–Ω—ã–º –ø–∞–π–ø–ª–∞–π–Ω–æ–º –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤, –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Å—Ç—Ä—É–∫—Ç—É—Ä—ã, –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ –≤–µ–∫—Ç–æ—Ä–Ω—É—é –∏ –≥—Ä–∞—Ñ–æ–≤—É—é –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö.",
    category="ai",
    ui_placement="dashboard",
    enabled=True,
    system=True,  # –°–∏—Å—Ç–µ–º–Ω—ã–π –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç
    entrypoint="tools.ai.enterprise_rag_trainer:execute",
    params=[
        ToolParam(
            name="base_dir",
            type=ToolParamType.STRING,
            required=False,
            description="–ë–∞–∑–æ–≤–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å –¥–æ–∫—É–º–µ–Ω—Ç–∞–º–∏",
            ui={
                "placeholder": "–£–∫–∞–∂–∏—Ç–µ –ø—É—Ç—å –∫ –ø–∞–ø–∫–µ —Å –¥–æ–∫—É–º–µ–Ω—Ç–∞–º–∏ –∏–ª–∏ –æ—Å—Ç–∞–≤—å—Ç–µ –ø—É—Å—Ç—ã–º –¥–ª—è I:/docs/downloaded"
            }
        ),
        ToolParam(
            name="max_files",
            type=ToolParamType.NUMBER,
            required=False,
            description="–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–∞–π–ª–æ–≤",
            ui={
                "min": 1,
                "max": 10000,
                "step": 1
            }
        ),
        ToolParam(
            name="force_cuda",
            type=ToolParamType.BOOLEAN,
            required=False,
            default=True,
            description="–ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ CUDA",
            ui={
                "switch": True
            }
        ),
        ToolParam(
            name="reset_databases",
            type=ToolParamType.BOOLEAN,
            required=False,
            default=False,
            description="–°–±—Ä–æ—Å–∏—Ç—å –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö",
            ui={
                "switch": True
            }
        ),
        ToolParam(
            name="include_file_organization",
            type=ToolParamType.BOOLEAN,
            required=False,
            default=True,
            description="–í–∫–ª—é—á–∏—Ç—å –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—é —Ñ–∞–π–ª–æ–≤",
            ui={
                "switch": True
            }
        ),
        ToolParam(
            name="chunking_strategy",
            type=ToolParamType.ENUM,
            required=False,
            default="smart",
            description="–°—Ç—Ä–∞—Ç–µ–≥–∏—è —Ä–∞–∑–±–∏–µ–Ω–∏—è –Ω–∞ —á–∞–Ω–∫–∏",
            enum=[
                {"value": "smart", "label": "–£–º–Ω–æ–µ —Ä–∞–∑–±–∏–µ–Ω–∏–µ (1 –ø—É–Ω–∫—Ç = 1 —á–∞–Ω–∫)"},
                {"value": "fixed", "label": "–§–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ä–∞–∑–º–µ—Ä"},
                {"value": "semantic", "label": "–°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–µ —Ä–∞–∑–±–∏–µ–Ω–∏–µ"}
            ]
        ),
        ToolParam(
            name="processing_mode",
            type=ToolParamType.ENUM,
            required=False,
            default="comprehensive",
            description="–†–µ–∂–∏–º –æ–±—Ä–∞–±–æ—Ç–∫–∏",
            enum=[
                {"value": "fast", "label": "–ë—ã—Å—Ç—Ä–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞"},
                {"value": "comprehensive", "label": "–ö–æ–º–ø–ª–µ–∫—Å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞"},
                {"value": "expert", "label": "–≠–∫—Å–ø–µ—Ä—Ç–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞"}
            ]
        )
    ],
    outputs=["training_summary", "files_processed", "chunks_created", "works_extracted", "dependencies_saved"],
    permissions=["read:filesystem", "write:qdrant", "write:neo4j", "read:files"],
    tags=["rag", "training", "ai", "enterprise", "system"],
    result_display={
        "type": "training_report",
        "title": "–û—Ç—á–µ—Ç –æ –æ–±—É—á–µ–Ω–∏–∏ RAG —Å–∏—Å—Ç–µ–º—ã",
        "description": "–î–µ—Ç–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø—Ä–æ—Ü–µ—Å—Å–∞ –æ–±—É—á–µ–Ω–∏—è",
        "features": {
            "exportable": True,
            "printable": True,
            "interactive": True,
            "charts": True
        }
    },
    documentation={
        "examples": [
            {
                "title": "–ë—ã—Å—Ç—Ä–æ–µ –æ–±—É—á–µ–Ω–∏–µ",
                "base_dir": "I:/docs/downloaded",
                "max_files": 100,
                "processing_mode": "fast",
                "force_cuda": True
            },
            {
                "title": "–ü–æ–ª–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ",
                "base_dir": "I:/docs/downloaded",
                "processing_mode": "comprehensive",
                "include_file_organization": True
            }
        ],
        "tips": [
            "–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ CUDA –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è –æ–±—Ä–∞–±–æ—Ç–∫–∏",
            "–ù–∞—á–∏–Ω–∞–π—Ç–µ —Å –Ω–µ–±–æ–ª—å—à–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Ñ–∞–π–ª–æ–≤ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è",
            "–ü—Ä–æ–≤–µ—Ä—è–π—Ç–µ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å –±–∞–∑ –¥–∞–Ω–Ω—ã—Ö –ø–µ—Ä–µ–¥ –∑–∞–ø—É—Å–∫–æ–º"
        ]
    },
    coordinator_interface=coordinator_interface
)

def execute(**kwargs) -> Dict[str, Any]:
    """Execute enterprise-level RAG training with full pipeline."""
    start_time = time.time()
    
    try:
        # Parse parameters with defaults
        base_dir = kwargs.get('base_dir', 'I:/docs/downloaded')
        max_files = kwargs.get('max_files', None)
        force_cuda = kwargs.get('force_cuda', True)
        reset_databases = kwargs.get('reset_databases', False)
        include_file_organization = kwargs.get('include_file_organization', True)
        chunking_strategy = kwargs.get('chunking_strategy', 'smart')
        processing_mode = kwargs.get('processing_mode', 'comprehensive')
        
        # Set environment variables
        if force_cuda:
            os.environ['FORCE_CUDA'] = '1'
        
        # Reset databases if requested
        if reset_databases:
            _reset_rag_databases()
        
        # Import and initialize trainer
        try:
            from enterprise_rag_trainer_full import EnterpriseRAGTrainer
            trainer = EnterpriseRAGTrainer(base_dir=base_dir)
        except ImportError as e:
            return {
                'status': 'error',
                'error': f'–ù–µ —É–¥–∞–ª–æ—Å—å –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å RAG —Ç—Ä–µ–Ω–µ—Ä: {str(e)}',
                'execution_time': time.time() - start_time
            }
        
        # Configure trainer based on parameters
        if max_files:
            trainer.max_files = max_files
        
        # Set chunking strategy
        if chunking_strategy == 'smart':
            trainer.chunking_strategy = 'hierarchical'
        elif chunking_strategy == 'fixed':
            trainer.chunking_strategy = 'fixed_size'
        else:
            trainer.chunking_strategy = 'semantic'
        
        # Set processing mode
        if processing_mode == 'fast':
            trainer.quality_threshold = 0.7
            trainer.enable_ocr = False
        elif processing_mode == 'expert':
            trainer.quality_threshold = 0.9
            trainer.enable_ocr = True
        else:  # comprehensive
            trainer.quality_threshold = 0.8
            trainer.enable_ocr = True
        
        # Start training
        logger.info(f"üöÄ Starting RAG training with mode: {processing_mode}")
        training_start_time = time.time()
        
        try:
            trainer.train(max_files=max_files)
            training_successful = True
        except Exception as training_error:
            logger.error(f"Training failed: {training_error}")
            training_successful = False
        
        training_time = time.time() - training_start_time
        
        # Generate training summary
        training_summary = _generate_training_summary(trainer, training_successful, training_time)
        
        # Generate report file
        report_path = _generate_training_report(trainer, training_summary, base_dir)
        
        # Generate metadata
        metadata = {
            'base_dir': base_dir,
            'max_files': max_files,
            'force_cuda': force_cuda,
            'reset_databases': reset_databases,
            'chunking_strategy': chunking_strategy,
            'processing_mode': processing_mode,
            'training_successful': training_successful,
            'trained_at': time.strftime('%Y-%m-%d %H:%M:%S'),
            'report_path': report_path
        }
        
        execution_time = time.time() - start_time
        
        return {
            'status': 'success' if training_successful else 'error',
            'data': {
                'training_summary': training_summary,
                'files_processed': training_summary.get('files_processed', 0),
                'chunks_created': training_summary.get('chunks_created', 0),
                'works_extracted': training_summary.get('works_extracted', 0),
                'dependencies_saved': training_summary.get('dependencies_saved', 0),
                'file_path': report_path,
                'metadata': metadata
            },
            'execution_time': execution_time,
            'result_type': 'training_report',
            'result_title': f'üß† –û–±—É—á–µ–Ω–∏–µ RAG —Å–∏—Å—Ç–µ–º—ã: {training_summary.get("files_processed", 0)} —Ñ–∞–π–ª–æ–≤',
            'result_table': _create_training_table(training_summary),
            'metadata': metadata
        }
        
    except Exception as e:
        return { 
            'status': 'error', 
            'error': str(e),
            'execution_time': time.time() - start_time
        }


def _reset_rag_databases():
    """Reset RAG databases before training."""
    try:
        from quick_reset_rag import main as reset_main
        reset_main()
        logger.info("‚úÖ RAG databases reset successfully")
    except Exception as e:
        logger.warning(f"‚ö†Ô∏è Failed to reset databases: {e}")


def _generate_training_summary(trainer, training_successful: bool, training_time: float) -> Dict[str, Any]:
    """Generate comprehensive training summary."""
    try:
        stats = getattr(trainer, 'stats', {})
        
        return {
            'training_successful': training_successful,
            'files_processed': stats.get('files_processed', 0),
            'files_failed': stats.get('files_failed', 0),
            'total_chunks': stats.get('total_chunks', 0),
            'total_works': stats.get('total_works', 0),
            'training_time': training_time,
            'files_per_minute': stats.get('files_processed', 0) / (training_time / 60) if training_time > 0 else 0,
            'chunks_per_file': stats.get('total_chunks', 0) / stats.get('files_processed', 1) if stats.get('files_processed', 0) > 0 else 0,
            'works_per_file': stats.get('total_works', 0) / stats.get('files_processed', 1) if stats.get('files_processed', 0) > 0 else 0,
            'success_rate': (stats.get('files_processed', 0) / (stats.get('files_processed', 0) + stats.get('files_failed', 0))) * 100 if (stats.get('files_processed', 0) + stats.get('files_failed', 0)) > 0 else 0,
            'cuda_enabled': os.environ.get('FORCE_CUDA') == '1',
            'databases_status': _check_databases_status()
        }
    except Exception as e:
        logger.error(f"Error generating training summary: {e}")
        return {
            'training_successful': training_successful,
            'files_processed': 0,
            'files_failed': 0,
            'total_chunks': 0,
            'total_works': 0,
            'training_time': training_time,
            'error': str(e)
        }


def _check_databases_status() -> Dict[str, Any]:
    """Check status of RAG databases."""
    status = {'qdrant': False, 'neo4j': False}
    
    try:
        # Check Qdrant
        from qdrant_client import QdrantClient
        client = QdrantClient(host='localhost', port=6333)
        collections = client.get_collections()
        status['qdrant'] = True
    except Exception as e:
        logger.warning(f"Qdrant not available: {e}")
    
    try:
        # Check Neo4j
        import neo4j
        driver = neo4j.GraphDatabase.driver('neo4j://127.0.0.1:7687', auth=('neo4j', 'neopassword'))
        with driver.session() as session:
            session.run("RETURN 1")
        driver.close()
        status['neo4j'] = True
    except Exception as e:
        logger.warning(f"Neo4j not available: {e}")
    
    return status


def _generate_training_report(trainer, training_summary: Dict[str, Any], base_dir: str) -> str:
    """Generate detailed training report."""
    try:
        timestamp = time.strftime('%Y%m%d_%H%M%S')
        report_dir = Path(base_dir) / "reports"
        report_dir.mkdir(exist_ok=True)
        
        report_path = report_dir / f"rag_training_report_{timestamp}.json"
        
        report_data = {
            'training_summary': training_summary,
            'trainer_stats': getattr(trainer, 'stats', {}),
            'configuration': {
                'base_dir': base_dir,
                'cuda_enabled': os.environ.get('FORCE_CUDA') == '1',
                'chunking_strategy': getattr(trainer, 'chunking_strategy', 'smart'),
                'quality_threshold': getattr(trainer, 'quality_threshold', 0.8)
            },
            'generated_at': time.strftime('%Y-%m-%d %H:%M:%S')
        }
        
        import json
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(report_data, f, indent=2, ensure_ascii=False)
        
        logger.info(f"üìä Training report saved: {report_path}")
        return str(report_path)
        
    except Exception as e:
        logger.error(f"Error generating training report: {e}")
        return ""


def _create_training_table(training_summary: Dict[str, Any]) -> List[Dict[str, Any]]:
    """Create training results table."""
    table_data = [
        {
            'metric': '–§–∞–π–ª–æ–≤ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ',
            'value': training_summary.get('files_processed', 0),
            'status': 'success'
        },
        {
            'metric': '–§–∞–π–ª–æ–≤ —Å –æ—à–∏–±–∫–∞–º–∏',
            'value': training_summary.get('files_failed', 0),
            'status': 'warning' if training_summary.get('files_failed', 0) > 0 else 'success'
        },
        {
            'metric': '–ß–∞–Ω–∫–æ–≤ —Å–æ–∑–¥–∞–Ω–æ',
            'value': training_summary.get('total_chunks', 0),
            'status': 'info'
        },
        {
            'metric': '–†–∞–±–æ—Ç –∏–∑–≤–ª–µ—á–µ–Ω–æ',
            'value': training_summary.get('total_works', 0),
            'status': 'info'
        },
        {
            'metric': '–í—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è',
            'value': f"{training_summary.get('training_time', 0):.1f} —Å–µ–∫",
            'status': 'info'
        },
        {
            'metric': '–°–∫–æ—Ä–æ—Å—Ç—å –æ–±—Ä–∞–±–æ—Ç–∫–∏',
            'value': f"{training_summary.get('files_per_minute', 0):.1f} —Ñ–∞–π–ª–æ–≤/–º–∏–Ω",
            'status': 'info'
        },
        {
            'metric': '–ü—Ä–æ—Ü–µ–Ω—Ç —É—Å–ø–µ—Ö–∞',
            'value': f"{training_summary.get('success_rate', 0):.1f}%",
            'status': 'success' if training_summary.get('success_rate', 0) > 80 else 'warning'
        }
    ]
    
    return table_data
