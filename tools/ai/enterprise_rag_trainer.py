# namespace:ai
from typing import Any, Dict, List
import time
import os
import sys
from pathlib import Path
from core.tools.base_tool import ToolManifest, ToolInterface, ToolParam, ToolParamType

# Ğ¡Ğ¾Ğ·Ğ´Ğ°ĞµĞ¼ Pydantic Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ´Ğ»Ñ ÑƒĞ½Ğ¸Ğ²ĞµÑ€ÑĞ°Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ñ
coordinator_interface = ToolInterface(
    purpose="ĞŸÑ€Ğ¾Ñ„ĞµÑÑĞ¸Ğ¾Ğ½Ğ°Ğ»ÑŒĞ½Ğ¾Ğµ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ RAG ÑĞ¸ÑÑ‚ĞµĞ¼Ñ‹ Ñ Ğ¿Ğ¾Ğ»Ğ½Ñ‹Ğ¼ Ğ¿Ğ°Ğ¹Ğ¿Ğ»Ğ°Ğ¹Ğ½Ğ¾Ğ¼ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸ Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ¾Ğ², Ğ¸Ğ·Ğ²Ğ»ĞµÑ‡ĞµĞ½Ğ¸Ñ ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ñ‹, Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ ÑĞ¼Ğ±ĞµĞ´Ğ´Ğ¸Ğ½Ğ³Ğ¾Ğ² Ğ¸ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ñ Ğ² Ğ²ĞµĞºÑ‚Ğ¾Ñ€Ğ½ÑƒÑ Ğ¸ Ğ³Ñ€Ğ°Ñ„Ğ¾Ğ²ÑƒÑ Ğ±Ğ°Ğ·Ñ‹ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…",
    input_requirements={
        "base_dir": ToolParam(
            name="base_dir",
            type=ToolParamType.STRING,
            required=False,
            description="Ğ‘Ğ°Ğ·Ğ¾Ğ²Ğ°Ñ Ğ´Ğ¸Ñ€ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ñ Ñ Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ°Ğ¼Ğ¸ Ğ´Ğ»Ñ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸"
        ),
        "max_files": ToolParam(
            name="max_files",
            type=ToolParamType.NUMBER,
            required=False,
            description="ĞœĞ°ĞºÑĞ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ğ¾Ğµ ĞºĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾ Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ² Ğ´Ğ»Ñ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸"
        ),
        "force_cuda": ToolParam(
            name="force_cuda",
            type=ToolParamType.BOOLEAN,
            required=False,
            default=True,
            description="ĞŸÑ€Ğ¸Ğ½ÑƒĞ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾Ğµ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ CUDA Ğ´Ğ»Ñ SBERT"
        ),
        "reset_databases": ToolParam(
            name="reset_databases",
            type=ToolParamType.BOOLEAN,
            required=False,
            default=False,
            description="Ğ¡Ğ±Ñ€Ğ¾ÑĞ¸Ñ‚ÑŒ Ğ±Ğ°Ğ·Ñ‹ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¿ĞµÑ€ĞµĞ´ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸ĞµĞ¼"
        ),
        "include_file_organization": ToolParam(
            name="include_file_organization",
            type=ToolParamType.BOOLEAN,
            required=False,
            default=True,
            description="Ğ’ĞºĞ»ÑÑ‡Ğ¸Ñ‚ÑŒ Ğ¾Ñ€Ğ³Ğ°Ğ½Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ² Ğ¿Ğ¾ ĞºĞ°Ñ‚ĞµĞ³Ğ¾Ñ€Ğ¸ÑĞ¼"
        ),
        "chunking_strategy": ToolParam(
            name="chunking_strategy",
            type=ToolParamType.ENUM,
            required=False,
            default="smart",
            description="Ğ¡Ñ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ñ Ñ€Ğ°Ğ·Ğ±Ğ¸ĞµĞ½Ğ¸Ñ Ğ½Ğ° Ñ‡Ğ°Ğ½ĞºĞ¸",
            enum=[
                {"value": "smart", "label": "Ğ£Ğ¼Ğ½Ğ¾Ğµ Ñ€Ğ°Ğ·Ğ±Ğ¸ĞµĞ½Ğ¸Ğµ (1 Ğ¿ÑƒĞ½ĞºÑ‚ = 1 Ñ‡Ğ°Ğ½Ğº)"},
                {"value": "fixed", "label": "Ğ¤Ğ¸ĞºÑĞ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¹ Ñ€Ğ°Ğ·Ğ¼ĞµÑ€"},
                {"value": "semantic", "label": "Ğ¡ĞµĞ¼Ğ°Ğ½Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğµ Ñ€Ğ°Ğ·Ğ±Ğ¸ĞµĞ½Ğ¸Ğµ"}
            ]
        ),
        "processing_mode": ToolParam(
            name="processing_mode",
            type=ToolParamType.ENUM,
            required=False,
            default="comprehensive",
            description="Ğ ĞµĞ¶Ğ¸Ğ¼ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸",
            enum=[
                {"value": "fast", "label": "Ğ‘Ñ‹ÑÑ‚Ñ€Ğ°Ñ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ°"},
                {"value": "comprehensive", "label": "ĞšĞ¾Ğ¼Ğ¿Ğ»ĞµĞºÑĞ½Ğ°Ñ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ°"},
                {"value": "expert", "label": "Ğ­ĞºÑĞ¿ĞµÑ€Ñ‚Ğ½Ğ°Ñ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ°"}
            ]
        )
    },
    execution_flow=[
        "1. Ğ˜Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ RAG Ñ‚Ñ€ĞµĞ½ĞµÑ€Ğ° Ñ CUDA Ğ¿Ğ¾Ğ´Ğ´ĞµÑ€Ğ¶ĞºĞ¾Ğ¹",
        "2. ĞŸĞ¾Ğ´ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ğµ Ğº Qdrant Ğ¸ Neo4j Ğ±Ğ°Ğ·Ğ°Ğ¼ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…",
        "3. Ğ¡ĞºĞ°Ğ½Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ´Ğ¸Ñ€ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ğ¸ Ñ Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ°Ğ¼Ğ¸",
        "4. Ğ’Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸Ñ Ğ¸ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ğ´ÑƒĞ±Ğ»Ğ¸ĞºĞ°Ñ‚Ğ¾Ğ² Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ²",
        "5. Ğ˜Ğ·Ğ²Ğ»ĞµÑ‡ĞµĞ½Ğ¸Ğµ Ñ‚ĞµĞºÑÑ‚Ğ° Ğ¸Ğ· Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ¾Ğ² (PDF, DOCX, Excel)",
        "6. ĞĞ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ğµ Ñ‚Ğ¸Ğ¿Ğ° Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ¾Ğ² Ğ¸ ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ñ‹",
        "7. ĞĞ½Ğ°Ğ»Ğ¸Ğ· ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ñ‹ Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ SBERT",
        "8. Ğ˜Ğ·Ğ²Ğ»ĞµÑ‡ĞµĞ½Ğ¸Ğµ Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ĞµĞ¹ Ñ€Ğ°Ğ±Ğ¾Ñ‚",
        "9. Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ğµ Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚ĞµĞ¹ Ğ² Neo4j",
        "10. Ğ£Ğ¼Ğ½Ğ¾Ğµ Ñ€Ğ°Ğ·Ğ±Ğ¸ĞµĞ½Ğ¸Ğµ Ğ½Ğ° Ñ‡Ğ°Ğ½ĞºĞ¸",
        "11. Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ ÑĞ¼Ğ±ĞµĞ´Ğ´Ğ¸Ğ½Ğ³Ğ¾Ğ² Ğ¸ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ğµ Ğ² Qdrant",
        "12. ĞÑ€Ğ³Ğ°Ğ½Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ² Ğ¿Ğ¾ ĞºĞ°Ñ‚ĞµĞ³Ğ¾Ñ€Ğ¸ÑĞ¼",
        "13. Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ğ¾Ñ‚Ñ‡ĞµÑ‚Ğ° Ğ¾ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ°Ñ…"
    ],
    output_format={
        "structure": {
            "status": "success/error",
            "data": {
                "training_summary": "object - ÑĞ²Ğ¾Ğ´ĞºĞ° Ğ¿Ğ¾ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ",
                "files_processed": "number - ĞºĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ğ½Ğ½Ñ‹Ñ… Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ²",
                "chunks_created": "number - ĞºĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾ ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ñ‡Ğ°Ğ½ĞºĞ¾Ğ²",
                "works_extracted": "number - ĞºĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾ Ğ¸Ğ·Ğ²Ğ»ĞµÑ‡ĞµĞ½Ğ½Ñ‹Ñ… Ñ€Ğ°Ğ±Ğ¾Ñ‚",
                "dependencies_saved": "number - ĞºĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ½Ñ‹Ñ… Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚ĞµĞ¹",
                "file_path": "string - Ğ¿ÑƒÑ‚ÑŒ Ğº Ğ¾Ñ‚Ñ‡ĞµÑ‚Ñƒ"
            },
            "execution_time": "float in seconds"
        },
        "result_fields": {
            "training_summary": "object - Ğ´ĞµÑ‚Ğ°Ğ»ÑŒĞ½Ğ°Ñ ÑÑ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ° Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ",
            "files_processed": "number - ĞºĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾ ÑƒÑĞ¿ĞµÑˆĞ½Ğ¾ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ğ½Ğ½Ñ‹Ñ… Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ²",
            "chunks_created": "number - ĞºĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾ ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ²ĞµĞºÑ‚Ğ¾Ñ€Ğ½Ñ‹Ñ… Ñ‡Ğ°Ğ½ĞºĞ¾Ğ²",
            "works_extracted": "number - ĞºĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾ Ğ¸Ğ·Ğ²Ğ»ĞµÑ‡ĞµĞ½Ğ½Ñ‹Ñ… Ñ€Ğ°Ğ±Ğ¾Ñ‚",
            "dependencies_saved": "number - ĞºĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ½Ñ‹Ñ… Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚ĞµĞ¹",
            "file_path": "string - Ğ¿ÑƒÑ‚ÑŒ Ğº Ğ´ĞµÑ‚Ğ°Ğ»ÑŒĞ½Ğ¾Ğ¼Ñƒ Ğ¾Ñ‚Ñ‡ĞµÑ‚Ñƒ"
        }
    },
    usage_guidelines={
        "for_coordinator": [
            "Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞ¹Ñ‚Ğµ Ğ´Ğ»Ñ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ RAG ÑĞ¸ÑÑ‚ĞµĞ¼Ñ‹ Ğ½Ğ° Ğ½Ğ¾Ğ²Ñ‹Ñ… Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ°Ñ…",
            "Ğ£ĞºĞ°Ğ·Ñ‹Ğ²Ğ°Ğ¹Ñ‚Ğµ Ğ´Ğ¸Ñ€ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ñ Ñ Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ°Ğ¼Ğ¸ Ğ´Ğ»Ñ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸",
            "ĞĞ°ÑÑ‚Ñ€Ğ°Ğ¸Ğ²Ğ°Ğ¹Ñ‚Ğµ Ñ€ĞµĞ¶Ğ¸Ğ¼ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸ Ğ² Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚Ğ¸ Ğ¾Ñ‚ Ñ‚Ñ€ĞµĞ±Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğ¹",
            "Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞ¹Ñ‚Ğµ CUDA Ğ´Ğ»Ñ ÑƒÑĞºĞ¾Ñ€ĞµĞ½Ğ¸Ñ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸"
        ],
        "for_models": [
            "Ğ˜Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚ Ğ²Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚ Ğ´ĞµÑ‚Ğ°Ğ»ÑŒĞ½ÑƒÑ ÑÑ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºÑƒ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ",
            "Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞ¹Ñ‚Ğµ training_summary Ğ´Ğ»Ñ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ° Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ²",
            "ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞ¹Ñ‚Ğµ ĞºĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ğ½Ğ½Ñ‹Ñ… Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ² Ğ¸ Ñ‡Ğ°Ğ½ĞºĞ¾Ğ²",
            "Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚ ÑĞ¾Ğ´ĞµÑ€Ğ¶Ğ¸Ñ‚ Ğ²ÑĞµ Ğ½ĞµĞ¾Ğ±Ñ…Ğ¾Ğ´Ğ¸Ğ¼Ñ‹Ğµ Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞ¸ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ°"
        ]
    },
    integration_notes={
        "dependencies": ["Qdrant", "Neo4j", "SBERT", "CUDA", "File system"],
        "performance": "Ğ”Ğ»Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ°Ñ Ğ¾Ğ¿ĞµÑ€Ğ°Ñ†Ğ¸Ñ: 10-60 Ğ¼Ğ¸Ğ½ÑƒÑ‚ Ğ² Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚Ğ¸ Ğ¾Ñ‚ Ğ¾Ğ±ÑŠĞµĞ¼Ğ°",
        "reliability": "ĞÑ‡ĞµĞ½ÑŒ Ğ²Ñ‹ÑĞ¾ĞºĞ°Ñ - Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞµĞ½Ğ½Ñ‹Ğ¹ Ğ¿Ğ°Ğ¹Ğ¿Ğ»Ğ°Ğ¹Ğ½ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸",
        "scalability": "ĞŸĞ¾Ğ´Ğ´ĞµÑ€Ğ¶Ğ¸Ğ²Ğ°ĞµÑ‚ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºÑƒ Ñ‚Ñ‹ÑÑÑ‡ Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ¾Ğ²"
    }
)

manifest = ToolManifest(
    name="enterprise_rag_trainer",
    version="1.0.0",
    title="ğŸ§  Enterprise RAG Trainer",
    description="ĞŸÑ€Ğ¾Ñ„ĞµÑÑĞ¸Ğ¾Ğ½Ğ°Ğ»ÑŒĞ½Ğ¾Ğµ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ RAG ÑĞ¸ÑÑ‚ĞµĞ¼Ñ‹ Ñ Ğ¿Ğ¾Ğ»Ğ½Ñ‹Ğ¼ Ğ¿Ğ°Ğ¹Ğ¿Ğ»Ğ°Ğ¹Ğ½Ğ¾Ğ¼ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸ Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ¾Ğ², Ğ¸Ğ·Ğ²Ğ»ĞµÑ‡ĞµĞ½Ğ¸Ñ ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ñ‹, Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ ÑĞ¼Ğ±ĞµĞ´Ğ´Ğ¸Ğ½Ğ³Ğ¾Ğ² Ğ¸ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ñ Ğ² Ğ²ĞµĞºÑ‚Ğ¾Ñ€Ğ½ÑƒÑ Ğ¸ Ğ³Ñ€Ğ°Ñ„Ğ¾Ğ²ÑƒÑ Ğ±Ğ°Ğ·Ñ‹ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ….",
    category="ai",
    ui_placement="dashboard",
    enabled=True,
    system=True,  # Ğ¡Ğ¸ÑÑ‚ĞµĞ¼Ğ½Ñ‹Ğ¹ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚
    entrypoint="tools.ai.enterprise_rag_trainer:execute",
    params=[
        ToolParam(
            name="base_dir",
            type=ToolParamType.STRING,
            required=False,
            description="Ğ‘Ğ°Ğ·Ğ¾Ğ²Ğ°Ñ Ğ´Ğ¸Ñ€ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ñ Ñ Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ°Ğ¼Ğ¸",
            ui={
                "placeholder": "Ğ£ĞºĞ°Ğ¶Ğ¸Ñ‚Ğµ Ğ¿ÑƒÑ‚ÑŒ Ğº Ğ¿Ğ°Ğ¿ĞºĞµ Ñ Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ°Ğ¼Ğ¸ Ğ¸Ğ»Ğ¸ Ğ¾ÑÑ‚Ğ°Ğ²ÑŒÑ‚Ğµ Ğ¿ÑƒÑÑ‚Ñ‹Ğ¼ Ğ´Ğ»Ñ I:/docs/downloaded"
            }
        ),
        ToolParam(
            name="max_files",
            type=ToolParamType.NUMBER,
            required=False,
            description="ĞœĞ°ĞºÑĞ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ğ¾Ğµ ĞºĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾ Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ²",
            ui={
                "min": 1,
                "max": 10000,
                "step": 1
            }
        ),
        ToolParam(
            name="force_cuda",
            type=ToolParamType.BOOLEAN,
            required=False,
            default=True,
            description="ĞŸÑ€Ğ¸Ğ½ÑƒĞ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾Ğµ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ CUDA",
            ui={
                "switch": True
            }
        ),
        ToolParam(
            name="reset_databases",
            type=ToolParamType.BOOLEAN,
            required=False,
            default=False,
            description="Ğ¡Ğ±Ñ€Ğ¾ÑĞ¸Ñ‚ÑŒ Ğ±Ğ°Ğ·Ñ‹ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…",
            ui={
                "switch": True
            }
        ),
        ToolParam(
            name="include_file_organization",
            type=ToolParamType.BOOLEAN,
            required=False,
            default=True,
            description="Ğ’ĞºĞ»ÑÑ‡Ğ¸Ñ‚ÑŒ Ğ¾Ñ€Ğ³Ğ°Ğ½Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ²",
            ui={
                "switch": True
            }
        ),
        ToolParam(
            name="chunking_strategy",
            type=ToolParamType.ENUM,
            required=False,
            default="smart",
            description="Ğ¡Ñ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ñ Ñ€Ğ°Ğ·Ğ±Ğ¸ĞµĞ½Ğ¸Ñ Ğ½Ğ° Ñ‡Ğ°Ğ½ĞºĞ¸",
            enum=[
                {"value": "smart", "label": "Ğ£Ğ¼Ğ½Ğ¾Ğµ Ñ€Ğ°Ğ·Ğ±Ğ¸ĞµĞ½Ğ¸Ğµ (1 Ğ¿ÑƒĞ½ĞºÑ‚ = 1 Ñ‡Ğ°Ğ½Ğº)"},
                {"value": "fixed", "label": "Ğ¤Ğ¸ĞºÑĞ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¹ Ñ€Ğ°Ğ·Ğ¼ĞµÑ€"},
                {"value": "semantic", "label": "Ğ¡ĞµĞ¼Ğ°Ğ½Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğµ Ñ€Ğ°Ğ·Ğ±Ğ¸ĞµĞ½Ğ¸Ğµ"}
            ]
        ),
        ToolParam(
            name="processing_mode",
            type=ToolParamType.ENUM,
            required=False,
            default="comprehensive",
            description="Ğ ĞµĞ¶Ğ¸Ğ¼ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸",
            enum=[
                {"value": "fast", "label": "Ğ‘Ñ‹ÑÑ‚Ñ€Ğ°Ñ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ°"},
                {"value": "comprehensive", "label": "ĞšĞ¾Ğ¼Ğ¿Ğ»ĞµĞºÑĞ½Ğ°Ñ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ°"},
                {"value": "expert", "label": "Ğ­ĞºÑĞ¿ĞµÑ€Ñ‚Ğ½Ğ°Ñ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ°"}
            ]
        )
    ],
    outputs=["training_summary", "files_processed", "chunks_created", "works_extracted", "dependencies_saved"],
    permissions=["read:filesystem", "write:qdrant", "write:neo4j", "read:files"],
    tags=["rag", "training", "ai", "enterprise", "system"],
    result_display={
        "type": "training_report",
        "title": "ĞÑ‚Ñ‡ĞµÑ‚ Ğ¾ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğ¸ RAG ÑĞ¸ÑÑ‚ĞµĞ¼Ñ‹",
        "description": "Ğ”ĞµÑ‚Ğ°Ğ»ÑŒĞ½Ğ°Ñ ÑÑ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ° Ğ¿Ñ€Ğ¾Ñ†ĞµÑÑĞ° Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ",
        "features": {
            "exportable": True,
            "printable": True,
            "interactive": True,
            "charts": True
        }
    },
    documentation={
        "examples": [
            {
                "title": "Ğ‘Ñ‹ÑÑ‚Ñ€Ğ¾Ğµ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ",
                "base_dir": "I:/docs/downloaded",
                "max_files": 100,
                "processing_mode": "fast",
                "force_cuda": True
            },
            {
                "title": "ĞŸĞ¾Ğ»Ğ½Ğ¾Ğµ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ",
                "base_dir": "I:/docs/downloaded",
                "processing_mode": "comprehensive",
                "include_file_organization": True
            }
        ],
        "tips": [
            "Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞ¹Ñ‚Ğµ CUDA Ğ´Ğ»Ñ ÑƒÑĞºĞ¾Ñ€ĞµĞ½Ğ¸Ñ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸",
            "ĞĞ°Ñ‡Ğ¸Ğ½Ğ°Ğ¹Ñ‚Ğµ Ñ Ğ½ĞµĞ±Ğ¾Ğ»ÑŒÑˆĞ¾Ğ³Ğ¾ ĞºĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ° Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ² Ğ´Ğ»Ñ Ñ‚ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ",
            "ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞ¹Ñ‚Ğµ Ğ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ğ¾ÑÑ‚ÑŒ Ğ±Ğ°Ğ· Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¿ĞµÑ€ĞµĞ´ Ğ·Ğ°Ğ¿ÑƒÑĞºĞ¾Ğ¼"
        ]
    },
    coordinator_interface=coordinator_interface
)

def execute(**kwargs) -> Dict[str, Any]:
    """Execute enterprise-level RAG training with full pipeline."""
    start_time = time.time()
    
    try:
        # Parse parameters with defaults
        base_dir = kwargs.get('base_dir', 'I:/docs/downloaded')
        max_files = kwargs.get('max_files', None)
        force_cuda = kwargs.get('force_cuda', True)
        reset_databases = kwargs.get('reset_databases', False)
        include_file_organization = kwargs.get('include_file_organization', True)
        chunking_strategy = kwargs.get('chunking_strategy', 'smart')
        processing_mode = kwargs.get('processing_mode', 'comprehensive')
        
        # Set environment variables
        if force_cuda:
            os.environ['FORCE_CUDA'] = '1'
        
        # Reset databases if requested
        if reset_databases:
            _reset_rag_databases()
        
        # Import and initialize trainer
        try:
            from enterprise_rag_trainer_full import EnterpriseRAGTrainer
            trainer = EnterpriseRAGTrainer(base_dir=base_dir)
        except ImportError as e:
            return {
                'status': 'error',
                'error': f'ĞĞµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ Ğ¸Ğ¼Ğ¿Ğ¾Ñ€Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ RAG Ñ‚Ñ€ĞµĞ½ĞµÑ€: {str(e)}',
                'execution_time': time.time() - start_time
            }
        
        # Configure trainer based on parameters
        if max_files:
            trainer.max_files = max_files
        
        # Set chunking strategy
        if chunking_strategy == 'smart':
            trainer.chunking_strategy = 'hierarchical'
        elif chunking_strategy == 'fixed':
            trainer.chunking_strategy = 'fixed_size'
        else:
            trainer.chunking_strategy = 'semantic'
        
        # Set processing mode
        if processing_mode == 'fast':
            trainer.quality_threshold = 0.7
            trainer.enable_ocr = False
        elif processing_mode == 'expert':
            trainer.quality_threshold = 0.9
            trainer.enable_ocr = True
        else:  # comprehensive
            trainer.quality_threshold = 0.8
            trainer.enable_ocr = True
        
        # Start training
        logger.info(f"ğŸš€ Starting RAG training with mode: {processing_mode}")
        training_start_time = time.time()
        
        try:
            trainer.train(max_files=max_files)
            training_successful = True
        except Exception as training_error:
            logger.error(f"Training failed: {training_error}")
            training_successful = False
        
        training_time = time.time() - training_start_time
        
        # Generate training summary
        training_summary = _generate_training_summary(trainer, training_successful, training_time)
        
        # Generate report file
        report_path = _generate_training_report(trainer, training_summary, base_dir)
        
        # Generate metadata
        metadata = {
            'base_dir': base_dir,
            'max_files': max_files,
            'force_cuda': force_cuda,
            'reset_databases': reset_databases,
            'chunking_strategy': chunking_strategy,
            'processing_mode': processing_mode,
            'training_successful': training_successful,
            'trained_at': time.strftime('%Y-%m-%d %H:%M:%S'),
            'report_path': report_path
        }
        
        execution_time = time.time() - start_time
        
        return {
            'status': 'success' if training_successful else 'error',
            'data': {
                'training_summary': training_summary,
                'files_processed': training_summary.get('files_processed', 0),
                'chunks_created': training_summary.get('chunks_created', 0),
                'works_extracted': training_summary.get('works_extracted', 0),
                'dependencies_saved': training_summary.get('dependencies_saved', 0),
                'file_path': report_path,
                'metadata': metadata
            },
            'execution_time': execution_time,
            'result_type': 'training_report',
            'result_title': f'ğŸ§  ĞĞ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ RAG ÑĞ¸ÑÑ‚ĞµĞ¼Ñ‹: {training_summary.get("files_processed", 0)} Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ²',
            'result_table': _create_training_table(training_summary),
            'metadata': metadata
        }
        
    except Exception as e:
        return { 
            'status': 'error', 
            'error': str(e),
            'execution_time': time.time() - start_time
        }


def _reset_rag_databases():
    """Reset RAG databases before training."""
    try:
        from quick_reset_rag import main as reset_main
        reset_main()
        logger.info("âœ… RAG databases reset successfully")
    except Exception as e:
        logger.warning(f"âš ï¸ Failed to reset databases: {e}")


def _generate_training_summary(trainer, training_successful: bool, training_time: float) -> Dict[str, Any]:
    """Generate comprehensive training summary."""
    try:
        stats = getattr(trainer, 'stats', {})
        
        return {
            'training_successful': training_successful,
            'files_processed': stats.get('files_processed', 0),
            'files_failed': stats.get('files_failed', 0),
            'total_chunks': stats.get('total_chunks', 0),
            'total_works': stats.get('total_works', 0),
            'training_time': training_time,
            'files_per_minute': stats.get('files_processed', 0) / (training_time / 60) if training_time > 0 else 0,
            'chunks_per_file': stats.get('total_chunks', 0) / stats.get('files_processed', 1) if stats.get('files_processed', 0) > 0 else 0,
            'works_per_file': stats.get('total_works', 0) / stats.get('files_processed', 1) if stats.get('files_processed', 0) > 0 else 0,
            'success_rate': (stats.get('files_processed', 0) / (stats.get('files_processed', 0) + stats.get('files_failed', 0))) * 100 if (stats.get('files_processed', 0) + stats.get('files_failed', 0)) > 0 else 0,
            'cuda_enabled': os.environ.get('FORCE_CUDA') == '1',
            'databases_status': _check_databases_status()
        }
    except Exception as e:
        logger.error(f"Error generating training summary: {e}")
        return {
            'training_successful': training_successful,
            'files_processed': 0,
            'files_failed': 0,
            'total_chunks': 0,
            'total_works': 0,
            'training_time': training_time,
            'error': str(e)
        }


def _check_databases_status() -> Dict[str, Any]:
    """Check status of RAG databases."""
    status = {'qdrant': False, 'neo4j': False}
    
    try:
        # Check Qdrant
        from qdrant_client import QdrantClient
        client = QdrantClient(host='localhost', port=6333)
        collections = client.get_collections()
        status['qdrant'] = True
    except Exception as e:
        logger.warning(f"Qdrant not available: {e}")
    
    try:
        # Check Neo4j
        import neo4j
        driver = neo4j.GraphDatabase.driver('neo4j://127.0.0.1:7687', auth=('neo4j', 'neopassword'))
        with driver.session() as session:
            session.run("RETURN 1")
        driver.close()
        status['neo4j'] = True
    except Exception as e:
        logger.warning(f"Neo4j not available: {e}")
    
    return status


def _generate_training_report(trainer, training_summary: Dict[str, Any], base_dir: str) -> str:
    """Generate detailed training report."""
    try:
        timestamp = time.strftime('%Y%m%d_%H%M%S')
        report_dir = Path(base_dir) / "reports"
        report_dir.mkdir(exist_ok=True)
        
        report_path = report_dir / f"rag_training_report_{timestamp}.json"
        
        report_data = {
            'training_summary': training_summary,
            'trainer_stats': getattr(trainer, 'stats', {}),
            'configuration': {
                'base_dir': base_dir,
                'cuda_enabled': os.environ.get('FORCE_CUDA') == '1',
                'chunking_strategy': getattr(trainer, 'chunking_strategy', 'smart'),
                'quality_threshold': getattr(trainer, 'quality_threshold', 0.8)
            },
            'generated_at': time.strftime('%Y-%m-%d %H:%M:%S')
        }
        
        import json
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(report_data, f, indent=2, ensure_ascii=False)
        
        logger.info(f"ğŸ“Š Training report saved: {report_path}")
        return str(report_path)
        
    except Exception as e:
        logger.error(f"Error generating training report: {e}")
        return ""


def _create_training_table(training_summary: Dict[str, Any]) -> List[Dict[str, Any]]:
    """Create training results table."""
    table_data = [
        {
            'metric': 'Ğ¤Ğ°Ğ¹Ğ»Ğ¾Ğ² Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ğ½Ğ¾',
            'value': training_summary.get('files_processed', 0),
            'status': 'success'
        },
        {
            'metric': 'Ğ¤Ğ°Ğ¹Ğ»Ğ¾Ğ² Ñ Ğ¾ÑˆĞ¸Ğ±ĞºĞ°Ğ¼Ğ¸',
            'value': training_summary.get('files_failed', 0),
            'status': 'warning' if training_summary.get('files_failed', 0) > 0 else 'success'
        },
        {
            'metric': 'Ğ§Ğ°Ğ½ĞºĞ¾Ğ² ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¾',
            'value': training_summary.get('total_chunks', 0),
            'status': 'info'
        },
        {
            'metric': 'Ğ Ğ°Ğ±Ğ¾Ñ‚ Ğ¸Ğ·Ğ²Ğ»ĞµÑ‡ĞµĞ½Ğ¾',
            'value': training_summary.get('total_works', 0),
            'status': 'info'
        },
        {
            'metric': 'Ğ’Ñ€ĞµĞ¼Ñ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ',
            'value': f"{training_summary.get('training_time', 0):.1f} ÑĞµĞº",
            'status': 'info'
        },
        {
            'metric': 'Ğ¡ĞºĞ¾Ñ€Ğ¾ÑÑ‚ÑŒ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸',
            'value': f"{training_summary.get('files_per_minute', 0):.1f} Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ²/Ğ¼Ğ¸Ğ½",
            'status': 'info'
        },
        {
            'metric': 'ĞŸÑ€Ğ¾Ñ†ĞµĞ½Ñ‚ ÑƒÑĞ¿ĞµÑ…Ğ°',
            'value': f"{training_summary.get('success_rate', 0):.1f}%",
            'status': 'success' if training_summary.get('success_rate', 0) > 80 else 'warning'
        }
    ]
    
    return table_data
