#!/usr/bin/env python3
"""
–ò–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π VLM –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä –¥–ª—è RAG —Ç—Ä–µ–Ω–µ—Ä–∞
–û–±—ä–µ–¥–∏–Ω—è–µ—Ç PyMuPDF + LayoutXLM + Smart Chunking + –∑–∞—â–∏—Ç–∞ –æ—Ç CUDA –æ—à–∏–±–æ–∫
"""

import torch
import logging
from typing import List, Dict, Optional, Tuple
from PIL import Image
import fitz  # PyMuPDF
import io
import numpy as np

logger = logging.getLogger(__name__)

class IntegratedVLMProcessor:
    """–ò–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π VLM –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä –¥–ª—è RAG —Ç—Ä–µ–Ω–µ—Ä–∞"""
    
    def __init__(self):
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        self.layout_model = None
        self.layout_processor = None
        self._initialize_integrated_models()
    
    def _initialize_integrated_models(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π"""
        try:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º Auto-–∫–ª–∞—Å—Å—ã –¥–ª—è –Ω–∞–¥–µ–∂–Ω–æ–π –∑–∞–≥—Ä—É–∑–∫–∏
            from transformers import AutoProcessor, AutoModelForTokenClassification
            
            # LayoutXLM - –º—É–ª—å—Ç–∏—è–∑—ã—á–Ω–∞—è –º–æ–¥–µ–ª—å
            model_name = "microsoft/layoutxlm-base"
            
            logger.info("Loading Integrated LayoutXLM for RAG trainer...")
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—É—é –º—É–ª—å—Ç–∏—è–∑—ã—á–Ω—É—é –º–æ–¥–µ–ª—å
            self.layout_processor = AutoProcessor.from_pretrained(
                model_name,
                max_length=512,
                truncation=True,
                padding=True
            )
            self.layout_model = AutoModelForTokenClassification.from_pretrained(
                model_name,
                num_labels=7  # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –∫–ª–∞—Å—Å—ã –¥–ª—è –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
            )
            self.layout_model.to(self.device)
            self.layout_model.eval()
            
            logger.info("Integrated LayoutXLM loaded successfully for RAG trainer")
            
        except Exception as e:
            logger.error(f"Failed to load Integrated LayoutXLM: {e}")
            # Fallback –Ω–∞ LayoutLMv3
            try:
                from transformers import LayoutLMv3ForTokenClassification, LayoutLMv3Processor
                
                logger.info("Falling back to Integrated LayoutLMv3...")
                self.layout_processor = LayoutLMv3Processor.from_pretrained(
                    "microsoft/layoutlmv3-base",
                    max_length=512,
                    truncation=True,
                    padding=True
                )
                self.layout_model = LayoutLMv3ForTokenClassification.from_pretrained("microsoft/layoutlmv3-base")
                self.layout_model.to(self.device)
                self.layout_model.eval()
                
                logger.warning("Using Integrated LayoutLMv3 fallback")
                
            except Exception as e2:
                logger.error(f"Failed to load fallback model: {e2}")
                self.layout_model = None
                self.layout_processor = None
    
    def is_available(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ VLM"""
        return self.layout_model is not None and self.layout_processor is not None
    
    def analyze_document_structure(self, pdf_path: str) -> Dict:
        """
        –ò–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–æ–∫—É–º–µ–Ω—Ç–∞ –¥–ª—è RAG —Ç—Ä–µ–Ω–µ—Ä–∞
        –û–±—ä–µ–¥–∏–Ω—è–µ—Ç PyMuPDF + LayoutXLM + Smart Chunking + –∑–∞—â–∏—Ç–∞ –æ—Ç CUDA
        """
        if not self.is_available():
            return {'vlm_available': False, 'tables': [], 'structure': 'fallback'}
        
        try:
            # –ò–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è PDF —Å PyMuPDF
            images = self._convert_pdf_integrated(pdf_path)
            
            if not images:
                return {'vlm_available': False, 'tables': [], 'structure': 'no_images'}
            
            # –ò–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∫–∞–∂–¥–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã
            all_tables = []
            successful_pages = 0
            total_chunks = 0
            
            for page_num, image in enumerate(images):
                try:
                    # –ò–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Å—Ç—Ä–∞–Ω–∏—Ü—ã —Å –∑–∞—â–∏—Ç–æ–π –æ—Ç CUDA
                    page_tables, chunks_processed = self._analyze_page_integrated(image, page_num)
                    all_tables.extend(page_tables)
                    successful_pages += 1
                    total_chunks += chunks_processed
                    
                except Exception as e:
                    logger.error(f"Page {page_num + 1} analysis failed: {e}")
                    continue
            
            return {
                'vlm_available': True,
                'tables': all_tables,
                'total_tables': len(all_tables),
                'pages_processed': successful_pages,
                'total_pages': len(images),
                'total_chunks': total_chunks,
                'structure': 'integrated_pymupdf_layoutxlm',
                'success_rate': successful_pages / len(images) if images else 0,
                'avg_chunks_per_page': total_chunks / successful_pages if successful_pages > 0 else 0
            }
            
        except Exception as e:
            logger.error(f"Integrated analysis failed: {e}")
            return {'vlm_available': False, 'tables': [], 'structure': 'error'}
    
    def _convert_pdf_integrated(self, pdf_path: str, dpi: int = 300) -> List[Image.Image]:
        """–ò–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è PDF —Å PyMuPDF"""
        images = []
        
        try:
            doc = fitz.open(pdf_path)
            
            for page_num in range(len(doc)):
                try:
                    page = doc[page_num]
                    mat = fitz.Matrix(dpi/72, dpi/72)
                    pix = page.get_pixmap(matrix=mat, alpha=False)
                    
                    img_data = pix.tobytes("png")
                    img = Image.open(io.BytesIO(img_data))
                    
                    if self._validate_image_integrated(img, page_num):
                        images.append(img)
                        logger.debug(f"Page {page_num + 1} converted: {img.size}")
                    else:
                        logger.warning(f"Page {page_num + 1} failed validation")
                        
                except Exception as e:
                    logger.error(f"Failed to convert page {page_num + 1}: {e}")
                    continue
            
            total_pages = len(doc)
            doc.close()
            logger.info(f"Integrated conversion: {len(images)} valid pages from {total_pages} total")
            
        except Exception as e:
            logger.error(f"Integrated conversion failed: {e}")
            return []
        
        return images
    
    def _validate_image_integrated(self, img: Image.Image, page_num: int) -> bool:
        """–ò–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
        try:
            if img.size[0] == 0 or img.size[1] == 0:
                return False
            
            if img.size[0] < 100 or img.size[1] < 100:
                return False
            
            # –ò–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ä–∞–∑–º–µ—Ä—ã –¥–ª—è —á–∞–Ω–∫–∏–Ω–≥–∞
            if img.size[0] > 1500 or img.size[1] > 1500:
                img.thumbnail((1500, 1500), Image.Resampling.LANCZOS)
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –ø—É—Å—Ç–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            img_array = np.array(img)
            if len(img_array.shape) == 3:
                if np.all(img_array == img_array[0, 0]):
                    return False
            
            return True
            
        except Exception as e:
            logger.error(f"Integrated validation failed for page {page_num + 1}: {e}")
            return False
    
    def _analyze_page_integrated(self, image: Image.Image, page_num: int) -> Tuple[List[Dict], int]:
        """–ò–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Å—Ç—Ä–∞–Ω–∏—Ü—ã —Å –ø–æ–ª–Ω–æ–π –∑–∞—â–∏—Ç–æ–π –æ—Ç CUDA –æ—à–∏–±–æ–∫"""
        try:
            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è
            if not self._validate_image_integrated(image, page_num):
                return [], 0
            
            # –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ô –§–ò–ö–°: –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–µ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ —Ç–æ–∫–µ–Ω–æ–≤
            inputs = self.layout_processor(
                image, 
                return_tensors="pt",
                max_length=512,  # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –¥–æ 512 —Ç–æ–∫–µ–Ω–æ–≤
                truncation=True,  # –û–±—Ä–µ–∑–∫–∞ –¥–ª–∏–Ω–Ω—ã—Ö –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π
                padding=True
            )
            
            # –ü–µ—Ä–µ–º–µ—â–∞–µ–º –Ω–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ
            inputs = {k: v.to(self.device) for k, v in inputs.items()}
            
            # –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ô –§–ò–ö–°: –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –ø–µ—Ä–µ–≤–æ–¥–∏–º –≤ FP16 –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å VLM
            import torch
            inputs = {k: v.to(torch.float16) if v.dtype == torch.float32 else v for k, v in inputs.items()}
            
            # –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –ó–ê–©–ò–¢–ê: –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–ª–∏–Ω—ã —Ç–æ–∫–µ–Ω–æ–≤
            input_ids = inputs.get('input_ids', None)
            if input_ids is not None:
                token_count = input_ids.shape[1]
                if token_count > 512:
                    logger.warning(f"‚ö†Ô∏è Page {page_num + 1} has {token_count} tokens (>{512}), truncating to prevent CUDA error")
                    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –æ–±—Ä–µ–∑–∫–∞ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
                    inputs['input_ids'] = input_ids[:, :512]
                    if 'attention_mask' in inputs:
                        inputs['attention_mask'] = inputs['attention_mask'][:, :512]
            
            # –ó–∞—â–∏—Ç–∞ –æ—Ç –Ω—É–ª–µ–≤—ã—Ö —Ç–µ–Ω–∑–æ—Ä–æ–≤
            for key, tensor in inputs.items():
                if tensor.numel() == 0:
                    logger.warning(f"‚ö†Ô∏è Page {page_num + 1} skipped: Empty tensor {key}")
                    return [], 0
            
            # –ò–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π VLM –∞–Ω–∞–ª–∏–∑ —Å –∑–∞—â–∏—Ç–æ–π –æ—Ç CUDA –æ—à–∏–±–æ–∫
            with torch.no_grad():
                outputs = self.layout_model(**inputs)
                predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)
                
                # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
                tables = self._extract_structure_integrated(predictions, image, page_num)
                return tables, 1
            
        except RuntimeError as e:
            # –°–ø–µ—Ü–∏–∞–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ CUDA –æ—à–∏–±–æ–∫
            if "device-side assert triggered" in str(e) or "srcSelectDimSize" in str(e):
                logger.error(f"üõë CUDA assertion failed on page {page_num + 1}. Skipping: {e}")
                return [], 0
            raise e
        except Exception as e:
            logger.error(f"Page {page_num + 1} analysis failed: {e}")
            return [], 0
    
    def _extract_structure_integrated(self, predictions: torch.Tensor, image: Image.Image, page_num: int) -> List[Dict]:
        """–ò–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã"""
        tables = []
        
        try:
            # –ò–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
            # –í —Ä–µ–∞–ª—å–Ω–æ–π —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ –∑–¥–µ—Å—å –±—ã–ª–∞ –±—ã —Å–ª–æ–∂–Ω–∞—è –ª–æ–≥–∏–∫–∞
            return tables
            
        except Exception as e:
            logger.error(f"Integrated structure extraction failed for page {page_num + 1}: {e}")
            return []


def test_integrated_vlm():
    """–¢–µ—Å—Ç –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ VLM –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞"""
    print("Testing Integrated VLM processor for RAG trainer...")
    
    processor = IntegratedVLMProcessor()
    
    if not processor.is_available():
        print("ERROR: Integrated VLM not available")
        return False
    
    # –¢–µ—Å—Ç —Å —Ä–µ–∞–ª—å–Ω—ã–º PDF
    import os
    test_pdf = None
    for root, dirs, files in os.walk("I:/docs/downloaded"):
        for file in files:
            if file.endswith('.pdf'):
                test_pdf = os.path.join(root, file)
                break
        if test_pdf:
            break
    
    if not test_pdf:
        print("ERROR: No PDF files found for testing")
        return False
    
    try:
        # –¢–µ—Å—Ç –∞–Ω–∞–ª–∏–∑–∞
        result = processor.analyze_document_structure(test_pdf)
        print(f"SUCCESS: Analysis completed - {result['total_tables']} tables")
        print(f"Pages: {result['pages_processed']}/{result['total_pages']}, Chunks: {result['total_chunks']}")
        print(f"Success rate: {result['success_rate']:.2%}, Avg chunks per page: {result['avg_chunks_per_page']:.1f}")
        print(f"Structure: {result['structure']}")
        
        return True
        
    except Exception as e:
        print(f"ERROR: Test failed: {e}")
        return False


if __name__ == "__main__":
    success = test_integrated_vlm()
    if success:
        print("SUCCESS: Integrated VLM processor works!")
    else:
        print("FAILED: Integrated VLM processor failed!")
