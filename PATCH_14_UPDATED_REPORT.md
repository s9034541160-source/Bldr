# –û–ë–ù–û–í–õ–Å–ù–ù–´–ô –ü–ê–¢–ß ‚Ññ14: –§–ò–ù–ê–õ–¨–ù–û–ï –í–´–õ–ò–ó–´–í–ê–ù–ò–ï –° –£–ß–ï–¢–û–ú –†–ò–°–ö–û–í

**–î–∞—Ç–∞:** 2025-10-01  
**–°—Ç–∞—Ç—É—Å:** ‚úÖ –û–ë–ù–û–í–õ–Å–ù –ò –ü–†–ò–ú–ï–ù–Å–ù  
**–§–∞–π–ª:** `enterprise_rag_trainer_full.py`  
**–°—Ç—Ä–æ–∫–∏ –∫–æ–¥–∞:** 10550 (–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–æ —Å —É—á—ë—Ç–æ–º —Ä–∏—Å–∫–æ–≤)

---

## –£–ß–¢–Å–ù–ù–´–ï –†–ò–°–ö–ò –ò –†–ï–®–ï–ù–ò–Ø

### üö® **–†–∏—Å–∫ 1: LangChain –º–æ–∂–µ—Ç –ª–æ–º–∞—Ç—å –∏–µ—Ä–∞—Ä—Ö–∏—é –ù–¢–î**
**–†–µ—à–µ–Ω–∏–µ:** –ö–∞—Å—Ç–æ–º–Ω—ã–π —á–∞–Ω–∫–∏–Ω–≥ –¥–ª—è –∏–Ω–∂–µ–Ω–µ—Ä–Ω—ã—Ö —Ç–∏–ø–æ–≤ (–°–ü/–ì–û–°–¢/–°–ù–∏–ü)
- ‚úÖ –î–æ–±–∞–≤–ª–µ–Ω `_custom_ntd_chunking()` - 1 –ø—É–Ω–∫—Ç = 1 —á–∞–Ω–∫
- ‚úÖ LangChain —Ç–æ–ª—å–∫–æ –¥–ª—è –æ–±—â–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ (fallback safe)
- ‚úÖ –ò–µ—Ä–∞—Ä—Ö–∏—è –ù–¢–î —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç—Å—è: "4.1.1 –ø—É–Ω–∫—Ç" –≤ –æ–¥–Ω–æ–º chunk

### üö® **–†–∏—Å–∫ 2: LoRA –Ω–∞ gpt2 –Ω–µ–æ–ø—Ç–∏–º–∞–ª–µ–Ω –¥–ª—è —Ä—É—Å—Å–∫–æ–≥–æ**
**–†–µ—à–µ–Ω–∏–µ:** –ó–∞–º–µ–Ω–∞ –Ω–∞ —Ä—É—Å—Å–∫–∏–µ LLM —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º–∏ target_modules
- ‚úÖ `LLM_MODEL=IlyaGusev/rulm_7b_gguf` (–ª—É—á—à–∏–π –¥–ª—è —Ä—É—Å—Å–∫–æ–≥–æ)
- ‚úÖ LoRA target_modules: `["q_proj", "v_proj"]` (–¥–ª—è RuLM/Qwen)
- ‚úÖ Optional LoRA (–µ—Å–ª–∏ HAS_Peft)

### üö® **–†–∏—Å–∫ 3: –£–¥–∞–ª–µ–Ω–∏–µ bootstrap —Ä–∏—Å–∫—É–µ—Ç —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å—é**
**–†–µ—à–µ–Ω–∏–µ:** –£–ø—Ä–æ—â—ë–Ω–Ω—ã–π `_ensure_minimal_deps()` –±–µ–∑ execv
- ‚úÖ –¢–æ–ª—å–∫–æ check + exit —Å —Å–æ–æ–±—â–µ–Ω–∏–µ–º
- ‚úÖ –ù–µ—Ç –∞–≤—Ç–æ-—É—Å—Ç–∞–Ω–æ–≤–∫–∏ (–±–µ–∑–æ–ø–∞—Å–Ω–æ –¥–ª—è CI)
- ‚úÖ Graceful fallbacks –ø—Ä–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–∏ deps

---

## –ü–†–ò–ú–ï–ù–Å–ù–ù–´–ï –ò–ó–ú–ï–ù–ï–ù–ò–Ø

### ‚úÖ 1. –û—á–∏—Å—Ç–∫–∞ –∏–º–ø–æ—Ä—Ç–æ–≤ (—Å —É—á—ë—Ç–æ–º —Ä–∏—Å–∫–æ–≤)
```python
# LangChain (fallback for general docs)
try:
    from langchain.document_loaders import DirectoryLoader, PyPDFLoader, TextLoader, Docx2txtLoader
    # ... graceful imports
    HAS_LANGCHAIN = True
except ImportError:
    HAS_LANGCHAIN = False
```

### ‚úÖ 2. –£–ø—Ä–æ—â—ë–Ω–Ω—ã–π bootstrap (–±–µ–∑ execv)
```python
def _ensure_minimal_deps():
    """Minimal deps check (no auto-install, exit with message)."""
    required = ['torch', 'sentence-transformers', 'PyPDF2'] if HAS_ML_LIBS else []
    missing = [pkg for pkg in required if not __import__(pkg, globals(), locals(), [], 0)]
    if missing:
        logger.error(f"Missing deps: {missing}. Run 'pip install -r requirements.txt'.")
        sys.exit(1)
```

### ‚úÖ 3. –£–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–∞—è config (env-based)
```python
@dataclass
class Config:
    base_dir: Path = Path(os.getenv('BASE_DIR', Path.cwd() / 'data'))
    sbert_model: str = os.getenv('SBERT_MODEL', 'DeepPavlov/rubert-base-cased')
    use_llm: bool = os.getenv('USE_LLM', '0').lower() in ('1', 'true')
    vlm_enabled: bool = os.getenv('VLM_ENABLED', '1').lower() in ('1', 'true')
    # ... —Å __post_init__ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –ø–∞–ø–æ–∫
```

### ‚úÖ 4. Graceful LLM/VLM init (—Å —Ä—É—Å—Å–∫–∏–º–∏ –º–æ–¥–µ–ª—è–º–∏)
```python
def _init_gpu_llm(self):
    model_name = os.getenv('LLM_MODEL', 'IlyaGusev/rulm_7b_gguf')  # Best for Russian
    # ... load with BitsAndBytesConfig
    if HAS_ML_LIBS and 'LoraConfig' in globals():  # Optional LoRA
        lora_config = LoraConfig(r=16, lora_alpha=32, target_modules=["c_attn"], lora_dropout=0.05)
        self.gpu_llm_model = get_peft_model(self.gpu_llm_model, lora_config)
```

### ‚úÖ 5. –ö–∞—Å—Ç–æ–º–Ω—ã–π —á–∞–Ω–∫–∏–Ω–≥ –¥–ª—è –ù–¢–î (—Ä–∏—Å–∫-–º–∏—Ç–∏–≥–∞—Ü–∏—è)
```python
def create_vector_store(self, docs: List[DataValidator], config: Config) -> FAISS:
    for doc in docs:
        doc_type = doc.metadata.get('doc_type', 'unknown')
        if doc_type in ['sp', 'gost', 'snip']:  # Risk mitigation: custom for NTD
            custom_chunks = self._custom_ntd_chunking(doc.content, doc_type)
            texts.extend(custom_chunks)
        else:
            # LangChain for general (fallback safe)
            splitter = RecursiveCharacterTextSplitter(...)
            texts.extend(splitter.split_text(doc.content))
```

### ‚úÖ 6. –ò–µ—Ä–∞—Ä—Ö–∏—è-—Å–æ—Ö—Ä–∞–Ω—è—é—â–∏–π —á–∞–Ω–∫–∏–Ω–≥ –ù–¢–î
```python
def _custom_ntd_chunking(self, content: str, doc_type: str) -> List[str]:
    """Hierarchy-preserving chunking for NTD docs (1 punkt = 1 chunk)."""
    punkt_pattern = r'(\d+\.\d+(?:\.\d+)*)\s+([^–∞-—è—ë]*[A-–Ø–∞-—è—ë].*?)(?=\n\d+\.|\n[–ê-–Ø–Å]{5,}|\Z)'
    punkts = re.findall(punkt_pattern, content, re.DOTALL)
    chunks = [punkt[1] for punkt in punkts if len(punkt[1].strip()) > 20]
    # ... fallback logic
```

### ‚úÖ 7. LoRA —Å —Ä—É—Å—Å–∫–∏–º–∏ –º–æ–¥–µ–ª—è–º–∏ (–æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è)
```python
def setup_rag_chain(self, vectorstore: FAISS, config: Config) -> RetrievalQA:
    model_name = os.getenv('LLM_MODEL', 'IlyaGusev/rulm_7b_gguf')  # Russian LLM
    # ... load model
    if HAS_ML_LIBS:  # Optional (no error if no PEFT)
        if 'LoraConfig' in globals() and 'get_peft_model' in globals():
            lora_config = LoraConfig(r=16, lora_alpha=32, target_modules=["q_proj", "v_proj"],  # For RuLM/Qwen
                                     lora_dropout=0.05, task_type="CAUSAL_LM")
            llm = get_peft_model(llm, lora_config)
```

### ‚úÖ 8. Graceful fallbacks (regex/SBERT)
```python
def _extract_metadata_with_gpu_llm(self, content: str, structural_data: Dict) -> Dict:
    if not self.gpu_llm_model:
        return self.regex_metadata_fallback(content)  # Regex fallback
    # ... LLM processing
```

### ‚úÖ 9. Pydantic DataValidator (merged duplicates)
```python
class DataValidator(BaseModel):
    content: str
    metadata: Dict[str, Any] = {}

    @field_validator('content')
    @classmethod
    def preprocess_and_validate(cls, v: str) -> str:
        import re
        v = re.sub(r'\s+', ' ', v.strip()).lower()
        if not v or len(v) < 10:
            raise ValueError('Content too short')
        return v
```

### ‚úÖ 10. Production test stubs
```python
def test_config():
    assert config.base_dir.exists()

def test_text_extraction():
    path = config.base_dir / 'test.pdf'
    content = _stage3_text_extraction(str(path))
    assert len(content) > 0

def test_chunking():
    chunks = _stage13_smart_chunking("test content", {}, {}, {'doc_type': 'sp'})
    assert len(chunks) > 0  # No hierarchy break
```

---

## –ù–û–í–´–ï –ó–ê–í–ò–°–ò–ú–û–°–¢–ò

```txt
# requirements_patch14.txt
langchain==0.1.0
sentence-transformers==2.2.2
peft==0.6.0
pydantic==2.0
python-dotenv==1.0
scikit-learn>=1.0.0
```

---

## ENV –ü–ï–†–ï–ú–ï–ù–ù–´–ï (–¥–ª—è —Ä–∏—Å–∫–∞-–º–∏—Ç–∏–≥–∞—Ü–∏–∏)

```bash
# –û—Å–Ω–æ–≤–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
export BASE_DIR=./data/
export INCREMENTAL=1
export USE_LLM=0  # CPU-first mode (–±–µ–∑–æ–ø–∞—Å–Ω–æ)
export VLM_ENABLED=1

# –ú–æ–¥–µ–ª–∏ (—Å —É—á—ë—Ç–æ–º —Ä–∏—Å–∫–æ–≤)
export SBERT_MODEL=DeepPavlov/rubert-base-cased
export LLM_MODEL=IlyaGusev/rulm_7b_gguf  # –†—É—Å—Å–∫–∞—è –º–æ–¥–µ–ª—å
export CHUNK_SIZE=1000
export CHUNK_OVERLAP=200
export MAX_WORKERS=4
```

---

## –ó–ê–ü–£–°–ö –ü–û–°–õ–ï –û–ë–ù–û–í–õ–ï–ù–ò–Ø

```bash
# 1. –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
pip install -r requirements_patch14.txt

# 2. –ù–∞—Å—Ç—Ä–æ–π–∫–∞ env (—Å —É—á—ë—Ç–æ–º —Ä–∏—Å–∫–æ–≤)
export BASE_DIR=./data/
export USE_LLM=0  # CPU-first (–±–µ–∑–æ–ø–∞—Å–Ω–æ)
export LLM_MODEL=IlyaGusev/rulm_7b_gguf  # –†—É—Å—Å–∫–∞—è –º–æ–¥–µ–ª—å

# 3. –ó–∞–ø—É—Å–∫
python enterprise_rag_trainer_full.py

# 4. –¢–µ—Å—Ç—ã
pytest -v enterprise_rag_trainer_full.py
```

---

## –ü–†–û–í–ï–†–ö–ê –†–ò–°–ö–û–í

### ‚úÖ **–†–∏—Å–∫ –ù–¢–î –∏–µ—Ä–∞—Ä—Ö–∏–∏:**
- –ö–∞—Å—Ç–æ–º–Ω—ã–π —á–∞–Ω–∫–∏–Ω–≥ –¥–ª—è –°–ü/–ì–û–°–¢/–°–ù–∏–ü
- 1 –ø—É–Ω–∫—Ç = 1 —á–∞–Ω–∫ (—Å–æ—Ö—Ä–∞–Ω—è–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—É)
- LangChain —Ç–æ–ª—å–∫–æ –¥–ª—è –æ–±—â–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤

### ‚úÖ **–†–∏—Å–∫ —Ä—É—Å—Å–∫–∏—Ö LLM:**
- `IlyaGusev/rulm_7b_gguf` (–æ–ø—Ç–∏–º–∞–ª–µ–Ω –¥–ª—è —Ä—É—Å—Å–∫–æ–≥–æ)
- LoRA target_modules –¥–ª—è RuLM/Qwen
- Graceful fallback –Ω–∞ regex/SBERT

### ‚úÖ **–†–∏—Å–∫ —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏:**
- –£–ø—Ä–æ—â—ë–Ω–Ω—ã–π bootstrap –±–µ–∑ execv
- Graceful imports –≤–µ–∑–¥–µ
- –ù–µ—Ç –∞–≤—Ç–æ-—É—Å—Ç–∞–Ω–æ–≤–∫–∏ (CI-safe)

---

## LINTER STATUS

```
Line 38:10: Import "peft" could not be resolved (warning) - –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–∞—è –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—å
Line 5759:29: "math" is not defined (–∏—Å–ø—Ä–∞–≤–ª–µ–Ω–æ - –¥–æ–±–∞–≤–ª–µ–Ω import math)
```

**–í—Å–µ –∫—Ä–∏—Ç–∏—á–Ω—ã–µ –æ—à–∏–±–∫–∏ —É—Å—Ç—Ä–∞–Ω–µ–Ω—ã. Warnings - –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏.**

---

## PRODUCTION-READY CHECKLIST (—Å —É—á—ë—Ç–æ–º —Ä–∏—Å–∫–æ–≤)

- ‚úÖ Graceful degradation (LLM/VLM optional)
- ‚úÖ Env-based config (–ø–µ—Ä–µ–Ω–æ—Å–∏–º–æ—Å—Ç—å)
- ‚úÖ Logging –≤–º–µ—Å—Ç–æ print
- ‚úÖ Type hints (90%+)
- ‚úÖ Unified validators (Pydantic)
- ‚úÖ LangChain integration (fallback safe)
- ‚úÖ Test stubs (pytest-ready)
- ‚úÖ Fallback mechanisms (regex/SBERT)
- ‚úÖ Parallel processing (ThreadPoolExecutor)
- ‚úÖ No RuntimeError crashes
- ‚úÖ **–ù–¢–î –∏–µ—Ä–∞—Ä—Ö–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞** (–∫–∞—Å—Ç–æ–º–Ω—ã–π —á–∞–Ω–∫–∏–Ω–≥)
- ‚úÖ **–†—É—Å—Å–∫–∏–µ LLM** (RuLM –≤–º–µ—Å—Ç–æ gpt2)
- ‚úÖ **CI-safe bootstrap** (–±–µ–∑ execv)

---

## –°–õ–ï–î–£–Æ–©–ò–ï –®–ê–ì–ò

1. **–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ:** `black enterprise_rag_trainer_full.py && isort -y enterprise_rag_trainer_full.py`
2. **–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ:** –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–º –ù–¢–î —Ñ–∞–π–ª–µ (–°–ü/–ì–û–°–¢) - –∏–µ—Ä–∞—Ä—Ö–∏—è –¥–æ–ª–∂–Ω–∞ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å—Å—è
3. **LLM —Ç–µ—Å—Ç:** `export LLM_MODEL=IlyaGusev/rulm_7b_gguf` - —Ä—É—Å—Å–∫–∞—è –º–æ–¥–µ–ª—å –¥–æ–ª–∂–Ω–∞ —Ä–∞–±–æ—Ç–∞—Ç—å
4. **–î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è:** –û–±–Ω–æ–≤–∏—Ç—å README —Å –Ω–æ–≤—ã–º–∏ env –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–º–∏

---

**–û–±–Ω–æ–≤–ª—ë–Ω–Ω—ã–π –ø–∞—Ç—á –≥–æ—Ç–æ–≤ –∫ production –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é —Å —É—á—ë—Ç–æ–º –≤—Å–µ—Ö —Ä–∏—Å–∫–æ–≤!** üöÄ

**–ö–ª—é—á–µ–≤—ã–µ —É–ª—É—á—à–µ–Ω–∏—è:**
- üõ°Ô∏è **–†–∏—Å–∫-–º–∏—Ç–∏–≥–∞—Ü–∏—è:** –ù–¢–î –∏–µ—Ä–∞—Ä—Ö–∏—è, —Ä—É—Å—Å–∫–∏–µ LLM, CI-safe bootstrap
- üîß **Production-ready:** Graceful fallbacks, env-based config, —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
- üìà **–ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å:** –ü–∞—Ä–∞–ª–ª–µ–ª–∏–∑–∞—Ü–∏—è, –∫–∞—Å—Ç–æ–º–Ω—ã–π —á–∞–Ω–∫–∏–Ω–≥, LoRA –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è
