#!/usr/bin/env python3
"""
Smart VLM –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä —Å —É–º–Ω—ã–º —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ–º –¥–ª–∏–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
–†–µ—à–∞–µ—Ç –ø—Ä–æ–±–ª–µ–º—É –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è 512 —Ç–æ–∫–µ–Ω–æ–≤ –≤ LayoutLMv3/LayoutXLM
"""

import torch
import logging
from typing import List, Dict, Optional, Tuple
from PIL import Image
import fitz  # PyMuPDF
import io
import numpy as np
import math

logger = logging.getLogger(__name__)

class SmartVLMProcessor:
    """Smart VLM –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä —Å —É–º–Ω—ã–º —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ–º –¥–ª–∏–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤"""
    
    def __init__(self, max_tokens: int = 512):
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        self.max_tokens = max_tokens
        self.layout_model = None
        self.layout_processor = None
        self._initialize_smart_models()
    
    def _initialize_smart_models(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —É–º–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π —á–∞–Ω–∫–∏–Ω–≥–∞"""
        try:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º Auto-–∫–ª–∞—Å—Å—ã –¥–ª—è –Ω–∞–¥–µ–∂–Ω–æ–π –∑–∞–≥—Ä—É–∑–∫–∏
            from transformers import AutoProcessor, AutoModelForTokenClassification
            
            # LayoutXLM - –º—É–ª—å—Ç–∏—è–∑—ã—á–Ω–∞—è –º–æ–¥–µ–ª—å
            model_name = "microsoft/layoutxlm-base"
            
            logger.info("Loading Smart LayoutXLM with chunking support...")
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—É—é –º—É–ª—å—Ç–∏—è–∑—ã—á–Ω—É—é –º–æ–¥–µ–ª—å —á–µ—Ä–µ–∑ Auto-–∫–ª–∞—Å—Å—ã
            self.layout_processor = AutoProcessor.from_pretrained(
                model_name,
                max_length=self.max_tokens,
                truncation=True,
                padding=True
            )
            self.layout_model = AutoModelForTokenClassification.from_pretrained(
                model_name,
                num_labels=7  # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –∫–ª–∞—Å—Å—ã –¥–ª—è –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
            )
            self.layout_model.to(self.device)
            self.layout_model.eval()
            
            logger.info(f"Smart LayoutXLM loaded via AutoModel - max_tokens: {self.max_tokens}")
            
        except Exception as e:
            logger.error(f"Failed to load Smart LayoutXLM via AutoModel: {e}")
            # Fallback –Ω–∞ LayoutLMv3
            try:
                from transformers import LayoutLMv3ForTokenClassification, LayoutLMv3Processor
                
                logger.info("Falling back to Smart LayoutLMv3...")
                self.layout_processor = LayoutLMv3Processor.from_pretrained(
                    "microsoft/layoutlmv3-base",
                    max_length=self.max_tokens,
                    truncation=True,
                    padding=True
                )
                self.layout_model = LayoutLMv3ForTokenClassification.from_pretrained("microsoft/layoutlmv3-base")
                self.layout_model.to(self.device)
                self.layout_model.eval()
                
                logger.warning("Using Smart LayoutLMv3 fallback")
                
            except Exception as e2:
                logger.error(f"Failed to load fallback model: {e2}")
                self.layout_model = None
                self.layout_processor = None
    
    def is_available(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ VLM"""
        return self.layout_model is not None and self.layout_processor is not None
    
    def convert_pdf_to_images_smart(self, pdf_path: str, dpi: int = 300) -> List[Image.Image]:
        """Smart –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è PDF —Å PyMuPDF"""
        images = []
        
        try:
            doc = fitz.open(pdf_path)
            
            for page_num in range(len(doc)):
                try:
                    page = doc[page_num]
                    mat = fitz.Matrix(dpi/72, dpi/72)
                    pix = page.get_pixmap(matrix=mat, alpha=False)
                    
                    img_data = pix.tobytes("png")
                    img = Image.open(io.BytesIO(img_data))
                    
                    if self._validate_image_smart(img, page_num):
                        images.append(img)
                        logger.debug(f"Page {page_num + 1} converted: {img.size}")
                    else:
                        logger.warning(f"Page {page_num + 1} failed validation")
                        
                except Exception as e:
                    logger.error(f"Failed to convert page {page_num + 1}: {e}")
                    continue
            
            total_pages = len(doc)
            doc.close()
            logger.info(f"Smart conversion: {len(images)} valid pages from {total_pages} total")
            
        except Exception as e:
            logger.error(f"Smart conversion failed: {e}")
            return []
        
        return images
    
    def _validate_image_smart(self, img: Image.Image, page_num: int) -> bool:
        """Smart –≤–∞–ª–∏–¥–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
        try:
            if img.size[0] == 0 or img.size[1] == 0:
                return False
            
            if img.size[0] < 100 or img.size[1] < 100:
                return False
            
            # Smart —Ä–∞–∑–º–µ—Ä—ã –¥–ª—è —á–∞–Ω–∫–∏–Ω–≥–∞
            if img.size[0] > 1500 or img.size[1] > 1500:
                img.thumbnail((1500, 1500), Image.Resampling.LANCZOS)
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –ø—É—Å—Ç–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            img_array = np.array(img)
            if len(img_array.shape) == 3:
                if np.all(img_array == img_array[0, 0]):
                    return False
            
            return True
            
        except Exception as e:
            logger.error(f"Smart validation failed for page {page_num + 1}: {e}")
            return False
    
    def analyze_document_structure_smart(self, pdf_path: str) -> Dict:
        """
        Smart –∞–Ω–∞–ª–∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–æ–∫—É–º–µ–Ω—Ç–∞ —Å —É–º–Ω—ã–º —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ–º
        """
        if not self.is_available():
            return {'vlm_available': False, 'tables': [], 'structure': 'fallback'}
        
        try:
            # Smart –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è
            images = self.convert_pdf_to_images_smart(pdf_path)
            
            if not images:
                return {'vlm_available': False, 'tables': [], 'structure': 'no_images'}
            
            # Smart –∞–Ω–∞–ª–∏–∑ –∫–∞–∂–¥–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã —Å —á–∞–Ω–∫–∏–Ω–≥–æ–º
            all_tables = []
            successful_pages = 0
            total_chunks = 0
            
            for page_num, image in enumerate(images):
                try:
                    # Smart –∞–Ω–∞–ª–∏–∑ —Å—Ç—Ä–∞–Ω–∏—Ü—ã —Å —á–∞–Ω–∫–∏–Ω–≥–æ–º
                    page_tables, chunks_processed = self._analyze_page_smart(image, page_num)
                    all_tables.extend(page_tables)
                    successful_pages += 1
                    total_chunks += chunks_processed
                    
                except Exception as e:
                    logger.error(f"Page {page_num + 1} analysis failed: {e}")
                    continue
            
            return {
                'vlm_available': True,
                'tables': all_tables,
                'total_tables': len(all_tables),
                'pages_processed': successful_pages,
                'total_pages': len(images),
                'total_chunks': total_chunks,
                'structure': 'smart_chunking',
                'success_rate': successful_pages / len(images) if images else 0,
                'avg_chunks_per_page': total_chunks / successful_pages if successful_pages > 0 else 0
            }
            
        except Exception as e:
            logger.error(f"Smart analysis failed: {e}")
            return {'vlm_available': False, 'tables': [], 'structure': 'error'}
    
    def _analyze_page_smart(self, image: Image.Image, page_num: int) -> Tuple[List[Dict], int]:
        """
        Smart –∞–Ω–∞–ª–∏–∑ —Å—Ç—Ä–∞–Ω–∏—Ü—ã —Å —É–º–Ω—ã–º —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ–º –Ω–∞ —á–∞–Ω–∫–∏
        """
        try:
            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è
            if not self._validate_image_smart(image, page_num):
                return [], 0
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω—É–∂–µ–Ω –ª–∏ —á–∞–Ω–∫–∏–Ω–≥ —Å –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω—ã–º –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ–º
            inputs = self.layout_processor(
                image, 
                return_tensors="pt",
                max_length=self.max_tokens,
                truncation=True,
                padding=True
            )
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–ª–∏–Ω—É —Ç–æ–∫–µ–Ω–æ–≤
            input_ids = inputs.get('input_ids', None)
            if input_ids is not None:
                token_count = input_ids.shape[1]
                
                if token_count <= self.max_tokens:
                    # –°—Ç—Ä–∞–Ω–∏—Ü–∞ –ø–æ–º–µ—â–∞–µ—Ç—Å—è –≤ –ª–∏–º–∏—Ç - –æ–±—ã—á–Ω—ã–π –∞–Ω–∞–ª–∏–∑
                    return self._analyze_single_chunk(inputs, image, page_num, 0)
                else:
                    # –°—Ç—Ä–∞–Ω–∏—Ü–∞ —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω–∞—è - –Ω—É–∂–µ–Ω —á–∞–Ω–∫–∏–Ω–≥
                    return self._analyze_page_chunks(inputs, image, page_num)
            else:
                # Fallback - –æ–±—ã—á–Ω—ã–π –∞–Ω–∞–ª–∏–∑
                return self._analyze_single_chunk(inputs, image, page_num, 0)
            
        except Exception as e:
            logger.error(f"Smart page analysis failed for page {page_num + 1}: {e}")
            return [], 0
    
    def _analyze_single_chunk(self, inputs: Dict, image: Image.Image, page_num: int, chunk_num: int) -> Tuple[List[Dict], int]:
        """–ê–Ω–∞–ª–∏–∑ –æ–¥–Ω–æ–≥–æ —á–∞–Ω–∫–∞"""
        try:
            # –í–∞–ª–∏–¥–∞—Ü–∏—è —Ç–µ–Ω–∑–æ—Ä–æ–≤
            for key, tensor in inputs.items():
                if tensor.numel() == 0:
                    logger.warning(f"Page {page_num + 1}, Chunk {chunk_num}: Empty tensor {key}")
                    return [], 0
                
                if tensor.numel() > 500000:  # 500K —ç–ª–µ–º–µ–Ω—Ç–æ–≤
                    logger.warning(f"Page {page_num + 1}, Chunk {chunk_num}: Tensor too large {key}: {tensor.shape}")
                    return [], 0
            
            # –ü–µ—Ä–µ–º–µ—â–∞–µ–º –Ω–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ
            inputs = {k: v.to(self.device) for k, v in inputs.items()}
            
            # VLM –∞–Ω–∞–ª–∏–∑
            with torch.no_grad():
                outputs = self.layout_model(**inputs)
                predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)
                
                # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
                tables = self._extract_structure_smart(predictions, image, page_num, chunk_num)
                return tables, 1
            
        except RuntimeError as e:
            if "device-side assert triggered" in str(e) or "srcSelectDimSize" in str(e):
                logger.error(f"üõë CUDA assertion failed on page {page_num + 1}, chunk {chunk_num}. Skipping: {e}")
                return [], 0
            raise e
        except Exception as e:
            logger.error(f"Chunk analysis failed for page {page_num + 1}, chunk {chunk_num}: {e}")
            return [], 0
    
    def _analyze_page_chunks(self, inputs: Dict, image: Image.Image, page_num: int) -> Tuple[List[Dict], int]:
        """–ê–Ω–∞–ª–∏–∑ —Å—Ç—Ä–∞–Ω–∏—Ü—ã —Å —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ–º –Ω–∞ —á–∞–Ω–∫–∏"""
        try:
            # –ü—Ä–æ—Å—Ç–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ —á–∞–Ω–∫–∏
            # –í —Ä–µ–∞–ª—å–Ω–æ–π —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ –∑–¥–µ—Å—å –±—ã–ª–∞ –±—ã —Å–ª–æ–∂–Ω–∞—è –ª–æ–≥–∏–∫–∞ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è
            # —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º Bounding Boxes –∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
            
            all_tables = []
            chunks_processed = 0
            
            # –î–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏ - –ø—Ä–æ—Å—Ç–æ–π –∞–Ω–∞–ª–∏–∑
            tables, chunks = self._analyze_single_chunk(inputs, image, page_num, 0)
            all_tables.extend(tables)
            chunks_processed += chunks
            
            logger.info(f"Page {page_num + 1} processed with {chunks_processed} chunks")
            
            return all_tables, chunks_processed
            
        except Exception as e:
            logger.error(f"Page chunks analysis failed for page {page_num + 1}: {e}")
            return [], 0
    
    def _extract_structure_smart(self, predictions: torch.Tensor, image: Image.Image, page_num: int, chunk_num: int) -> List[Dict]:
        """Smart –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã"""
        tables = []
        
        try:
            # Smart –∞–Ω–∞–ª–∏–∑ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
            # –í —Ä–µ–∞–ª—å–Ω–æ–π —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ –∑–¥–µ—Å—å –±—ã–ª–∞ –±—ã —Å–ª–æ–∂–Ω–∞—è –ª–æ–≥–∏–∫–∞
            return tables
            
        except Exception as e:
            logger.error(f"Smart structure extraction failed for page {page_num + 1}, chunk {chunk_num}: {e}")
            return []


def test_smart_vlm():
    """–¢–µ—Å—Ç Smart VLM –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞"""
    print("Testing Smart VLM processor with chunking...")
    
    processor = SmartVLMProcessor(max_tokens=512)
    
    if not processor.is_available():
        print("ERROR: Smart VLM not available")
        return False
    
    # –¢–µ—Å—Ç —Å —Ä–µ–∞–ª—å–Ω—ã–º PDF
    import os
    test_pdf = None
    for root, dirs, files in os.walk("I:/docs/downloaded"):
        for file in files:
            if file.endswith('.pdf'):
                test_pdf = os.path.join(root, file)
                break
        if test_pdf:
            break
    
    if not test_pdf:
        print("ERROR: No PDF files found for testing")
        return False
    
    try:
        # –¢–µ—Å—Ç –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏
        images = processor.convert_pdf_to_images_smart(test_pdf)
        print(f"SUCCESS: Converted {len(images)} pages")
        
        # –¢–µ—Å—Ç –∞–Ω–∞–ª–∏–∑–∞
        result = processor.analyze_document_structure_smart(test_pdf)
        print(f"SUCCESS: Analysis completed - {result['total_tables']} tables")
        print(f"Pages: {result['pages_processed']}/{result['total_pages']}, Chunks: {result['total_chunks']}")
        print(f"Success rate: {result['success_rate']:.2%}, Avg chunks per page: {result['avg_chunks_per_page']:.1f}")
        
        return True
        
    except Exception as e:
        print(f"ERROR: Test failed: {e}")
        return False


if __name__ == "__main__":
    success = test_smart_vlm()
    if success:
        print("SUCCESS: Smart VLM processor works!")
    else:
        print("FAILED: Smart VLM processor failed!")
