#!/usr/bin/env python3
"""
ENTERPRISE RAG 3.0: VLM GPU Test Script
–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Ä–∞–±–æ—Ç—É VLM —Å GPU —É—Å–∫–æ—Ä–µ–Ω–∏–µ–º
"""

import torch
import logging
from vlm_processor import VLMProcessor

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def test_gpu_availability():
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å GPU"""
    
    logger.info("üîç Testing GPU availability...")
    
    # CUDA
    if torch.cuda.is_available():
        logger.info(f"üöÄ CUDA available: {torch.cuda.get_device_name(0)}")
        logger.info(f"üìä CUDA version: {torch.version.cuda}")
        logger.info(f"üíæ GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
        return "cuda"
    
    # MPS (Apple Silicon)
    elif torch.backends.mps.is_available():
        logger.info("üçé MPS (Apple Silicon) available")
        return "mps"
    
    else:
        logger.warning("‚ö†Ô∏è No GPU acceleration available, using CPU")
        return "cpu"

def test_vlm_processor():
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç VLM –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä"""
    
    logger.info("üß† Testing VLM processor...")
    
    try:
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è VLM
        vlm = VLMProcessor(device="auto")
        
        if vlm.is_available():
            logger.info("‚úÖ VLM processor is ready!")
            
            # –¢–µ—Å—Ç–∏—Ä—É–µ–º –º–æ–¥–µ–ª–∏
            logger.info("üîç Testing BLIP model...")
            if vlm.blip_model is not None:
                logger.info("‚úÖ BLIP model loaded")
            else:
                logger.warning("‚ö†Ô∏è BLIP model not loaded")
            
            logger.info("üîç Testing LayoutLMv3 model...")
            if vlm.layout_model is not None:
                logger.info("‚úÖ LayoutLMv3 model loaded")
            else:
                logger.warning("‚ö†Ô∏è LayoutLMv3 model not loaded")
            
            return True
        else:
            logger.error("‚ùå VLM processor not available")
            return False
            
    except Exception as e:
        logger.error(f"‚ùå VLM test failed: {e}")
        return False

def test_gpu_memory():
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç GPU –ø–∞–º—è—Ç—å"""
    
    if torch.cuda.is_available():
        logger.info("üíæ Testing GPU memory...")
        
        # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø–∞–º—è—Ç–∏
        total_memory = torch.cuda.get_device_properties(0).total_memory
        allocated_memory = torch.cuda.memory_allocated(0)
        cached_memory = torch.cuda.memory_reserved(0)
        
        logger.info(f"üìä Total GPU memory: {total_memory / 1024**3:.1f} GB")
        logger.info(f"üìä Allocated memory: {allocated_memory / 1024**3:.1f} GB")
        logger.info(f"üìä Cached memory: {cached_memory / 1024**3:.1f} GB")
        logger.info(f"üìä Free memory: {(total_memory - allocated_memory) / 1024**3:.1f} GB")
        
        # –¢–µ—Å—Ç–∏—Ä—É–µ–º –≤—ã–¥–µ–ª–µ–Ω–∏–µ –ø–∞–º—è—Ç–∏
        try:
            test_tensor = torch.randn(1000, 1000).cuda()
            logger.info("‚úÖ GPU memory allocation test passed")
            del test_tensor
            torch.cuda.empty_cache()
            return True
        except Exception as e:
            logger.error(f"‚ùå GPU memory test failed: {e}")
            return False
    
    return True

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"""
    
    logger.info("üöÄ ENTERPRISE RAG 3.0: VLM GPU Test")
    
    # –¢–µ—Å—Ç 1: GPU –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å
    device = test_gpu_availability()
    
    # –¢–µ—Å—Ç 2: GPU –ø–∞–º—è—Ç—å
    if device == "cuda":
        test_gpu_memory()
    
    # –¢–µ—Å—Ç 3: VLM –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä
    vlm_success = test_vlm_processor()
    
    # –ò—Ç–æ–≥–æ–≤—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
    logger.info("üìä Test Results:")
    logger.info(f"   Device: {device}")
    logger.info(f"   VLM Ready: {'‚úÖ' if vlm_success else '‚ùå'}")
    
    if vlm_success:
        logger.info("üéâ VLM with GPU acceleration is ready!")
        logger.info("üí° You can now use VLM features in your RAG trainer")
    else:
        logger.warning("‚ö†Ô∏è VLM not fully ready, but fallback mode will work")
        logger.info("üí° RAG trainer will work without VLM features")

if __name__ == "__main__":
    main()
