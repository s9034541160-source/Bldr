"""
üá∑üá∫ –†–æ—Å—Å–∏–π—Å–∫–∏–π LLM –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä –¥–ª—è RAG –ø–∞–π–ø–ª–∞–π–Ω–∞
–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è YaLM/GigaChat –¥–ª—è –≥–ª—É–±–æ–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ —Ä—É—Å—Å–∫–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
"""

import logging
import requests
import json
import time
from typing import Dict, List, Any, Optional
from dataclasses import dataclass

logger = logging.getLogger(__name__)

@dataclass
class RussianLLMConfig:
    """–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Ä–æ—Å—Å–∏–π—Å–∫–æ–≥–æ LLM"""
    provider: str = "yalm"  # yalm, gigachat, rut5
    api_key: str = ""
    base_url: str = ""
    model_name: str = ""
    max_tokens: int = 2048
    temperature: float = 0.1
    timeout: int = 30

class RussianLLMProcessor:
    """
    –†–æ—Å—Å–∏–π—Å–∫–∏–π LLM –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä –¥–ª—è –≥–ª—É–±–æ–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç YaLM, GigaChat, RuT5
    """
    
    def __init__(self, config: RussianLLMConfig):
        self.config = config
        self.logger = logging.getLogger(__name__)
        self._validate_config()
    
    def _validate_config(self):
        """–í–∞–ª–∏–¥–∞—Ü–∏—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏"""
        if not self.config.api_key:
            raise ValueError("API –∫–ª—é—á –Ω–µ —É–∫–∞–∑–∞–Ω")
        
        if self.config.provider not in ["yalm", "gigachat", "rut5"]:
            raise ValueError(f"–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π –ø—Ä–æ–≤–∞–π–¥–µ—Ä: {self.config.provider}")
    
    def analyze_document_structure(self, content: str, vlm_metadata: Dict) -> Dict:
        """
        –ì–ª—É–±–æ–∫–∏–π –∞–Ω–∞–ª–∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–æ–∫—É–º–µ–Ω—Ç–∞ —Å –ø–æ–º–æ—â—å—é —Ä–æ—Å—Å–∏–π—Å–∫–æ–≥–æ LLM
        
        Args:
            content: –¢–µ–∫—Å—Ç –¥–æ–∫—É–º–µ–Ω—Ç–∞
            vlm_metadata: –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –æ—Ç VLM –∞–Ω–∞–ª–∏–∑–∞
            
        Returns:
            Dict —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –∞–Ω–∞–ª–∏–∑–∞
        """
        try:
            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –ø—Ä–æ–º–ø—Ç –¥–ª—è —Ä–æ—Å—Å–∏–π—Å–∫–æ–≥–æ LLM
            prompt = self._prepare_analysis_prompt(content, vlm_metadata)
            
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å –∫ LLM
            response = self._send_llm_request(prompt)
            
            # –ü–∞—Ä—Å–∏–º –æ—Ç–≤–µ—Ç
            analysis_result = self._parse_llm_response(response)
            
            return {
                'russian_llm_available': True,
                'analysis': analysis_result,
                'provider': self.config.provider,
                'model': self.config.model_name,
                'tokens_used': response.get('usage', {}).get('total_tokens', 0)
            }
            
        except Exception as e:
            self.logger.error(f"Russian LLM analysis failed: {e}")
            return {
                'russian_llm_available': False,
                'error': str(e),
                'fallback_to_vlm': True
            }
    
    def _prepare_analysis_prompt(self, content: str, vlm_metadata: Dict) -> str:
        """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø—Ä–æ–º–ø—Ç–∞ –¥–ª—è —Ä–æ—Å—Å–∏–π—Å–∫–æ–≥–æ LLM"""
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ—Ç VLM
        vlm_tables = vlm_metadata.get('tables', [])
        vlm_sections = vlm_metadata.get('sections', [])
        
        prompt = f"""
–¢—ã - —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –∞–Ω–∞–ª–∏–∑—É —Å—Ç—Ä–æ–∏—Ç–µ–ª—å–Ω–æ–π –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Å–ª–µ–¥—É—é—â–∏–π –¥–æ–∫—É–º–µ–Ω—Ç –∏ –∏–∑–≤–ª–µ–∫–∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é.

–î–û–ö–£–ú–ï–ù–¢:
{content[:3000]}...

VLM –ê–ù–ê–õ–ò–ó (–ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—ã–π):
- –¢–∞–±–ª–∏—Ü—ã: {len(vlm_tables)}
- –°–µ–∫—Ü–∏–∏: {len(vlm_sections)}

–ó–ê–î–ê–ß–ò:
1. –û–ø—Ä–µ–¥–µ–ª–∏ —Ç–∏–ø –¥–æ–∫—É–º–µ–Ω—Ç–∞ (–°–ù–∏–ü, –ì–û–°–¢, –ü–ü–†, —Å–º–µ—Ç–∞, –ø—Ä–æ–µ–∫—Ç)
2. –ò–∑–≤–ª–µ–∫–∏ –æ—Å–Ω–æ–≤–Ω—ã–µ —Ä–∞–∑–¥–µ–ª—ã –∏ –ø–æ–¥—Ä–∞–∑–¥–µ–ª—ã
3. –ù–∞–π–¥–∏ —Ç–∞–±–ª–∏—Ü—ã –∏ –∏—Ö —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ
4. –í—ã–¥–µ–ª–∏ –∫–ª—é—á–µ–≤—ã–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –∏ –Ω–æ—Ä–º—ã
5. –û–ø—Ä–µ–¥–µ–ª–∏ –ø—Ä–∏–º–µ–Ω–∏–º–æ—Å—Ç—å –∏ –æ–±–ª–∞—Å—Ç—å –¥–µ–π—Å—Ç–≤–∏—è

–§–û–†–ú–ê–¢ –û–¢–í–ï–¢–ê (JSON):
{{
    "document_type": "—Ç–∏–ø –¥–æ–∫—É–º–µ–Ω—Ç–∞",
    "sections": [
        {{
            "title": "–Ω–∞–∑–≤–∞–Ω–∏–µ —Ä–∞–∑–¥–µ–ª–∞",
            "content": "—Å–æ–¥–µ—Ä–∂–∏–º–æ–µ",
            "level": 1
        }}
    ],
    "tables": [
        {{
            "title": "–Ω–∞–∑–≤–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü—ã",
            "data": "–¥–∞–Ω–Ω—ã–µ —Ç–∞–±–ª–∏—Ü—ã"
        }}
    ],
    "requirements": [
        "–∫–ª—é—á–µ–≤–æ–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–µ 1",
        "–∫–ª—é—á–µ–≤–æ–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–µ 2"
    ],
    "scope": "–æ–±–ª–∞—Å—Ç—å –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è"
}}

–û—Ç–≤–µ—á–∞–π —Ç–æ–ª—å–∫–æ JSON, –±–µ–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞.
"""
        return prompt
    
    def _send_llm_request(self, prompt: str) -> Dict:
        """–û—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –∫ —Ä–æ—Å—Å–∏–π—Å–∫–æ–º—É LLM"""
        
        if self.config.provider == "yalm":
            return self._send_yalm_request(prompt)
        elif self.config.provider == "gigachat":
            return self._send_gigachat_request(prompt)
        elif self.config.provider == "rut5":
            return self._send_rut5_request(prompt)
        else:
            raise ValueError(f"–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π –ø—Ä–æ–≤–∞–π–¥–µ—Ä: {self.config.provider}")
    
    def _send_yalm_request(self, prompt: str) -> Dict:
        """–ó–∞–ø—Ä–æ—Å –∫ YaLM API"""
        url = f"{self.config.base_url}/v1/chat/completions"
        
        headers = {
            "Authorization": f"Bearer {self.config.api_key}",
            "Content-Type": "application/json"
        }
        
        data = {
            "model": self.config.model_name,
            "messages": [
                {"role": "user", "content": prompt}
            ],
            "max_tokens": self.config.max_tokens,
            "temperature": self.config.temperature
        }
        
        response = requests.post(
            url, 
            headers=headers, 
            json=data, 
            timeout=self.config.timeout
        )
        
        if response.status_code != 200:
            raise Exception(f"YaLM API error: {response.status_code} - {response.text}")
        
        return response.json()
    
    def _send_gigachat_request(self, prompt: str) -> Dict:
        """–ó–∞–ø—Ä–æ—Å –∫ GigaChat API"""
        # –†–µ–∞–ª–∏–∑–∞—Ü–∏—è –¥–ª—è GigaChat API
        # (—Ç—Ä–µ–±—É–µ—Ç —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—É—é –Ω–∞—Å—Ç—Ä–æ–π–∫—É –¥–ª—è –°–±–µ—Ä–∞)
        pass
    
    def _send_rut5_request(self, prompt: str) -> Dict:
        """–ó–∞–ø—Ä–æ—Å –∫ RuT5 (–ª–æ–∫–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å)"""
        # –†–µ–∞–ª–∏–∑–∞—Ü–∏—è –¥–ª—è –ª–æ–∫–∞–ª—å–Ω–æ–π RuT5 –º–æ–¥–µ–ª–∏
        # (—Ç—Ä–µ–±—É–µ—Ç —É—Å—Ç–∞–Ω–æ–≤–∫–∏ transformers)
        pass
    
    def _parse_llm_response(self, response: Dict) -> Dict:
        """–ü–∞—Ä—Å–∏–Ω–≥ –æ—Ç–≤–µ—Ç–∞ –æ—Ç LLM"""
        try:
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç –æ—Ç–≤–µ—Ç–∞
            if 'choices' in response and len(response['choices']) > 0:
                content = response['choices'][0]['message']['content']
            else:
                raise ValueError("–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞ –æ—Ç LLM")
            
            # –ü–∞—Ä—Å–∏–º JSON
            analysis = json.loads(content)
            return analysis
            
        except json.JSONDecodeError as e:
            self.logger.error(f"Failed to parse LLM response as JSON: {e}")
            return {"error": "Failed to parse LLM response"}
        except Exception as e:
            self.logger.error(f"Failed to parse LLM response: {e}")
            return {"error": str(e)}

# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
if __name__ == "__main__":
    # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–ª—è YaLM
    config = RussianLLMConfig(
        provider="yalm",
        api_key="your-yalm-api-key",
        base_url="https://api.yalm.ru",
        model_name="yalm-30b",
        max_tokens=2048
    )
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞
    processor = RussianLLMProcessor(config)
    
    # –¢–µ—Å—Ç–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑
    test_content = "–≠—Ç–æ —Ç–µ—Å—Ç–æ–≤—ã–π –¥–æ–∫—É–º–µ–Ω—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã."
    vlm_metadata = {"tables": [], "sections": []}
    
    result = processor.analyze_document_structure(test_content, vlm_metadata)
    print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞: {result}")
