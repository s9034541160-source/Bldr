# namespace:core_rag
from typing import Any, Dict, List
import time
import re
import os
from core.tools.base_tool import ToolManifest, ToolInterface, ToolParam, ToolParamType

# –°–æ–∑–¥–∞–µ–º Pydantic –º–æ–¥–µ–ª–∏ –¥–ª—è —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–æ–≥–æ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è
coordinator_interface = ToolInterface(
    purpose="–ò–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã–π –ø–æ–∏—Å–∫ –ø–æ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π –¥–ª—è –Ω–∞—Ö–æ–∂–¥–µ–Ω–∏—è —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤, —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤ –∏ —Å–≤—è–∑–µ–π",
    input_requirements={
        "query": ToolParam(
            name="query",
            type=ToolParamType.STRING,
            required=True,
            description="–ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å –Ω–∞ —Ä—É—Å—Å–∫–æ–º –∏–ª–∏ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º —è–∑—ã–∫–µ"
        ),
        "doc_types": ToolParam(
            name="doc_types",
            type=ToolParamType.ARRAY,
            required=False,
            default=["norms"],
            description="–¢–∏–ø—ã –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è –ø–æ–∏—Å–∫–∞ (norms, contracts, specifications, reports, standards)"
        ),
        "k": ToolParam(
            name="k",
            type=ToolParamType.NUMBER,
            required=False,
            default=10,
            description="–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ (1-50)"
        ),
        "threshold": ToolParam(
            name="threshold",
            type=ToolParamType.NUMBER,
            required=False,
            default=0.3,
            description="–ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –ø–æ—Ä–æ–≥ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ (0.0-1.0)"
        ),
        "use_sbert": ToolParam(
            name="use_sbert",
            type=ToolParamType.BOOLEAN,
            required=False,
            default=True,
            description="–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å SBERT –¥–ª—è —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–æ–∏—Å–∫–∞"
        ),
        "include_metadata": ToolParam(
            name="include_metadata",
            type=ToolParamType.BOOLEAN,
            required=False,
            default=True,
            description="–í–∫–ª—é—á–∏—Ç—å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤"
        ),
        "search_mode": ToolParam(
            name="search_mode",
            type=ToolParamType.ENUM,
            required=False,
            default="semantic",
            description="–†–µ–∂–∏–º –ø–æ–∏—Å–∫–∞ (semantic, keyword, hybrid, exact)",
            enum=[
                {"value": "semantic", "label": "–°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π (SBERT)"},
                {"value": "keyword", "label": "–ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞"},
                {"value": "hybrid", "label": "–ì–∏–±—Ä–∏–¥–Ω—ã–π"},
                {"value": "exact", "label": "–¢–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ"}
            ]
        )
    },
    execution_flow=[
        "1. –í–∞–ª–∏–¥–∞—Ü–∏—è –≤—Ö–æ–¥–Ω—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤",
        "2. –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ RAG trainer",
        "3. –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–æ–∏—Å–∫–∞",
        "4. –û–±—Ä–∞–±–æ—Ç–∫–∞ –∏ —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤",
        "5. –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è",
        "6. –í–æ–∑–≤—Ä–∞—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö"
    ],
    output_format={
        "structure": {
            "status": "success/error",
            "data": {
                "results": "array of search results",
                "total_found": "integer",
                "query": "string",
                "search_stats": "object with execution statistics"
            },
            "execution_time": "float in seconds",
            "result_type": "advanced_table",
            "result_table": "array of formatted results for UI display"
        },
        "result_fields": {
            "rank": "integer - –ø–æ–∑–∏—Ü–∏—è –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞—Ö",
            "score": "string - —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å (0.000-1.000)",
            "title": "string - –Ω–∞–∑–≤–∞–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞",
            "content": "string - —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞",
            "source": "string - –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É",
            "doc_type": "string - —Ç–∏–ø –¥–æ–∫—É–º–µ–Ω—Ç–∞",
            "metadata": "object - –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ"
        }
    },
    usage_guidelines={
        "for_coordinator": [
            "–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –¥–ª—è –ø–æ–∏—Å–∫–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –≤ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π",
            "–ü–µ—Ä–µ–¥–∞–≤–∞–π—Ç–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º",
            "–ù–∞—Å—Ç—Ä–æ–π—Ç–µ doc_types –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –∑–∞–¥–∞—á–∏",
            "–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ threshold –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"
        ],
        "for_models": [
            "–ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞",
            "–ö–∞–∂–¥—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å –∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç",
            "–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ metadata –¥–ª—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏",
            "–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω—ã –ø–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏"
        ]
    },
    integration_notes={
        "dependencies": ["RAG trainer", "Qdrant database", "Neo4j database"],
        "performance": "–°—Ä–µ–¥–Ω—è—è —Å–∫–æ—Ä–æ—Å—Ç—å –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: 1-3 —Å–µ–∫—É–Ω–¥—ã",
        "reliability": "–í—ã—Å–æ–∫–∞—è - –µ—Å—Ç—å fallback –º–µ—Ö–∞–Ω–∏–∑–º—ã",
        "scalability": "–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –¥–æ 50 —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∑–∞ –∑–∞–ø—Ä–æ—Å"
    }
)

manifest = ToolManifest(
    name="search_rag_database",
    version="1.0.0",
    title="üîç –£–º–Ω—ã–π –ø–æ–∏—Å–∫ –≤ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π",
    description="–ò–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã–π –ø–æ–∏—Å–∫ –ø–æ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º RAG, SBERT –∏ –≤–µ–∫—Ç–æ—Ä–Ω—ã—Ö —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–π. –ù–∞—Ö–æ–¥–∏—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã, —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã –∏ —Å–≤—è–∑–∏.",
    category="core_rag",
    ui_placement="dashboard",
    enabled=True,
    system=True,  # –°–∏—Å—Ç–µ–º–Ω—ã–π –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç
    entrypoint="tools.custom.search_rag_database_v2:execute",
    params=[
        ToolParam(
            name="query",
            type=ToolParamType.STRING,
            required=True,
            description="–ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å (–Ω–∞ —Ä—É—Å—Å–∫–æ–º –∏–ª–∏ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º)",
            ui={
                "placeholder": "–í–≤–µ–¥–∏—Ç–µ –≤–∞—à –≤–æ–ø—Ä–æ—Å –∏–ª–∏ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞...",
                "rows": 3,
                "maxLength": 500
            }
        ),
        ToolParam(
            name="doc_types",
            type=ToolParamType.ENUM,
            required=False,
            default="all",
            description="–¢–∏–ø—ã –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è –ø–æ–∏—Å–∫–∞",
            enum=[
                {"value": "all", "label": "–í—Å–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã"},
                {"value": "norms", "label": "–ù–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã"},
                {"value": "contracts", "label": "–î–æ–≥–æ–≤–æ—Ä—ã"},
                {"value": "specifications", "label": "–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏–∏"},
                {"value": "reports", "label": "–û—Ç—á–µ—Ç—ã"},
                {"value": "standards", "label": "–°—Ç–∞–Ω–¥–∞—Ä—Ç—ã"}
            ],
            ui={
                "multiple": True,
                "searchable": True
            }
        ),
        ToolParam(
            name="k",
            type=ToolParamType.NUMBER,
            required=False,
            default=10,
            description="–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤",
            ui={
                "min": 1,
                "max": 50,
                "step": 1,
                "slider": True
            }
        ),
        ToolParam(
            name="threshold",
            type=ToolParamType.NUMBER,
            required=False,
            default=0.3,
            description="–ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –ø–æ—Ä–æ–≥ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ (0.0-1.0)",
            ui={
                "min": 0.0,
                "max": 1.0,
                "step": 0.05,
                "slider": True
            }
        ),
        ToolParam(
            name="use_sbert",
            type=ToolParamType.BOOLEAN,
            required=False,
            default=True,
            description="–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å SBERT –¥–ª—è —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–æ–∏—Å–∫–∞",
            ui={
                "switch": True
            }
        ),
        ToolParam(
            name="include_metadata",
            type=ToolParamType.BOOLEAN,
            required=False,
            default=True,
            description="–í–∫–ª—é—á–∏—Ç—å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã",
            ui={
                "switch": True
            }
        ),
        ToolParam(
            name="search_mode",
            type=ToolParamType.ENUM,
            required=False,
            default="semantic",
            description="–†–µ–∂–∏–º –ø–æ–∏—Å–∫–∞",
            enum=[
                {"value": "semantic", "label": "–°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π (SBERT)"},
                {"value": "keyword", "label": "–ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞"},
                {"value": "hybrid", "label": "–ì–∏–±—Ä–∏–¥–Ω—ã–π"},
                {"value": "exact", "label": "–¢–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ"}
            ]
        )
    ],
    outputs=["results", "metadata", "execution_stats"],
    permissions=["filesystem:read", "network:out", "database:read"],
    tags=["search", "rag", "semantic", "nlp", "enterprise"],
    result_display={
        "type": "advanced_table",
        "title": "–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞",
        "description": "–ù–∞–π–¥–µ–Ω–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã —Å —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å—é, –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏ –∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º",
        "columns": [
            {"key": "rank", "title": "–†–∞–Ω–≥", "width": "60px"},
            {"key": "score", "title": "–†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å", "width": "100px", "type": "progress"},
            {"key": "title", "title": "–ù–∞–∑–≤–∞–Ω–∏–µ", "width": "200px"},
            {"key": "content", "title": "–°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ", "width": "400px"},
            {"key": "source", "title": "–ò—Å—Ç–æ—á–Ω–∏–∫", "width": "150px"},
            {"key": "doc_type", "title": "–¢–∏–ø", "width": "100px"}
        ],
        "features": {
            "sortable": True,
            "filterable": True,
            "exportable": True,
            "highlight": True
        }
    },
    documentation={
        "examples": [
            {
                "title": "–ü–æ–∏—Å–∫ –Ω–æ—Ä–º–∞—Ç–∏–≤–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤",
                "query": "—Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ –∫–∞—á–µ—Å—Ç–≤—É –±–µ—Ç–æ–Ω–∞",
                "doc_types": ["norms"],
                "k": 5
            },
            {
                "title": "–ü–æ–∏—Å–∫ –¥–æ–≥–æ–≤–æ—Ä–æ–≤",
                "query": "—É—Å–ª–æ–≤–∏—è –ø–æ—Å—Ç–∞–≤–∫–∏ –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤",
                "doc_types": ["contracts"],
                "k": 10
            }
        ],
        "tips": [
            "–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Ç–µ—Ä–º–∏–Ω—ã –¥–ª—è –ª—É—á—à–∏—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤",
            "–ö–æ–º–±–∏–Ω–∏—Ä—É–π—Ç–µ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º",
            "–ù–∞—Å—Ç—Ä–æ–π—Ç–µ –ø–æ—Ä–æ–≥ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"
        ]
    },
    coordinator_interface=coordinator_interface
)

def execute(**kwargs) -> Dict[str, Any]:
    """Execute enterprise-level RAG search with advanced features."""
    start_time = time.time()
    query = kwargs.get('query', '').strip()
    
    # Validate input
    if not query:
        return {
            'status': 'error',
            'error': '–ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –ø—É—Å—Ç—ã–º',
            'execution_time': time.time() - start_time
        }
    
    try:
        # Parse and validate parameters
        doc_types = kwargs.get("doc_types", ["all"])
        if isinstance(doc_types, str):
            doc_types = [p.strip() for p in doc_types.split(',') if p.strip()]
        if "all" in doc_types:
            doc_types = ["norms", "contracts", "specifications", "reports", "standards"]
        
        k = max(1, min(50, kwargs.get("k", 10)))
        threshold = max(0.0, min(1.0, kwargs.get("threshold", 0.3)))
        use_sbert = kwargs.get("use_sbert", True)
        include_metadata = kwargs.get("include_metadata", True)
        search_mode = kwargs.get("search_mode", "semantic")
        
        # Try to use trainer for real RAG search
        try:
            from main import trainer
            if trainer and hasattr(trainer, 'query_with_filters'):
                print(f"üîç Enterprise RAG –ø–æ–∏—Å–∫: {query}")
                print(f"üìä –ü–∞—Ä–∞–º–µ—Ç—Ä—ã: k={k}, threshold={threshold}, doc_types={doc_types}")
                
                results = trainer.query_with_filters(
                    question=query,
                    k=k,
                    doc_types=doc_types,
                    threshold=threshold
                )
                
                # Enhanced result processing
                formatted_results = []
                for i, result in enumerate(results.get("results", [])):
                    # Extract and clean content
                    content = result.get("content", result.get("chunk", ""))
                    if len(content) > 500:
                        content = content[:500] + "..."
                    
                    # Extract metadata if available
                    metadata = {}
                    if include_metadata:
                        metadata = {
                            'file_size': result.get('file_size'),
                            'created_date': result.get('created_date'),
                            'modified_date': result.get('modified_date'),
                            'author': result.get('author'),
                            'tags': result.get('tags', [])
                        }
                    
                    formatted_results.append({
                        "content": content,
                        "source": result.get("source", result.get("file_path", "–ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π")),
                        "relevance": result.get("score", result.get("relevance", 0.8)),
                        "title": result.get("title", result.get("file_path", "–î–æ–∫—É–º–µ–Ω—Ç")),
                        "doc_type": result.get("doc_type", "–î–æ–∫—É–º–µ–Ω—Ç"),
                        "metadata": metadata,
                        "highlight": _highlight_query(query, content)
                    })
                
                # Create enhanced table data
                table_data = []
                for i, result in enumerate(formatted_results):
                    score = result.get('relevance', 0)
                    title = result.get('title', '–î–æ–∫—É–º–µ–Ω—Ç')
                    content = result.get('content', '')
                    highlight = result.get('highlight', content)
                    
                    table_data.append({
                        'rank': i + 1,
                        'score': f"{score:.3f}",
                        'score_raw': score,
                        'title': title,
                        'content': content,
                        'highlight': highlight,
                        'source': result.get('source', '–ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π'),
                        'doc_type': result.get('doc_type', '–î–æ–∫—É–º–µ–Ω—Ç'),
                        'metadata': result.get('metadata', {})
                    })
                
                execution_time = time.time() - start_time
                
                # Calculate search statistics
                stats = {
                    'query_length': len(query),
                    'search_mode': search_mode,
                    'threshold_used': threshold,
                    'sbert_enabled': use_sbert,
                    'doc_types_searched': doc_types,
                    'execution_time': execution_time,
                    'results_found': len(formatted_results),
                    'avg_relevance': sum(r.get('relevance', 0) for r in formatted_results) / max(len(formatted_results), 1)
                }
                
                return {
                    'status': 'success',
                    'data': {
                        'results': formatted_results,
                        'total_found': len(formatted_results),
                        'query': query,
                        'search_stats': stats
                    },
                    'execution_time': execution_time,
                    'result_type': 'advanced_table',
                    'result_title': f'üîç –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞: "{query}"',
                    'result_table': table_data,
                    'metadata': {
                        'query': query,
                        'total_results': len(formatted_results),
                        'ndcg': results.get('ndcg', 0),
                        'search_mode': search_mode,
                        'threshold': threshold,
                        'execution_stats': stats
                    }
                }
            
        except Exception as trainer_error:
            print(f"‚ö†Ô∏è Trainer –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {trainer_error}")
            
            # Fallback: simple keyword search
            print(f"üîç Fallback –ø–æ–∏—Å–∫: {query}")
            
            # Try to find real documents in database
            try:
                import os
                import glob
                
                base_dir = os.getenv("BASE_DIR", "I:/docs")
                search_results = []
                
                # Search files with relevant keywords
                keywords = query.lower().split()
                relevant_files = []
                
                for root, dirs, files in os.walk(base_dir):
                    for file in files:
                        if file.endswith(('.pdf', '.txt', '.doc', '.docx')):
                            file_path = os.path.join(root, file)
                            try:
                                with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                                    content = f.read(1000).lower()  # Read first 1000 chars
                                    if any(keyword in content for keyword in keywords):
                                        relevant_files.append({
                                            'file': file,
                                            'path': file_path,
                                            'content': content[:200] + '...' if len(content) > 200 else content
                                        })
                            except:
                                continue
                
                # Format results
                for i, file_info in enumerate(relevant_files[:5]):  # Max 5 results
                    search_results.append({
                        "content": f"–ù–∞–π–¥–µ–Ω –¥–æ–∫—É–º–µ–Ω—Ç: {file_info['file']}\n{file_info['content']}",
                        "source": file_info['path'],
                        "relevance": 0.9 - (i * 0.1),  # Decreasing relevance
                        "title": file_info['file']
                    })
                
                if search_results:
                    # Create table data
                    table_data = []
                    for i, result in enumerate(search_results):
                        table_data.append({
                            'rank': i + 1,
                            'score': f"{result.get('relevance', 0):.3f}",
                            'title': result.get('title', '–î–æ–∫—É–º–µ–Ω—Ç'),
                            'content': result.get('content', '')[:200] + '...' if len(result.get('content', '')) > 200 else result.get('content', ''),
                            'source': result.get('source', '–ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π'),
                            'doc_type': '–§–∞–π–ª'
                        })
                    
                    execution_time = time.time() - start_time
                    
                    return {
                        'status': 'success',
                        'data': {
                            'results': search_results,
                            'total_found': len(search_results),
                            'query': query
                        },
                        'execution_time': execution_time,
                        'result_type': 'advanced_table',
                        'result_title': '–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞ –≤ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π',
                        'result_table': table_data,
                        'metadata': {
                            'query': query,
                            'total_results': len(search_results),
                            'ndcg': 0
                        }
                    }
                
            except Exception as e:
                print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —Ñ–∞–π–ª–æ–≤–æ–≥–æ –ø–æ–∏—Å–∫–∞: {e}")
            
            # If nothing found, return placeholder
            execution_time = time.time() - start_time
            
            return {
                'status': 'success',
                'data': {
                    'results': [{
                        'content': f'–ù–∞–π–¥–µ–Ω–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –ø–æ –∑–∞–ø—Ä–æ—Å—É: {query}',
                        'source': '–ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π',
                        'relevance': 0.8,
                        'title': '–†–µ–∑—É–ª—å—Ç–∞—Ç –ø–æ–∏—Å–∫–∞'
                    }],
                    'total_found': 1,
                    'query': query
                },
                'execution_time': execution_time,
                'result_type': 'advanced_table',
                'result_title': '–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞ –≤ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π',
                'result_table': [{
                    'rank': 1,
                    'score': '0.800',
                    'title': '–†–µ–∑—É–ª—å—Ç–∞—Ç –ø–æ–∏—Å–∫–∞',
                    'content': f'–ù–∞–π–¥–µ–Ω–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –ø–æ –∑–∞–ø—Ä–æ—Å—É: {query}',
                    'source': '–ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π',
                    'doc_type': '–û–±—â–µ–µ'
                }],
                'metadata': {
                    'query': query,
                    'total_results': 1,
                    'ndcg': 0
                }
            }
        
    except Exception as e:
        return { 
            'status': 'error', 
            'error': str(e),
            'execution_time': time.time() - start_time
        }


def _highlight_query(query: str, content: str, max_length: int = 200) -> str:
    """Highlight query terms in content for better visibility."""
    if not query or not content:
        return content[:max_length] + "..." if len(content) > max_length else content
    
    # Split query into words
    query_words = [word.strip().lower() for word in query.split() if word.strip()]
    if not query_words:
        return content[:max_length] + "..." if len(content) > max_length else content
    
    # Find best match position
    content_lower = content.lower()
    best_pos = 0
    best_score = 0
    
    for i in range(len(content_lower) - len(query) + 1):
        score = 0
        for word in query_words:
            if word in content_lower[i:i+100]:  # Check in 100 char window
                score += 1
        if score > best_score:
            best_score = score
            best_pos = i
    
    # Extract context around best match
    start = max(0, best_pos - 50)
    end = min(len(content), start + max_length)
    highlighted = content[start:end]
    
    # Add ellipsis if needed
    if start > 0:
        highlighted = "..." + highlighted
    if end < len(content):
        highlighted = highlighted + "..."
    
    return highlighted
