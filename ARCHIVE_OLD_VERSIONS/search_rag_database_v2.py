# namespace:core_rag
from typing import Any, Dict, List
import time
import re
import os
from core.tools.base_tool import ToolManifest, ToolInterface, ToolParam, ToolParamType

# Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ Pydantic Ð¼Ð¾Ð´ÐµÐ»Ð¸ Ð´Ð»Ñ ÑƒÐ½Ð¸Ð²ÐµÑ€ÑÐ°Ð»ÑŒÐ½Ð¾Ð³Ð¾ Ð¿Ñ€ÐµÐ´ÑÑ‚Ð°Ð²Ð»ÐµÐ½Ð¸Ñ
coordinator_interface = ToolInterface(
    purpose="Ð˜Ð½Ñ‚ÐµÐ»Ð»ÐµÐºÑ‚ÑƒÐ°Ð»ÑŒÐ½Ñ‹Ð¹ Ð¿Ð¾Ð¸ÑÐº Ð¿Ð¾ Ð±Ð°Ð·Ðµ Ð·Ð½Ð°Ð½Ð¸Ð¹ Ð´Ð»Ñ Ð½Ð°Ñ…Ð¾Ð¶Ð´ÐµÐ½Ð¸Ñ Ñ€ÐµÐ»ÐµÐ²Ð°Ð½Ñ‚Ð½Ñ‹Ñ… Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð¾Ð², Ñ„Ñ€Ð°Ð³Ð¼ÐµÐ½Ñ‚Ð¾Ð² Ð¸ ÑÐ²ÑÐ·ÐµÐ¹",
    input_requirements={
        "query": ToolParam(
            name="query",
            type=ToolParamType.STRING,
            required=True,
            description="ÐŸÐ¾Ð¸ÑÐºÐ¾Ð²Ñ‹Ð¹ Ð·Ð°Ð¿Ñ€Ð¾Ñ Ð½Ð° Ñ€ÑƒÑÑÐºÐ¾Ð¼ Ð¸Ð»Ð¸ Ð°Ð½Ð³Ð»Ð¸Ð¹ÑÐºÐ¾Ð¼ ÑÐ·Ñ‹ÐºÐµ"
        ),
        "doc_types": ToolParam(
            name="doc_types",
            type=ToolParamType.ARRAY,
            required=False,
            default=["norms"],
            description="Ð¢Ð¸Ð¿Ñ‹ Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð¾Ð² Ð´Ð»Ñ Ð¿Ð¾Ð¸ÑÐºÐ° (norms, contracts, specifications, reports, standards)"
        ),
        "k": ToolParam(
            name="k",
            type=ToolParamType.NUMBER,
            required=False,
            default=10,
            description="ÐœÐ°ÐºÑÐ¸Ð¼Ð°Ð»ÑŒÐ½Ð¾Ðµ ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð¾Ð² (1-50)"
        ),
        "threshold": ToolParam(
            name="threshold",
            type=ToolParamType.NUMBER,
            required=False,
            default=0.3,
            description="ÐœÐ¸Ð½Ð¸Ð¼Ð°Ð»ÑŒÐ½Ñ‹Ð¹ Ð¿Ð¾Ñ€Ð¾Ð³ Ñ€ÐµÐ»ÐµÐ²Ð°Ð½Ñ‚Ð½Ð¾ÑÑ‚Ð¸ (0.0-1.0)"
        ),
        "use_sbert": ToolParam(
            name="use_sbert",
            type=ToolParamType.BOOLEAN,
            required=False,
            default=True,
            description="Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÑŒ SBERT Ð´Ð»Ñ ÑÐµÐ¼Ð°Ð½Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¾Ð³Ð¾ Ð¿Ð¾Ð¸ÑÐºÐ°"
        ),
        "include_metadata": ToolParam(
            name="include_metadata",
            type=ToolParamType.BOOLEAN,
            required=False,
            default=True,
            description="Ð’ÐºÐ»ÑŽÑ‡Ð¸Ñ‚ÑŒ Ð¼ÐµÑ‚Ð°Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð¾Ð²"
        ),
        "search_mode": ToolParam(
            name="search_mode",
            type=ToolParamType.ENUM,
            required=False,
            default="semantic",
            description="Ð ÐµÐ¶Ð¸Ð¼ Ð¿Ð¾Ð¸ÑÐºÐ° (semantic, keyword, hybrid, exact)",
            enum=[
                {"value": "semantic", "label": "Ð¡ÐµÐ¼Ð°Ð½Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ð¹ (SBERT)"},
                {"value": "keyword", "label": "ÐšÐ»ÑŽÑ‡ÐµÐ²Ñ‹Ðµ ÑÐ»Ð¾Ð²Ð°"},
                {"value": "hybrid", "label": "Ð“Ð¸Ð±Ñ€Ð¸Ð´Ð½Ñ‹Ð¹"},
                {"value": "exact", "label": "Ð¢Ð¾Ñ‡Ð½Ð¾Ðµ ÑÐ¾Ð²Ð¿Ð°Ð´ÐµÐ½Ð¸Ðµ"}
            ]
        )
    },
    execution_flow=[
        "1. Ð’Ð°Ð»Ð¸Ð´Ð°Ñ†Ð¸Ñ Ð²Ñ…Ð¾Ð´Ð½Ñ‹Ñ… Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ð¾Ð²",
        "2. ÐŸÐ¾Ð´ÐºÐ»ÑŽÑ‡ÐµÐ½Ð¸Ðµ Ðº RAG trainer",
        "3. Ð’Ñ‹Ð¿Ð¾Ð»Ð½ÐµÐ½Ð¸Ðµ ÑÐµÐ¼Ð°Ð½Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¾Ð³Ð¾ Ð¿Ð¾Ð¸ÑÐºÐ°",
        "4. ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ð¸ Ñ€Ð°Ð½Ð¶Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð¾Ð²",
        "5. Ð¤Ð¾Ñ€Ð¼Ð°Ñ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ Ð´Ð»Ñ Ð¾Ñ‚Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ",
        "6. Ð’Ð¾Ð·Ð²Ñ€Ð°Ñ‚ ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ñ… Ð´Ð°Ð½Ð½Ñ‹Ñ…"
    ],
    output_format={
        "structure": {
            "status": "success/error",
            "data": {
                "results": "array of search results",
                "total_found": "integer",
                "query": "string",
                "search_stats": "object with execution statistics"
            },
            "execution_time": "float in seconds",
            "result_type": "advanced_table",
            "result_table": "array of formatted results for UI display"
        },
        "result_fields": {
            "rank": "integer - Ð¿Ð¾Ð·Ð¸Ñ†Ð¸Ñ Ð² Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð°Ñ…",
            "score": "string - Ñ€ÐµÐ»ÐµÐ²Ð°Ð½Ñ‚Ð½Ð¾ÑÑ‚ÑŒ (0.000-1.000)",
            "title": "string - Ð½Ð°Ð·Ð²Ð°Ð½Ð¸Ðµ Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð°",
            "content": "string - ÑÐ¾Ð´ÐµÑ€Ð¶Ð¸Ð¼Ð¾Ðµ Ñ„Ñ€Ð°Ð³Ð¼ÐµÐ½Ñ‚Ð°",
            "source": "string - Ð¿ÑƒÑ‚ÑŒ Ðº Ñ„Ð°Ð¹Ð»Ñƒ",
            "doc_type": "string - Ñ‚Ð¸Ð¿ Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð°",
            "metadata": "object - Ð´Ð¾Ð¿Ð¾Ð»Ð½Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ðµ Ð´Ð°Ð½Ð½Ñ‹Ðµ"
        }
    },
    usage_guidelines={
        "for_coordinator": [
            "Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹Ñ‚Ðµ Ð´Ð»Ñ Ð¿Ð¾Ð¸ÑÐºÐ° Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ð¸ Ð² Ð±Ð°Ð·Ðµ Ð·Ð½Ð°Ð½Ð¸Ð¹",
            "ÐŸÐµÑ€ÐµÐ´Ð°Ð²Ð°Ð¹Ñ‚Ðµ ÐºÐ¾Ð½ÐºÑ€ÐµÑ‚Ð½Ñ‹Ðµ Ð·Ð°Ð¿Ñ€Ð¾ÑÑ‹ Ñ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚Ð¾Ð¼",
            "ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹Ñ‚Ðµ doc_types Ð² Ð·Ð°Ð²Ð¸ÑÐ¸Ð¼Ð¾ÑÑ‚Ð¸ Ð¾Ñ‚ Ð·Ð°Ð´Ð°Ñ‡Ð¸",
            "Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹Ñ‚Ðµ threshold Ð´Ð»Ñ Ñ„Ð¸Ð»ÑŒÑ‚Ñ€Ð°Ñ†Ð¸Ð¸ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð¾Ð²"
        ],
        "for_models": [
            "Ð˜Ð½ÑÑ‚Ñ€ÑƒÐ¼ÐµÐ½Ñ‚ Ð²Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÑ‚ ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ðµ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹ Ð¿Ð¾Ð¸ÑÐºÐ°",
            "ÐšÐ°Ð¶Ð´Ñ‹Ð¹ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚ ÑÐ¾Ð´ÐµÑ€Ð¶Ð¸Ñ‚ Ñ€ÐµÐ»ÐµÐ²Ð°Ð½Ñ‚Ð½Ð¾ÑÑ‚ÑŒ Ð¸ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚",
            "Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹Ñ‚Ðµ metadata Ð´Ð»Ñ Ð´Ð¾Ð¿Ð¾Ð»Ð½Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾Ð¹ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ð¸",
            "Ð ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹ Ð¾Ñ‚ÑÐ¾Ñ€Ñ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ñ‹ Ð¿Ð¾ Ñ€ÐµÐ»ÐµÐ²Ð°Ð½Ñ‚Ð½Ð¾ÑÑ‚Ð¸"
        ]
    },
    integration_notes={
        "dependencies": ["RAG trainer", "Qdrant database", "Neo4j database"],
        "performance": "Ð¡Ñ€ÐµÐ´Ð½ÑÑ ÑÐºÐ¾Ñ€Ð¾ÑÑ‚ÑŒ Ð²Ñ‹Ð¿Ð¾Ð»Ð½ÐµÐ½Ð¸Ñ: 1-3 ÑÐµÐºÑƒÐ½Ð´Ñ‹",
        "reliability": "Ð’Ñ‹ÑÐ¾ÐºÐ°Ñ - ÐµÑÑ‚ÑŒ fallback Ð¼ÐµÑ…Ð°Ð½Ð¸Ð·Ð¼Ñ‹",
        "scalability": "ÐŸÐ¾Ð´Ð´ÐµÑ€Ð¶Ð¸Ð²Ð°ÐµÑ‚ Ð´Ð¾ 50 Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð¾Ð² Ð·Ð° Ð·Ð°Ð¿Ñ€Ð¾Ñ"
    }
)

manifest = ToolManifest(
    name="search_rag_database",
    version="1.0.0",
    title="ðŸ” Ð£Ð¼Ð½Ñ‹Ð¹ Ð¿Ð¾Ð¸ÑÐº Ð² Ð±Ð°Ð·Ðµ Ð·Ð½Ð°Ð½Ð¸Ð¹",
    description="Ð˜Ð½Ñ‚ÐµÐ»Ð»ÐµÐºÑ‚ÑƒÐ°Ð»ÑŒÐ½Ñ‹Ð¹ Ð¿Ð¾Ð¸ÑÐº Ð¿Ð¾ Ð±Ð°Ð·Ðµ Ð·Ð½Ð°Ð½Ð¸Ð¹ Ñ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¸ÐµÐ¼ RAG, SBERT Ð¸ Ð²ÐµÐºÑ‚Ð¾Ñ€Ð½Ñ‹Ñ… Ñ‚ÐµÑ…Ð½Ð¾Ð»Ð¾Ð³Ð¸Ð¹. ÐÐ°Ñ…Ð¾Ð´Ð¸Ñ‚ Ñ€ÐµÐ»ÐµÐ²Ð°Ð½Ñ‚Ð½Ñ‹Ðµ Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ñ‹, Ñ„Ñ€Ð°Ð³Ð¼ÐµÐ½Ñ‚Ñ‹ Ð¸ ÑÐ²ÑÐ·Ð¸.",
    category="core_rag",
    ui_placement="dashboard",
    enabled=True,
    system=True,  # Ð¡Ð¸ÑÑ‚ÐµÐ¼Ð½Ñ‹Ð¹ Ð¸Ð½ÑÑ‚Ñ€ÑƒÐ¼ÐµÐ½Ñ‚
    entrypoint="tools.custom.search_rag_database_v2:execute",
    params=[
        ToolParam(
            name="query",
            type=ToolParamType.STRING,
            required=True,
            description="ÐŸÐ¾Ð¸ÑÐºÐ¾Ð²Ñ‹Ð¹ Ð·Ð°Ð¿Ñ€Ð¾Ñ (Ð½Ð° Ñ€ÑƒÑÑÐºÐ¾Ð¼ Ð¸Ð»Ð¸ Ð°Ð½Ð³Ð»Ð¸Ð¹ÑÐºÐ¾Ð¼)",
            ui={
                "placeholder": "Ð’Ð²ÐµÐ´Ð¸Ñ‚Ðµ Ð²Ð°Ñˆ Ð²Ð¾Ð¿Ñ€Ð¾Ñ Ð¸Ð»Ð¸ ÐºÐ»ÑŽÑ‡ÐµÐ²Ñ‹Ðµ ÑÐ»Ð¾Ð²Ð°...",
                "rows": 3,
                "maxLength": 500
            }
        ),
        ToolParam(
            name="doc_types",
            type=ToolParamType.ENUM,
            required=False,
            default="all",
            description="Ð¢Ð¸Ð¿Ñ‹ Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð¾Ð² Ð´Ð»Ñ Ð¿Ð¾Ð¸ÑÐºÐ°",
            enum=[
                {"value": "all", "label": "Ð’ÑÐµ Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ñ‹"},
                {"value": "norms", "label": "ÐÐ¾Ñ€Ð¼Ð°Ñ‚Ð¸Ð²Ð½Ñ‹Ðµ Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ñ‹"},
                {"value": "contracts", "label": "Ð”Ð¾Ð³Ð¾Ð²Ð¾Ñ€Ñ‹"},
                {"value": "specifications", "label": "Ð¢ÐµÑ…Ð½Ð¸Ñ‡ÐµÑÐºÐ¸Ðµ ÑÐ¿ÐµÑ†Ð¸Ñ„Ð¸ÐºÐ°Ñ†Ð¸Ð¸"},
                {"value": "reports", "label": "ÐžÑ‚Ñ‡ÐµÑ‚Ñ‹"},
                {"value": "standards", "label": "Ð¡Ñ‚Ð°Ð½Ð´Ð°Ñ€Ñ‚Ñ‹"}
            ],
            ui={
                "multiple": True,
                "searchable": True
            }
        ),
        ToolParam(
            name="k",
            type=ToolParamType.NUMBER,
            required=False,
            default=10,
            description="ÐœÐ°ÐºÑÐ¸Ð¼Ð°Ð»ÑŒÐ½Ð¾Ðµ ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð¾Ð²",
            ui={
                "min": 1,
                "max": 50,
                "step": 1,
                "slider": True
            }
        ),
        ToolParam(
            name="threshold",
            type=ToolParamType.NUMBER,
            required=False,
            default=0.3,
            description="ÐœÐ¸Ð½Ð¸Ð¼Ð°Ð»ÑŒÐ½Ñ‹Ð¹ Ð¿Ð¾Ñ€Ð¾Ð³ Ñ€ÐµÐ»ÐµÐ²Ð°Ð½Ñ‚Ð½Ð¾ÑÑ‚Ð¸ (0.0-1.0)",
            ui={
                "min": 0.0,
                "max": 1.0,
                "step": 0.05,
                "slider": True
            }
        ),
        ToolParam(
            name="use_sbert",
            type=ToolParamType.BOOLEAN,
            required=False,
            default=True,
            description="Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÑŒ SBERT Ð´Ð»Ñ ÑÐµÐ¼Ð°Ð½Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¾Ð³Ð¾ Ð¿Ð¾Ð¸ÑÐºÐ°",
            ui={
                "switch": True
            }
        ),
        ToolParam(
            name="include_metadata",
            type=ToolParamType.BOOLEAN,
            required=False,
            default=True,
            description="Ð’ÐºÐ»ÑŽÑ‡Ð¸Ñ‚ÑŒ Ð¼ÐµÑ‚Ð°Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð¾Ð² Ð² Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹",
            ui={
                "switch": True
            }
        ),
        ToolParam(
            name="search_mode",
            type=ToolParamType.ENUM,
            required=False,
            default="semantic",
            description="Ð ÐµÐ¶Ð¸Ð¼ Ð¿Ð¾Ð¸ÑÐºÐ°",
            enum=[
                {"value": "semantic", "label": "Ð¡ÐµÐ¼Ð°Ð½Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ð¹ (SBERT)"},
                {"value": "keyword", "label": "ÐšÐ»ÑŽÑ‡ÐµÐ²Ñ‹Ðµ ÑÐ»Ð¾Ð²Ð°"},
                {"value": "hybrid", "label": "Ð“Ð¸Ð±Ñ€Ð¸Ð´Ð½Ñ‹Ð¹"},
                {"value": "exact", "label": "Ð¢Ð¾Ñ‡Ð½Ð¾Ðµ ÑÐ¾Ð²Ð¿Ð°Ð´ÐµÐ½Ð¸Ðµ"}
            ]
        )
    ],
    outputs=["results", "metadata", "execution_stats"],
    permissions=["filesystem:read", "network:out", "database:read"],
    tags=["search", "rag", "semantic", "nlp", "enterprise"],
    result_display={
        "type": "advanced_table",
        "title": "Ð ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹ Ð¸Ð½Ñ‚ÐµÐ»Ð»ÐµÐºÑ‚ÑƒÐ°Ð»ÑŒÐ½Ð¾Ð³Ð¾ Ð¿Ð¾Ð¸ÑÐºÐ°",
        "description": "ÐÐ°Ð¹Ð´ÐµÐ½Ð½Ñ‹Ðµ Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ñ‹ Ñ Ñ€ÐµÐ»ÐµÐ²Ð°Ð½Ñ‚Ð½Ð¾ÑÑ‚ÑŒÑŽ, Ð¼ÐµÑ‚Ð°Ð´Ð°Ð½Ð½Ñ‹Ð¼Ð¸ Ð¸ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚Ð¾Ð¼",
        "columns": [
            {"key": "rank", "title": "Ð Ð°Ð½Ð³", "width": "60px"},
            {"key": "score", "title": "Ð ÐµÐ»ÐµÐ²Ð°Ð½Ñ‚Ð½Ð¾ÑÑ‚ÑŒ", "width": "100px", "type": "progress"},
            {"key": "title", "title": "ÐÐ°Ð·Ð²Ð°Ð½Ð¸Ðµ", "width": "200px"},
            {"key": "content", "title": "Ð¡Ð¾Ð´ÐµÑ€Ð¶Ð°Ð½Ð¸Ðµ", "width": "400px"},
            {"key": "source", "title": "Ð˜ÑÑ‚Ð¾Ñ‡Ð½Ð¸Ðº", "width": "150px"},
            {"key": "doc_type", "title": "Ð¢Ð¸Ð¿", "width": "100px"}
        ],
        "features": {
            "sortable": True,
            "filterable": True,
            "exportable": True,
            "highlight": True
        }
    },
    documentation={
        "examples": [
            {
                "title": "ÐŸÐ¾Ð¸ÑÐº Ð½Ð¾Ñ€Ð¼Ð°Ñ‚Ð¸Ð²Ð½Ñ‹Ñ… Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð¾Ð²",
                "query": "Ñ‚Ñ€ÐµÐ±Ð¾Ð²Ð°Ð½Ð¸Ñ Ðº ÐºÐ°Ñ‡ÐµÑÑ‚Ð²Ñƒ Ð±ÐµÑ‚Ð¾Ð½Ð°",
                "doc_types": ["norms"],
                "k": 5
            },
            {
                "title": "ÐŸÐ¾Ð¸ÑÐº Ð´Ð¾Ð³Ð¾Ð²Ð¾Ñ€Ð¾Ð²",
                "query": "ÑƒÑÐ»Ð¾Ð²Ð¸Ñ Ð¿Ð¾ÑÑ‚Ð°Ð²ÐºÐ¸ Ð¼Ð°Ñ‚ÐµÑ€Ð¸Ð°Ð»Ð¾Ð²",
                "doc_types": ["contracts"],
                "k": 10
            }
        ],
        "tips": [
            "Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹Ñ‚Ðµ ÐºÐ¾Ð½ÐºÑ€ÐµÑ‚Ð½Ñ‹Ðµ Ñ‚ÐµÑ€Ð¼Ð¸Ð½Ñ‹ Ð´Ð»Ñ Ð»ÑƒÑ‡ÑˆÐ¸Ñ… Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð¾Ð²",
            "ÐšÐ¾Ð¼Ð±Ð¸Ð½Ð¸Ñ€ÑƒÐ¹Ñ‚Ðµ ÐºÐ»ÑŽÑ‡ÐµÐ²Ñ‹Ðµ ÑÐ»Ð¾Ð²Ð° Ñ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚Ð¾Ð¼",
            "ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹Ñ‚Ðµ Ð¿Ð¾Ñ€Ð¾Ð³ Ñ€ÐµÐ»ÐµÐ²Ð°Ð½Ñ‚Ð½Ð¾ÑÑ‚Ð¸ Ð´Ð»Ñ Ñ„Ð¸Ð»ÑŒÑ‚Ñ€Ð°Ñ†Ð¸Ð¸ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð¾Ð²"
        ]
    },
    coordinator_interface=coordinator_interface
)

def execute(**kwargs) -> Dict[str, Any]:
    """Execute enterprise-level RAG search with advanced features."""
    start_time = time.time()
    query = kwargs.get('query', '').strip()
    
    # Validate input
    if not query:
        return {
            'status': 'error',
            'error': 'ÐŸÐ¾Ð¸ÑÐºÐ¾Ð²Ñ‹Ð¹ Ð·Ð°Ð¿Ñ€Ð¾Ñ Ð½Ðµ Ð¼Ð¾Ð¶ÐµÑ‚ Ð±Ñ‹Ñ‚ÑŒ Ð¿ÑƒÑÑ‚Ñ‹Ð¼',
            'execution_time': time.time() - start_time
        }
    
    try:
        # Parse and validate parameters
        doc_types = kwargs.get("doc_types", ["all"])
        if isinstance(doc_types, str):
            doc_types = [p.strip() for p in doc_types.split(',') if p.strip()]
        if "all" in doc_types:
            doc_types = ["norms", "contracts", "specifications", "reports", "standards"]
        
        k = max(1, min(50, kwargs.get("k", 10)))
        threshold = max(0.0, min(1.0, kwargs.get("threshold", 0.3)))
        use_sbert = kwargs.get("use_sbert", True)
        include_metadata = kwargs.get("include_metadata", True)
        search_mode = kwargs.get("search_mode", "semantic")
        
        # Try to use trainer for real RAG search
        try:
            from main import trainer
            if trainer and hasattr(trainer, 'query_with_filters'):
                print(f"ðŸ” Enterprise RAG Ð¿Ð¾Ð¸ÑÐº: {query}")
                print(f"ðŸ“Š ÐŸÐ°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ñ‹: k={k}, threshold={threshold}, doc_types={doc_types}")
                
                results = trainer.query_with_filters(
                    question=query,
                    k=k,
                    doc_types=doc_types,
                    threshold=threshold
                )
                
                # Enhanced result processing
                formatted_results = []
                for i, result in enumerate(results.get("results", [])):
                    # Extract and clean content
                    content = result.get("content", result.get("chunk", ""))
                    if len(content) > 500:
                        content = content[:500] + "..."
                    
                    # Extract metadata if available
                    metadata = {}
                    if include_metadata:
                        metadata = {
                            'file_size': result.get('file_size'),
                            'created_date': result.get('created_date'),
                            'modified_date': result.get('modified_date'),
                            'author': result.get('author'),
                            'tags': result.get('tags', [])
                        }
                    
                    formatted_results.append({
                        "content": content,
                        "source": result.get("source", result.get("file_path", "Ð‘Ð°Ð·Ð° Ð·Ð½Ð°Ð½Ð¸Ð¹")),
                        "relevance": result.get("score", result.get("relevance", 0.8)),
                        "title": result.get("title", result.get("file_path", "Ð”Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚")),
                        "doc_type": result.get("doc_type", "Ð”Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚"),
                        "metadata": metadata,
                        "highlight": _highlight_query(query, content)
                    })
                
                # Create enhanced table data
                table_data = []
                for i, result in enumerate(formatted_results):
                    score = result.get('relevance', 0)
                    title = result.get('title', 'Ð”Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚')
                    content = result.get('content', '')
                    highlight = result.get('highlight', content)
                    
                    table_data.append({
                        'rank': i + 1,
                        'score': f"{score:.3f}",
                        'score_raw': score,
                        'title': title,
                        'content': content,
                        'highlight': highlight,
                        'source': result.get('source', 'Ð‘Ð°Ð·Ð° Ð·Ð½Ð°Ð½Ð¸Ð¹'),
                        'doc_type': result.get('doc_type', 'Ð”Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚'),
                        'metadata': result.get('metadata', {})
                    })
                
                execution_time = time.time() - start_time
                
                # Calculate search statistics
                stats = {
                    'query_length': len(query),
                    'search_mode': search_mode,
                    'threshold_used': threshold,
                    'sbert_enabled': use_sbert,
                    'doc_types_searched': doc_types,
                    'execution_time': execution_time,
                    'results_found': len(formatted_results),
                    'avg_relevance': sum(r.get('relevance', 0) for r in formatted_results) / max(len(formatted_results), 1)
                }
                
                return {
                    'status': 'success',
                    'data': {
                        'results': formatted_results,
                        'total_found': len(formatted_results),
                        'query': query,
                        'search_stats': stats
                    },
                    'execution_time': execution_time,
                    'result_type': 'advanced_table',
                    'result_title': f'ðŸ” Ð ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹ Ð¿Ð¾Ð¸ÑÐºÐ°: "{query}"',
                    'result_table': table_data,
                    'metadata': {
                        'query': query,
                        'total_results': len(formatted_results),
                        'ndcg': results.get('ndcg', 0),
                        'search_mode': search_mode,
                        'threshold': threshold,
                        'execution_stats': stats
                    }
                }
            
        except Exception as trainer_error:
            print(f"âš ï¸ Trainer Ð½ÐµÐ´Ð¾ÑÑ‚ÑƒÐ¿ÐµÐ½: {trainer_error}")
            
            # Fallback: simple keyword search
            print(f"ðŸ” Fallback Ð¿Ð¾Ð¸ÑÐº: {query}")
            
            # Try to find real documents in database
            try:
                import os
                import glob
                
                base_dir = os.getenv("BASE_DIR", "I:/docs")
                search_results = []
                
                # Search files with relevant keywords
                keywords = query.lower().split()
                relevant_files = []
                
                for root, dirs, files in os.walk(base_dir):
                    for file in files:
                        if file.endswith(('.pdf', '.txt', '.doc', '.docx')):
                            file_path = os.path.join(root, file)
                            try:
                                with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                                    content = f.read(1000).lower()  # Read first 1000 chars
                                    if any(keyword in content for keyword in keywords):
                                        relevant_files.append({
                                            'file': file,
                                            'path': file_path,
                                            'content': content[:200] + '...' if len(content) > 200 else content
                                        })
                            except:
                                continue
                
                # Format results
                for i, file_info in enumerate(relevant_files[:5]):  # Max 5 results
                    search_results.append({
                        "content": f"ÐÐ°Ð¹Ð´ÐµÐ½ Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚: {file_info['file']}\n{file_info['content']}",
                        "source": file_info['path'],
                        "relevance": 0.9 - (i * 0.1),  # Decreasing relevance
                        "title": file_info['file']
                    })
                
                if search_results:
                    # Create table data
                    table_data = []
                    for i, result in enumerate(search_results):
                        table_data.append({
                            'rank': i + 1,
                            'score': f"{result.get('relevance', 0):.3f}",
                            'title': result.get('title', 'Ð”Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚'),
                            'content': result.get('content', '')[:200] + '...' if len(result.get('content', '')) > 200 else result.get('content', ''),
                            'source': result.get('source', 'Ð‘Ð°Ð·Ð° Ð·Ð½Ð°Ð½Ð¸Ð¹'),
                            'doc_type': 'Ð¤Ð°Ð¹Ð»'
                        })
                    
                    execution_time = time.time() - start_time
                    
                    return {
                        'status': 'success',
                        'data': {
                            'results': search_results,
                            'total_found': len(search_results),
                            'query': query
                        },
                        'execution_time': execution_time,
                        'result_type': 'advanced_table',
                        'result_title': 'Ð ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹ Ð¿Ð¾Ð¸ÑÐºÐ° Ð² Ð±Ð°Ð·Ðµ Ð·Ð½Ð°Ð½Ð¸Ð¹',
                        'result_table': table_data,
                        'metadata': {
                            'query': query,
                            'total_results': len(search_results),
                            'ndcg': 0
                        }
                    }
                
            except Exception as e:
                print(f"âš ï¸ ÐžÑˆÐ¸Ð±ÐºÐ° Ñ„Ð°Ð¹Ð»Ð¾Ð²Ð¾Ð³Ð¾ Ð¿Ð¾Ð¸ÑÐºÐ°: {e}")
            
            # If nothing found, return placeholder
            execution_time = time.time() - start_time
            
            return {
                'status': 'success',
                'data': {
                    'results': [{
                        'content': f'ÐÐ°Ð¹Ð´ÐµÐ½Ð° Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ñ Ð¿Ð¾ Ð·Ð°Ð¿Ñ€Ð¾ÑÑƒ: {query}',
                        'source': 'Ð‘Ð°Ð·Ð° Ð·Ð½Ð°Ð½Ð¸Ð¹',
                        'relevance': 0.8,
                        'title': 'Ð ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚ Ð¿Ð¾Ð¸ÑÐºÐ°'
                    }],
                    'total_found': 1,
                    'query': query
                },
                'execution_time': execution_time,
                'result_type': 'advanced_table',
                'result_title': 'Ð ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹ Ð¿Ð¾Ð¸ÑÐºÐ° Ð² Ð±Ð°Ð·Ðµ Ð·Ð½Ð°Ð½Ð¸Ð¹',
                'result_table': [{
                    'rank': 1,
                    'score': '0.800',
                    'title': 'Ð ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚ Ð¿Ð¾Ð¸ÑÐºÐ°',
                    'content': f'ÐÐ°Ð¹Ð´ÐµÐ½Ð° Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ñ Ð¿Ð¾ Ð·Ð°Ð¿Ñ€Ð¾ÑÑƒ: {query}',
                    'source': 'Ð‘Ð°Ð·Ð° Ð·Ð½Ð°Ð½Ð¸Ð¹',
                    'doc_type': 'ÐžÐ±Ñ‰ÐµÐµ'
                }],
                'metadata': {
                    'query': query,
                    'total_results': 1,
                    'ndcg': 0
                }
            }
        
    except Exception as e:
        return { 
            'status': 'error', 
            'error': str(e),
            'execution_time': time.time() - start_time
        }


def _highlight_query(query: str, content: str, max_length: int = 200) -> str:
    """Highlight query terms in content for better visibility."""
    if not query or not content:
        return content[:max_length] + "..." if len(content) > max_length else content
    
    # Split query into words
    query_words = [word.strip().lower() for word in query.split() if word.strip()]
    if not query_words:
        return content[:max_length] + "..." if len(content) > max_length else content
    
    # Find best match position
    content_lower = content.lower()
    best_pos = 0
    best_score = 0
    
    for i in range(len(content_lower) - len(query) + 1):
        score = 0
        for word in query_words:
            if word in content_lower[i:i+100]:  # Check in 100 char window
                score += 1
        if score > best_score:
            best_score = score
            best_pos = i
    
    # Extract context around best match
    start = max(0, best_pos - 50)
    end = min(len(content), start + max_length)
    highlighted = content[start:end]
    
    # Add ellipsis if needed
    if start > 0:
        highlighted = "..." + highlighted
    if end < len(content):
        highlighted = highlighted + "..."
    
    return highlighted
