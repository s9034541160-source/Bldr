#!/usr/bin/env python3
"""
–¢–µ—Å—Ç–æ–≤—ã–π —Å–∫—Ä–∏–ø—Ç –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ BldrRAGTrainer –±–µ–∑ LLM –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
"""

from scripts.bldr_rag_trainer import BldrRAGTrainer
import os
import tempfile

def test_basic_pipeline():
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –±–∞–∑–æ–≤—ã–µ —Å—Ç–∞–¥–∏–∏ RAG trainer –±–µ–∑ LLM"""
    print("üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ BldrRAGTrainer –±–µ–∑ LLM –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π...")
    
    # –°–æ–∑–¥–∞–µ–º —Ç—Ä–µ–Ω–µ—Ä
    trainer = BldrRAGTrainer()
    print("‚úÖ Trainer —Å–æ–∑–¥–∞–Ω —É—Å–ø–µ—à–Ω–æ")
    
    # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª
    test_content = """
    –¢–µ—Å—Ç–æ–≤—ã–π –¥–æ–∫—É–º–µ–Ω—Ç –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Ä–∞–±–æ—Ç—ã —Å–∏—Å—Ç–µ–º—ã.
    
    –†–∞–∑–¥–µ–ª 1.1 –ù–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è
    –î–∞–Ω–Ω—ã–π –¥–æ–∫—É–º–µ–Ω—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç –°–ü 31.13330.2012 —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è.
    –†–∞–±–æ—Ç–∞ –ø–æ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–µ –æ—Å–Ω–æ–≤–∞–Ω–∏—è –¥–æ–ª–∂–Ω–∞ –≤—ã–ø–æ–ª–Ω—è—Ç—å—Å—è —Å–æ–≥–ª–∞—Å–Ω–æ –Ω–æ—Ä–º–∞–º.
    
    –¢–∞–±–ª–∏—Ü–∞ 1: –ú–∞—Ç–µ—Ä–∏–∞–ª—ã
    –ë–µ—Ç–æ–Ω –∫–ª–∞—Å—Å–∞ B25 - 100 –º3
    –¶–µ–º–µ–Ω—Ç –ú400 - 50 —Ç–æ–Ω–Ω
    
    –°—Ç–æ–∏–º–æ—Å—Ç—å: 1500000 —Ä—É–±–ª–µ–π
    –ü–æ–∑–∏—Ü–∏—è 1: –ó–µ–º–ª—è–Ω—ã–µ —Ä–∞–±–æ—Ç—ã
    –ü–æ–∑–∏—Ü–∏—è 2: –ë–µ—Ç–æ–Ω–Ω—ã–µ —Ä–∞–±–æ—Ç—ã
    """
    
    with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False, encoding='utf-8') as f:
        f.write(test_content)
        test_file = f.name
    
    try:
        print(f"üìÑ –¢–µ—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª: {test_file}")
        
        # Stage 1: –í–∞–ª–∏–¥–∞—Ü–∏—è
        stage1_result = trainer._stage1_initial_validation(test_file)
        print(f"‚úÖ Stage 1: {stage1_result['log']}")
        
        # Stage 2: –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
        stage2_result = trainer._stage2_duplicate_checking(test_file)
        print(f"‚úÖ Stage 2: {stage2_result['log']}")
        
        # Stage 3: –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞
        content = trainer._stage3_text_extraction(test_file)
        print(f"‚úÖ Stage 3: –ò–∑–≤–ª–µ—á–µ–Ω–æ {len(content)} —Å–∏–º–≤–æ–ª–æ–≤")
        
        # Stage 4: –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∏–ø–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞
        doc_type_result = trainer._stage4_document_type_detection(content, test_file)
        print(f"‚úÖ Stage 4: {doc_type_result['log']}")
        
        # Stage 5: –°—Ç—Ä—É–∫—Ç—É—Ä–Ω—ã–π –∞–Ω–∞–ª–∏–∑
        structural_result = trainer._stage5_structural_analysis(
            content, 
            doc_type_result['doc_type'], 
            doc_type_result['doc_subtype']
        )
        print(f"‚úÖ Stage 5: {structural_result['log']}")
        
        # Stage 6: –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ä–∞–±–æ—Ç (regex -> rubern)
        seed_works = trainer._stage6_regex_to_rubern(
            content, 
            doc_type_result['doc_type'], 
            structural_result['structural_data']
        )
        print(f"‚úÖ Stage 6: –ù–∞–π–¥–µ–Ω–æ {len(seed_works)} seed works")
        
        # Stage 7: Rubern —Ä–∞–∑–º–µ—Ç–∫–∞ 
        rubern_data = trainer._stage7_rubern_markup(
            content,
            doc_type_result['doc_type'],
            doc_type_result['doc_subtype'],
            seed_works,
            structural_result['structural_data']
        )
        print(f"‚úÖ Stage 7: Rubern —Ä–∞–∑–º–µ—Ç–∫–∞ —Å {len(rubern_data.get('works', []))} —Ä–∞–±–æ—Ç–∞–º–∏")
        
        # Stage 8: –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
        metadata = trainer._stage8_metadata_extraction(
            content,
            rubern_data,
            doc_type_result['doc_type']
        )
        print(f"‚úÖ Stage 8: {len(metadata.get('materials', []))} –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤, {len(metadata.get('finances', []))} —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã—Ö –∑–∞–ø–∏—Å–µ–π")
        
        # Stage 9: –ö–æ–Ω—Ç—Ä–æ–ª—å –∫–∞—á–µ—Å—Ç–≤–∞
        quality_score = trainer._stage9_quality_control(
            doc_type_result,
            structural_result['structural_data'],
            seed_works,
            rubern_data,
            metadata
        )
        print(f"‚úÖ Stage 9: –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ {quality_score:.2f}")
        
        # Stage 10: –¢–∏–ø–æ-—Å–ø–µ—Ü–∏—Ñ–∏—á–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ (–ë–ï–ó LLM!)
        type_specific_data = trainer._stage10_type_specific_processing(
            doc_type_result['doc_type'],
            doc_type_result['doc_subtype'],
            rubern_data
        )
        print(f"‚úÖ Stage 10: –°–ø–µ—Ü–∏—Ñ–∏—á–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞, conf {type_specific_data.get('conf', 0.9)}")
        
        # Stage 11: –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ —Ä–∞–±–æ—Ç (–ë–ï–ó tools_system!)
        work_sequences = trainer._stage11_work_sequence_extraction(rubern_data, metadata)
        print(f"‚úÖ Stage 11: {len(work_sequences)} –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π —Ä–∞–±–æ—Ç")
        
        # Stage 12: –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ —Ä–∞–±–æ—Ç
        trainer._stage12_save_work_sequences(work_sequences)
        print(f"‚úÖ Stage 12: –ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ —Ä–∞–±–æ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã")
        
        # Stage 13: –£–º–Ω–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ —á–∞–Ω–∫–∏
        chunks = trainer._stage13_smart_chunking(rubern_data, metadata, doc_type_result)
        print(f"‚úÖ Stage 13: –°–æ–∑–¥–∞–Ω–æ {len(chunks)} —á–∞–Ω–∫–æ–≤")
        
        print("\nüéâ –í–°–ï 13 –°–¢–ê–î–ò–ô –†–ê–ë–û–¢–ê–Æ–¢ –ë–ï–ó LLM –ó–ê–í–ò–°–ò–ú–û–°–¢–ï–ô!")
        print(f"üìä –ò—Ç–æ–≥–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
        print(f"   - –¢–∏–ø –¥–æ–∫—É–º–µ–Ω—Ç–∞: {doc_type_result['doc_type']}")
        print(f"   - –†–∞–±–æ—Ç—ã –∏–∑–≤–ª–µ—á–µ–Ω—ã: {len(rubern_data.get('works', []))}")
        print(f"   - –ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ —Ä–∞–±–æ—Ç: {len(work_sequences)}")
        print(f"   - –ß–∞–Ω–∫–∏ —Å–æ–∑–¥–∞–Ω—ã: {len(chunks)}")
        print(f"   - –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞: {quality_score:.2f}")
        
    finally:
        # –£–¥–∞–ª—è–µ–º —Ç–µ—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª
        try:
            os.unlink(test_file)
        except:
            pass

if __name__ == "__main__":
    test_basic_pipeline()