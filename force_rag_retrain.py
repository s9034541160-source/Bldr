#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
FORCE RAG RETRAIN - –ü–†–ò–ù–£–î–ò–¢–ï–õ–¨–ù–ê–Ø –ü–ï–†–ï–û–ë–†–ê–ë–û–¢–ö–ê
==============================================

–ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–∞—è –ø–µ—Ä–µ–æ–±—Ä–∞–±–æ—Ç–∫–∞ –≤—Å–µ—Ö —Ñ–∞–π–ª–æ–≤ –∏–∑ —É–∫–∞–∑–∞–Ω–Ω–æ–π –ø–∞–ø–∫–∏
—Å –∏—Å–∫–ª—é—á–µ–Ω–∏–µ–º —Å–∏—Å—Ç–µ–º–Ω—ã—Ö –ø–∞–ø–æ–∫.
"""

import os
import sys
import json
import shutil
from pathlib import Path
from datetime import datetime
import logging

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('force_retrain.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

def clear_rag_cache():
    """–û—á–∏—Å—Ç–∫–∞ –∫—ç—à–∞ RAG –¥–ª—è –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–π –ø–µ—Ä–µ–æ–±—Ä–∞–±–æ—Ç–∫–∏"""
    cache_dirs = [
        "I:/docs/downloaded/cache",
        "I:/docs/downloaded/embedding_cache", 
        "I:/docs/downloaded/qdrant_db",
        "I:/docs/downloaded/reports"
    ]
    
    logger.info("üßπ –û—á–∏—Å—Ç–∫–∞ –∫—ç—à–∞ RAG...")
    
    for cache_dir in cache_dirs:
        if os.path.exists(cache_dir):
            try:
                if cache_dir.endswith("qdrant_db"):
                    # –î–ª—è Qdrant DB - —É–¥–∞–ª—è–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ, –Ω–æ –æ—Å—Ç–∞–≤–ª—è–µ–º –ø–∞–ø–∫—É
                    for item in os.listdir(cache_dir):
                        item_path = os.path.join(cache_dir, item)
                        if os.path.isfile(item_path):
                            os.remove(item_path)
                        elif os.path.isdir(item_path):
                            shutil.rmtree(item_path)
                    logger.info(f"‚úÖ –û—á–∏—â–µ–Ω–∞ –ø–∞–ø–∫–∞: {cache_dir}")
                else:
                    # –î–ª—è –æ—Å—Ç–∞–ª—å–Ω—ã—Ö - –ø–æ–ª–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞
                    shutil.rmtree(cache_dir)
                    os.makedirs(cache_dir, exist_ok=True)
                    logger.info(f"‚úÖ –û—á–∏—â–µ–Ω–∞ –∏ –ø–µ—Ä–µ—Å–æ–∑–¥–∞–Ω–∞ –ø–∞–ø–∫–∞: {cache_dir}")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –æ—á–∏—Å—Ç–∏—Ç—å {cache_dir}: {e}")
        else:
            logger.info(f"‚ÑπÔ∏è –ü–∞–ø–∫–∞ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç: {cache_dir}")

def clear_processed_files():
    """–û—á–∏—Å—Ç–∫–∞ —Å–ø–∏—Å–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤"""
    processed_files_path = "processed_files.json"
    
    if os.path.exists(processed_files_path):
        try:
            os.remove(processed_files_path)
            logger.info("‚úÖ –£–¥–∞–ª–µ–Ω —Ñ–∞–π–ª processed_files.json")
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å processed_files.json: {e}")
    else:
        logger.info("‚ÑπÔ∏è –§–∞–π–ª processed_files.json –Ω–µ –Ω–∞–π–¥–µ–Ω")

def get_files_to_process():
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ —Ñ–∞–π–ª–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏"""
    base_dir = "I:/docs/downloaded"
    exclude_dirs = ["reports", "qdrant_db", "embedding_cache", "cache"]
    
    files_to_process = []
    
    logger.info(f"üîç –°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–∞–ø–∫–∏: {base_dir}")
    logger.info(f"üö´ –ò—Å–∫–ª—é—á–∞–µ–º –ø–∞–ø–∫–∏: {exclude_dirs}")
    
    for root, dirs, files in os.walk(base_dir):
        # –ò—Å–∫–ª—é—á–∞–µ–º —Å–∏—Å—Ç–µ–º–Ω—ã–µ –ø–∞–ø–∫–∏
        dirs[:] = [d for d in dirs if d not in exclude_dirs]
        
        for file in files:
            if file.lower().endswith(('.pdf', '.docx', '.xlsx', '.xls', '.txt', '.doc')):
                file_path = os.path.join(root, file)
                files_to_process.append(file_path)
    
    logger.info(f"üìÅ –ù–∞–π–¥–µ–Ω–æ —Ñ–∞–π–ª–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {len(files_to_process)}")
    return files_to_process

def backup_existing_data():
    """–°–æ–∑–¥–∞–Ω–∏–µ –±—ç–∫–∞–ø–∞ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö"""
    backup_dir = f"backup_rag_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
    
    try:
        os.makedirs(backup_dir, exist_ok=True)
        
        # –ë—ç–∫–∞–ø processed_files.json
        if os.path.exists("processed_files.json"):
            shutil.copy2("processed_files.json", f"{backup_dir}/processed_files.json")
            logger.info(f"‚úÖ –°–æ–∑–¥–∞–Ω –±—ç–∫–∞–ø processed_files.json –≤ {backup_dir}")
        
        # –ë—ç–∫–∞–ø –∫—ç—à–∞ (–µ—Å–ª–∏ –µ—Å—Ç—å)
        cache_dirs = ["I:/docs/downloaded/cache", "I:/docs/downloaded/embedding_cache"]
        for cache_dir in cache_dirs:
            if os.path.exists(cache_dir):
                cache_backup = f"{backup_dir}/{os.path.basename(cache_dir)}"
                shutil.copytree(cache_dir, cache_backup)
                logger.info(f"‚úÖ –°–æ–∑–¥–∞–Ω –±—ç–∫–∞–ø {cache_dir} –≤ {cache_backup}")
        
        logger.info(f"‚úÖ –ë—ç–∫–∞–ø —Å–æ–∑–¥–∞–Ω –≤ –ø–∞–ø–∫–µ: {backup_dir}")
        return backup_dir
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –±—ç–∫–∞–ø–∞: {e}")
        return None

def run_rag_trainer():
    """–ó–∞–ø—É—Å–∫ RAG-—Ç—Ä–µ–Ω–µ—Ä–∞"""
    logger.info("üöÄ –ó–∞–ø—É—Å–∫ RAG-—Ç—Ä–µ–Ω–µ—Ä–∞...")
    
    try:
        # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –∏ –∑–∞–ø—É—Å–∫–∞–µ–º —Ç—Ä–µ–Ω–µ—Ä
        from enterprise_rag_trainer_full import main as rag_main
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º —Å –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–π –ø–µ—Ä–µ–æ–±—Ä–∞–±–æ—Ç–∫–æ–π
        rag_main()
        
        logger.info("‚úÖ RAG-—Ç—Ä–µ–Ω–µ—Ä –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ")
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø—É—Å–∫–∞ RAG-—Ç—Ä–µ–Ω–µ—Ä–∞: {e}")
        logger.error(f"–¢—Ä–∞—Å—Å–∏—Ä–æ–≤–∫–∞: {traceback.format_exc()}")
        raise

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–π –ø–µ—Ä–µ–æ–±—Ä–∞–±–æ—Ç–∫–∏"""
    logger.info("üéØ –ù–ê–ß–ê–õ–û –ü–†–ò–ù–£–î–ò–¢–ï–õ–¨–ù–û–ô –ü–ï–†–ï–û–ë–†–ê–ë–û–¢–ö–ò RAG")
    logger.info("=" * 60)
    
    try:
        # 1. –°–æ–∑–¥–∞–µ–º –±—ç–∫–∞–ø
        logger.info("üì¶ –°–æ–∑–¥–∞–Ω–∏–µ –±—ç–∫–∞–ø–∞...")
        backup_dir = backup_existing_data()
        
        # 2. –û—á–∏—â–∞–µ–º –∫—ç—à
        logger.info("üßπ –û—á–∏—Å—Ç–∫–∞ –∫—ç—à–∞...")
        clear_rag_cache()
        clear_processed_files()
        
        # 3. –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤
        logger.info("üìÅ –ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ —Ñ–∞–π–ª–æ–≤...")
        files_to_process = get_files_to_process()
        
        if not files_to_process:
            logger.warning("‚ö†Ô∏è –ù–µ –Ω–∞–π–¥–µ–Ω–æ —Ñ–∞–π–ª–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏!")
            return
        
        logger.info(f"üìä –ë—É–¥–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Ñ–∞–π–ª–æ–≤: {len(files_to_process)}")
        
        # 4. –ó–∞–ø—É—Å–∫–∞–µ–º RAG-—Ç—Ä–µ–Ω–µ—Ä
        logger.info("üöÄ –ó–∞–ø—É—Å–∫ RAG-—Ç—Ä–µ–Ω–µ—Ä–∞...")
        run_rag_trainer()
        
        logger.info("‚úÖ –ü–†–ò–ù–£–î–ò–¢–ï–õ–¨–ù–ê–Ø –ü–ï–†–ï–û–ë–†–ê–ë–û–¢–ö–ê –ó–ê–í–ï–†–®–ï–ù–ê –£–°–ü–ï–®–ù–û!")
        logger.info("=" * 60)
        
    except Exception as e:
        logger.error(f"‚ùå –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê: {e}")
        logger.error(f"–¢—Ä–∞—Å—Å–∏—Ä–æ–≤–∫–∞: {traceback.format_exc()}")
        raise

if __name__ == "__main__":
    main()
