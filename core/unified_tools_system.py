#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
–£–ù–ò–§–ò–¶–ò–†–û–í–ê–ù–ù–ê–Ø –°–ò–°–¢–ï–ú–ê –ò–ù–°–¢–†–£–ú–ï–ù–¢–û–í –° KWARGS
=============================================

–ï–¥–∏–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –¥–ª—è –≤—Å–µ—Ö 47+ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ —Å —É–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏:
- –§–æ—Ä–º–∞—Ç–∞–º–∏ –≤—Ö–æ–¥–Ω—ã—Ö/–≤—ã—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö  
- –û–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫
- –í–∞–ª–∏–¥–∞—Ü–∏–µ–π –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ —á–µ—Ä–µ–∑ **kwargs
- –°—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ –æ—Ç–≤–µ—Ç–∞–º–∏

"""

import json
import traceback
from typing import Dict, Any, List, Optional, Callable, Union
from dataclasses import dataclass, asdict, field
from datetime import datetime
from pathlib import Path
import logging

from core.exceptions import (
    ToolValidationError, ToolDependencyError, ToolExecutionTimeoutError,
    ToolResourceError, get_error_category
)
from core.async_executor import get_async_executor, AsyncToolExecutor
from core.security.tool_auth import get_auth_manager, ToolPermission, AuthType
from core.memory.dual_memory import get_memory_system

# Configure logging
logger = logging.getLogger(__name__)

@dataclass
class ToolResult:
    """–°—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞"""
    status: str  # 'success' | 'error' | 'partial'
    data: Any = None
    error: Optional[str] = None
    warnings: List[str] = field(default_factory=list)
    metadata: Dict[str, Any] = field(default_factory=dict)
    execution_time: Optional[float] = None
    tool_name: Optional[str] = None
    
    def to_dict(self) -> Dict[str, Any]:
        """–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ —Å–ª–æ–≤–∞—Ä—å –¥–ª—è JSON serialization"""
        return asdict(self)
    
    def is_success(self) -> bool:
        return self.status == 'success'
    
    def add_warning(self, warning: str):
        self.warnings.append(warning)
    
    def set_metadata(self, key: str, value: Any):
        self.metadata[key] = value

@dataclass 
class ToolSignature:
    """–°–∏–≥–Ω–∞—Ç—É—Ä–∞ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞ —Å –æ–ø–∏—Å–∞–Ω–∏–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤"""
    name: str
    description: str
    required_params: List[str] = field(default_factory=list)
    optional_params: Dict[str, Any] = field(default_factory=dict)
    return_type: str = "ToolResult"
    category: str = "general"
    
class ToolValidationError(Exception):
    """–û—à–∏–±–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞"""
    pass

class ToolExecutionError(Exception):
    """–û—à–∏–±–∫–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞"""
    pass

class UnifiedToolsSystem:
    """–£–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ —Å kwargs –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π"""
    
    def __init__(self, rag_system: Any = None, model_manager: Any = None):
        # Optional RAG + model manager for legacy ToolsSystem delegation
        self.rag_system = rag_system
        self.model_manager = model_manager
        self._legacy_tools_system = None
        
        self.tools_registry: Dict[str, ToolSignature] = {}
        self.tools_methods: Dict[str, Callable] = {}
        self.execution_stats: Dict[str, Dict[str, Any]] = {}
        self.performance_metrics: Dict[str, Any] = {}  # üöÄ –ù–û–í–û–ï: –ú–µ—Ç—Ä–∏–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        self.async_executor: Optional[AsyncToolExecutor] = None  # üöÄ –ù–û–í–û–ï: –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –∏—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—å
        self.auth_manager = get_auth_manager()  # üöÄ –ù–û–í–û–ï: –ú–µ–Ω–µ–¥–∂–µ—Ä –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏
        self.memory_system = get_memory_system()  # üöÄ –ù–û–í–û–ï: –°–∏—Å—Ç–µ–º–∞ –ø–∞–º—è—Ç–∏
        
        # Register all tools
        self._register_all_tools()
        
        # Initialize tool methods
        self._init_tool_methods()
        
        # üöÄ –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø –ê–°–ò–ù–•–†–û–ù–ù–û–ì–û –ò–°–ü–û–õ–ù–ò–¢–ï–õ–Ø
        self.async_executor = get_async_executor()
    
    def _register_all_tools(self):
        """–†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è –≤—Å–µ—Ö 47+ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤"""
        
        # PRO FEATURE TOOLS (subset)
        self.register_tool(
            "generate_letter",
            description="AI-–≥–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã—Ö –ø–∏—Å–µ–º",
            required_params=["description"],
            optional_params={
                "template_id": "compliance_sp31",
                "project_id": None,
                "tone": 0.0,
                "dryness": 0.5,
                "humanity": 0.7,
                "length": "medium",
                "formality": "formal"
            },
            category="pro_features"
        )
        self.register_tool(
            "improve_letter",
            description="–£–ª—É—á—à–µ–Ω–∏–µ —á–µ—Ä–Ω–æ–≤–∏–∫–æ–≤ –ø–∏—Å–µ–º",
            required_params=["draft"],
            optional_params={
                "description": "",
                "template_id": "",
                "project_id": None,
                "tone": 0.0,
                "dryness": 0.5,
                "humanity": 0.7,
                "length": "medium",
                "formality": "formal"
            },
            category="pro_features"
        )
        self.register_tool(
            "auto_budget",
            description="–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —Å–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ —Å–º–µ—Ç",
            required_params=["estimate_data"],
            optional_params={
                "gesn_rates": {},
                "regional_coefficients": {},
                "overheads_percentage": 15,
                "profit_percentage": 10
            },
            category="pro_features"
        )
        self.register_tool(
            "generate_ppr",
            description="–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–æ–µ–∫—Ç–∞ –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–∞ —Ä–∞–±–æ—Ç",
            required_params=["project_data"],
            optional_params={"works_seq": [], "timeline": None, "resources": {}, "safety_requirements": []},
            category="pro_features"
        )
        self.register_tool(
            "create_gpp",
            description="–°–æ–∑–¥–∞–Ω–∏–µ –∫–∞–ª–µ–Ω–¥–∞—Ä–Ω–æ–≥–æ –ø–ª–∞–Ω–∞",
            required_params=["works_seq"],
            optional_params={"timeline": None, "constraints": {}, "resources": {}, "dependencies": []},
            category="pro_features"
        )
        
        # SUPER FEATURE TOOLS
        self.register_tool(
            "analyze_bentley_model",
            description="–ê–Ω–∞–ª–∏–∑ IFC/BIM –º–æ–¥–µ–ª–µ–π",
            required_params=["ifc_path"],
            optional_params={"analysis_type": "clash", "output_format": "json", "detailed": False},
            category="super_features"
        )
        self.register_tool(
            "monte_carlo_sim",
            description="Monte Carlo –∞–Ω–∞–ª–∏–∑ —Ä–∏—Å–∫–æ–≤",
            required_params=["project_data"],
            optional_params={"iterations": 10000, "confidence_level": 0.95, "variables": {}, "seed": None},
            category="super_features"
        )
        
        # ENHANCED / CORE RAG / VISUALIZATION (subset)
        self.register_tool(
            "search_rag_database",
            description="–ü–æ–∏—Å–∫ –≤ –ë–ó —Å SBERT",
            required_params=["query"],
            optional_params={"doc_types": ["norms"], "k": 5, "use_sbert": False, "min_relevance": 0.0},
            category="enhanced"
        )
        # Soft-landing registrations to allow delegation to legacy ToolsSystem without validation failure
        self.register_tool(
            "parse_estimate_unified",
            description="–£–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–∞—Ä—Å–µ—Ä —Å–º–µ—Ç (xls/xlsx/csv)",
            required_params=["estimate_file"],
            optional_params={},
            category="financial"
        )
        self.register_tool(
            "analyze_tender",
            description="–ê–Ω–∞–ª–∏–∑ —Ç–µ–Ω–¥–µ—Ä–Ω–æ–π –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏",
            required_params=[],
            optional_params={"input": None},
            category="analysis"
        )
        self.register_tool(
            "comprehensive_analysis",
            description="–ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –ø—Ä–æ–µ–∫—Ç–∞",
            required_params=[],
            optional_params={"input": None},
            category="analysis"
        )
        self.register_tool(
            "analyze_image",
            description="OCR + –∞–Ω–∞–ª–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π",
            required_params=["image_path"],
            optional_params={"analysis_type": "basic", "ocr_lang": "rus", "detect_objects": True},
            category="enhanced"
        )
        self.register_tool(
            "calculate_financial_metrics",
            description="–§–∏–Ω–∞–Ω—Å–æ–≤—ã–µ —Ä–∞—Å—á—ë—Ç—ã (ROI/NPV/IRR)",
            required_params=["type"],
            optional_params={"profit": 0.0, "cost": 0.0, "investment": 0.0, "revenue": 0.0},
            category="enhanced"
        )
        self.register_tool(
            "create_gantt_chart",
            description="–î–∏–∞–≥—Ä–∞–º–º—ã –ì–∞–Ω—Ç–∞",
            required_params=["tasks"],
            optional_params={"title": "Gantt Chart", "timeline": "auto"},
            category="visualization"
        )
        self.register_tool(
            "create_pie_chart",
            description="–ö—Ä—É–≥–æ–≤—ã–µ –¥–∏–∞–≥—Ä–∞–º–º—ã",
            required_params=["data"],
            optional_params={"title": "Pie Chart", "colors": None},
            category="visualization"
        )
        self.register_tool(
            "create_bar_chart",
            description="–°—Ç–æ–ª–±—á–∞—Ç—ã–µ –¥–∏–∞–≥—Ä–∞–º–º—ã",
            required_params=["data"],
            optional_params={"title": "Bar Chart", "orientation": "vertical"},
            category="visualization"
        )
        self.register_tool(
            "generate_mermaid_diagram",
            description="–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–∏–∞–≥—Ä–∞–º–º Mermaid",
            required_params=["type"],
            optional_params={"data": {}},
            category="visualization"
        )
        self.register_tool(
            "generate_construction_schedule",
            description="–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –≥—Ä–∞—Ñ–∏–∫–∞ —Å—Ç—Ä–æ–∏—Ç–µ–ª—å—Å—Ç–≤–∞",
            required_params=["works"],
            optional_params={"constraints": {}},
            category="project_management"
        )
        self.register_tool(
            "create_construction_schedule",
            description="–°–æ–∑–¥–∞–Ω–∏–µ –∫–∞–ª–µ–Ω–¥–∞—Ä–Ω–æ–≥–æ –≥—Ä–∞—Ñ–∏–∫–∞ —Ä–∞–±–æ—Ç",
            required_params=["works"],
            optional_params={"timeline": {}},
            category="project_management"
        )
        self.register_tool(
            "calculate_critical_path",
            description="–†–∞—Å—á—ë—Ç –∫—Ä–∏—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø—É—Ç–∏",
            required_params=["works"],
            optional_params={"dependencies": []},
            category="project_management"
        )
        self.register_tool(
            "extract_text_from_pdf",
            description="–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∏–∑ PDF",
            required_params=["pdf_path"],
            optional_params={"ocr": True},
            category="analysis"
        )
        self.register_tool(
            "extract_financial_data",
            description="–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö",
            required_params=["document"],
            optional_params={},
            category="financial"
        )
        self.register_tool(
            "text_to_speech",
            description="Text-to-Speech generation with Silero TTS",
            required_params=["text"],
            optional_params={"provider": "silero", "voice": "ru-RU-SvetlanaNeural", "format": "mp3"},
            category="audio"
        )
        
        # PRO FEATURE TOOLS (9) - Additional tools from archive
        self.register_tool(
            "auto_budget",
            description="–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —Å–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ —Å–º–µ—Ç",
            required_params=["estimate_data"],
            optional_params={
                "gesn_rates": {},
                "regional_coefficients": {},
                "overheads_percentage": 15,
                "profit_percentage": 10
            },
            category="pro_features"
        )
        
        self.register_tool(
            "generate_ppr",
            description="–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–æ–µ–∫—Ç–∞ –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–∞ —Ä–∞–±–æ—Ç",
            required_params=["project_data"],
            optional_params={
                "works_seq": [],
                "timeline": None,
                "resources": {},
                "safety_requirements": []
            },
            category="pro_features"
        )
        
        self.register_tool(
            "create_gpp",
            description="–°–æ–∑–¥–∞–Ω–∏–µ –∫–∞–ª–µ–Ω–¥–∞—Ä–Ω–æ–≥–æ –ø–ª–∞–Ω–∞",
            required_params=["works_seq"],
            optional_params={
                "timeline": None,
                "constraints": {},
                "resources": {},
                "dependencies": []
            },
            category="pro_features"
        )
        
        # SUPER FEATURE TOOLS (3)
        self.register_tool(
            "analyze_bentley_model",
            description="–ê–Ω–∞–ª–∏–∑ IFC/BIM –º–æ–¥–µ–ª–µ–π",
            required_params=["ifc_path"],
            optional_params={
                "analysis_type": "clash",
                "output_format": "json",
                "detailed": False
            },
            category="super_features"
        )
        
        self.register_tool(
            "monte_carlo_sim",
            description="Monte Carlo –∞–Ω–∞–ª–∏–∑ —Ä–∏—Å–∫–æ–≤",
            required_params=["project_data"],
            optional_params={
                "iterations": 10000,
                "confidence_level": 0.95,
                "variables": {},
                "seed": None
            },
            category="super_features"
        )
        
        # ENHANCED TOOLS (8)
        self.register_tool(
            "search_rag_database",
            description="–ü–æ–∏—Å–∫ –≤ –ë–ó —Å SBERT",
            required_params=["query"],
            optional_params={
                "doc_types": ["norms"],
                "k": 5,
                "use_sbert": False,
                "embed_model": "nomic",
                "min_relevance": 0.0,
                "security_level": 1,
                "date_range": None,
                "summarize": False
            },
            category="enhanced"
        )
        
        self.register_tool(
            "analyze_image",
            description="OCR + –∞–Ω–∞–ª–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π",
            required_params=["image_path"],
            optional_params={
                "analysis_type": "basic",
                "ocr_lang": "rus",
                "detect_objects": True,
                "extract_dimensions": False
            },
            category="enhanced"
        )
        
        self.register_tool(
            "calculate_financial_metrics",
            description="–§–∏–Ω–∞–Ω—Å–æ–≤—ã–µ —Ä–∞—Å—á—ë—Ç—ã (ROI/NPV/IRR)",
            required_params=["type"],
            optional_params={
                "profit": 0.0,
                "cost": 0.0,
                "investment": 0.0,
                "revenue": 0.0,
                "cash_flows": [],
                "discount_rate": 0.1
            },
            category="enhanced"
        )
        
        # DATA VISUALIZATION TOOLS (5)
        self.register_tool(
            "create_gantt_chart",
            description="–î–∏–∞–≥—Ä–∞–º–º—ã –ì–∞–Ω—Ç–∞",
            required_params=["tasks"],
            optional_params={
                "title": "Gantt Chart",
                "start_date": None,
                "timeline": "auto",
                "dependencies": True,
                "resources": False
            },
            category="visualization"
        )
        
        self.register_tool(
            "create_pie_chart",
            description="–ö—Ä—É–≥–æ–≤—ã–µ –¥–∏–∞–≥—Ä–∞–º–º—ã",
            required_params=["data"],
            optional_params={
                "title": "Pie Chart",
                "colors": None,
                "show_percentages": True,
                "explode": None
            },
            category="visualization"
        )
        
        self.register_tool(
            "create_bar_chart",
            description="–°—Ç–æ–ª–±—á–∞—Ç—ã–µ –¥–∏–∞–≥—Ä–∞–º–º—ã",
            required_params=["data"],
            optional_params={
                "title": "Bar Chart",
                "x_label": "",
                "y_label": "",
                "orientation": "vertical",
                "colors": None
            },
            category="visualization"
        )
        
        self.register_tool(
            "create_line_chart",
            description="–õ–∏–Ω–µ–π–Ω—ã–µ –≥—Ä–∞—Ñ–∏–∫–∏",
            required_params=["data"],
            optional_params={
                "title": "Line Chart",
                "x_label": "",
                "y_label": "",
                "markers": True,
                "grid": True
            },
            category="visualization"
        )
        
        self.register_tool(
            "create_scatter_plot",
            description="–¢–æ—á–µ—á–Ω—ã–µ –¥–∏–∞–≥—Ä–∞–º–º—ã",
            required_params=["data"],
            optional_params={
                "title": "Scatter Plot",
                "x_label": "",
                "y_label": "",
                "color_by": None,
                "size_by": None
            },
            category="visualization"
        )
        
        # PROJECT MANAGEMENT TOOLS (8)
        self.register_tool(
            "generate_construction_schedule",
            description="–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å—Ç—Ä–æ–∏—Ç–µ–ª—å–Ω–æ–≥–æ –∫–∞–ª–µ–Ω–¥–∞—Ä—è",
            required_params=["project_data"],
            optional_params={
                "start_date": None,
                "duration": None,
                "resources": {},
                "constraints": []
            },
            category="project_management"
        )
        
        self.register_tool(
            "calculate_project_metrics",
            description="–†–∞—Å—á—ë—Ç –º–µ—Ç—Ä–∏–∫ –ø—Ä–æ–µ–∫—Ç–∞",
            required_params=["project_data"],
            optional_params={
                "metrics": ["duration", "cost", "resources"],
                "baseline": None,
                "current": None
            },
            category="project_management"
        )
        
        self.register_tool(
            "optimize_resource_allocation",
            description="–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ä–µ—Å—É—Ä—Å–æ–≤",
            required_params=["resources", "tasks"],
            optional_params={
                "constraints": [],
                "objective": "minimize_cost",
                "time_limit": None
            },
            category="project_management"
        )
        
        self.register_tool(
            "generate_risk_assessment",
            description="–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ü–µ–Ω–∫–∏ —Ä–∏—Å–∫–æ–≤",
            required_params=["project_data"],
            optional_params={
                "risk_categories": ["technical", "financial", "schedule"],
                "probability_model": "expert",
                "impact_scale": "1-5"
            },
            category="project_management"
        )
        
        # ANALYSIS TOOLS (6)
        self.register_tool(
            "extract_text_from_pdf",
            description="–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∏–∑ PDF",
            required_params=["pdf_path"],
            optional_params={
                "page_range": None,
                "ocr": False,
                "language": "rus",
                "output_format": "text"
            },
            category="analysis"
        )
        
        self.register_tool(
            "extract_financial_data",
            description="–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö",
            required_params=["document_path"],
            optional_params={
                "data_types": ["costs", "revenues", "budgets"],
                "format": "json",
                "currency": "RUB"
            },
            category="analysis"
        )
        
        self.register_tool(
            "check_normative",
            description="–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è –Ω–æ—Ä–º–∞—Ç–∏–≤–∞–º",
            required_params=["project_data"],
            optional_params={
                "normative_type": "building_codes",
                "region": "RU",
                "detailed_report": True
            },
            category="analysis"
        )
        
        self.register_tool(
            "find_normatives",
            description="–ü–æ–∏—Å–∫ –Ω–æ—Ä–º–∞—Ç–∏–≤–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤",
            required_params=["query"],
            optional_params={
                "document_types": ["SNiP", "GOST", "SP"],
                "region": "RU",
                "date_range": None
            },
            category="analysis"
        )
        
        self.register_tool(
            "semantic_parse",
            description="–°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ —Ç–µ–∫—Å—Ç–∞",
            required_params=["text"],
            optional_params={
                "analysis_type": "entities",
                "language": "ru",
                "domain": "construction"
            },
            category="analysis"
        )
        
        self.register_tool(
            "generate_mermaid_diagram",
            description="–ì–µ–Ω–µ—Ä–∞—Ü–∏—è Mermaid –¥–∏–∞–≥—Ä–∞–º–º",
            required_params=["diagram_type", "data"],
            optional_params={
                "title": "",
                "theme": "default",
                "direction": "TD"
            },
            category="analysis"
        )
        
        # ARTIFACT GENERATION TOOLS (universal)
        self.register_tool(
            "auto_export",
            description="–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π —ç–∫—Å–ø–æ—Ä—Ç –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –≤ —Ñ–∞–π–ª (docx/pdf/txt/json/csv)",
            required_params=["content", "filename", "format"],
            optional_params={"encoding": "utf-8"},
            category="artifact"
        )
        self.register_tool(
            "create_document",
            description="–°–æ–∑–¥–∞–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞ (DOCX/PDF) –∏–∑ –∫–æ–Ω—Ç–µ–Ω—Ç–∞",
            required_params=["content", "filename"],
            optional_params={"format": "docx", "encoding": "utf-8"},
            category="artifact"
        )
        self.register_tool(
            "create_spreadsheet",
            description="–°–æ–∑–¥–∞–Ω–∏–µ —Ç–∞–±–ª–∏—á–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ (CSV/XLSX)",
            required_params=["content", "filename"],
            optional_params={"format": "csv", "encoding": "utf-8"},
            category="artifact"
        )

        # ADDITIONAL TOOLS FROM ARCHIVE (17+ tools)
        
        # ENHANCED RAG PROCESSORS (3)
        self.register_tool(
            "process_document_for_frontend",
            description="Frontend-—Å–æ–≤–º–µ—Å—Ç–∏–º–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤",
            required_params=["document_path"],
            optional_params={
                "output_format": "json",
                "include_metadata": True,
                "chunk_size": 1000
            },
            category="rag_processing"
        )
        
        self.register_tool(
            "extract_works_with_sbert",
            description="SBERT-–∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ä–∞–±–æ—Ç",
            required_params=["text"],
            optional_params={
                "model": "sbert",
                "confidence_threshold": 0.8,
                "output_format": "json"
            },
            category="rag_processing"
        )
        
        self.register_tool(
            "smart_chunk",
            description="–ò–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–æ–µ —Ä–∞–∑–±–∏–µ–Ω–∏–µ –Ω–∞ —á–∞–Ω–∫–∏",
            required_params=["text"],
            optional_params={
                "chunk_size": 1000,
                "overlap": 200,
                "preserve_sentences": True
            },
            category="rag_processing"
        )
        
        # STRUCTURE EXTRACTORS (4)
        self.register_tool(
            "extract_full_structure",
            description="–ü–æ–ª–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–æ–∫—É–º–µ–Ω—Ç–∞",
            required_params=["document_path"],
            optional_params={
                "include_tables": True,
                "include_images": False,
                "output_format": "json"
            },
            category="structure_extraction"
        )
        
        self.register_tool(
            "extract_complete_structure",
            description="–ö–æ–º–ø–ª–µ–∫—Å–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã",
            required_params=["document_path"],
            optional_params={
                "depth": "full",
                "include_metadata": True,
                "format": "hierarchical"
            },
            category="structure_extraction"
        )
        
        self.register_tool(
            "create_intelligent_chunks",
            description="–°–æ–∑–¥–∞–Ω–∏–µ —É–º–Ω—ã—Ö —á–∞–Ω–∫–æ–≤",
            required_params=["text"],
            optional_params={
                "chunk_size": 1000,
                "overlap": 200,
                "semantic_boundaries": True
            },
            category="structure_extraction"
        )
        
        self.register_tool(
            "get_frontend_compatible_structure",
            description="Frontend-—Å–æ–≤–º–µ—Å—Ç–∏–º—ã–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã",
            required_params=["data"],
            optional_params={
                "format": "react_compatible",
                "include_ui_hints": True
            },
            category="structure_extraction"
        )
        
        # ASYNC AI PROCESSORS (2)
        self.register_tool(
            "submit_ai_request",
            description="–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–µ AI-–∑–∞–ø—Ä–æ—Å—ã",
            required_params=["request_data"],
            optional_params={
                "priority": "normal",
                "timeout": 300,
                "callback_url": None
            },
            category="async_processing"
        )
        
        self.register_tool(
            "get_task_status",
            description="–°—Ç–∞—Ç—É—Å –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã—Ö –∑–∞–¥–∞—á",
            required_params=["task_id"],
            optional_params={
                "include_result": False,
                "include_logs": False
            },
            category="async_processing"
        )
        
        # NORMS & NTD PROCESSORS (4)
        self.register_tool(
            "dedup_and_restructure",
            description="–î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è –Ω–æ—Ä–º–∞—Ç–∏–≤–æ–≤",
            required_params=["normative_data"],
            optional_params={
                "similarity_threshold": 0.8,
                "merge_strategy": "keep_latest"
            },
            category="norms_processing"
        )
        
        self.register_tool(
            "merge_bases",
            description="–°–ª–∏—è–Ω–∏–µ –±–∞–∑ –Ω–æ—Ä–º–∞—Ç–∏–≤–æ–≤",
            required_params=["base1", "base2"],
            optional_params={
                "conflict_resolution": "merge",
                "validate_consistency": True
            },
            category="norms_processing"
        )
        
        self.register_tool(
            "ntd_preprocess",
            description="–ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –ù–¢–î",
            required_params=["ntd_document"],
            optional_params={
                "extract_metadata": True,
                "normalize_format": True
            },
            category="norms_processing"
        )
        
        self.register_tool(
            "search_documents",
            description="–ü–æ–∏—Å–∫ –≤ –ù–¢–î –±–∞–∑–µ",
            required_params=["query"],
            optional_params={
                "document_types": ["norms", "standards"],
                "date_range": None,
                "region": "RU"
            },
            category="norms_processing"
        )
        
        # TEMPLATE & PROJECT MANAGERS (2)
        self.register_tool(
            "create_template",
            description="–°–æ–∑–¥–∞–Ω–∏–µ —à–∞–±–ª–æ–Ω–æ–≤",
            required_params=["template_data"],
            optional_params={
                "template_type": "document",
                "category": "general",
                "reusable": True
            },
            category="template_management"
        )
        
        self.register_tool(
            "create_project",
            description="–°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–æ–≤",
            required_params=["project_data"],
            optional_params={
                "project_type": "construction",
                "region": "moscow",
                "auto_setup": True
            },
            category="project_management"
        )
        
        # ADDITIONAL DISCOVERED (2+)
        self.register_tool(
            "categorize_document",
            description="–ö–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤",
            required_params=["document_path"],
            optional_params={
                "categories": ["estimate", "project", "normative"],
                "confidence_threshold": 0.7
            },
            category="document_processing"
        )
        
        self.register_tool(
            "update_database",
            description="–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö",
            required_params=["update_data"],
            optional_params={
                "database": "neo4j",
                "validate": True,
                "backup": True
            },
            category="database_management"
        )
        
        # MISSING PRO FEATURE TOOLS
        self.register_tool(
            "parse_batch_estimates",
            description="–ú–∞—Å—Å–æ–≤—ã–π –ø–∞—Ä—Å–∏–Ω–≥ —Å–º–µ—Ç",
            required_params=["estimate_files"],
            optional_params={
                "batch_size": 10,
                "parallel_processing": True,
                "output_format": "json"
            },
            category="pro_features"
        )
        
        # MISSING EXISTING TOOLS
        self.register_tool(
            "calculate_estimate",
            description="–†–∞—Å—á—ë—Ç —Å–º–µ—Ç —Å –ì–≠–°–ù/–§–ï–†",
            required_params=["estimate_data"],
            optional_params={
                "gesn_rates": {},
                "regional_coefficients": {},
                "overheads": 15
            },
            category="financial"
        )
        
        self.register_tool(
            "get_work_sequence",
            description="–ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Ä–∞–±–æ—Ç (Neo4j)",
            required_params=["project_id"],
            optional_params={
                "include_dependencies": True,
                "optimize_order": True
            },
            category="project_management"
        )
        
        self.register_tool(
            "extract_construction_data",
            description="–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å—Ç—Ä–æ–∏—Ç–µ–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö",
            required_params=["document"],
            optional_params={
                "data_types": ["materials", "works", "costs"],
                "format": "structured"
            },
            category="analysis"
        )
        
        # Bind native implementations for artifact tools
        self.tools_methods["auto_export"] = self._tool_auto_export
        self.tools_methods["create_document"] = self._tool_create_document
        self.tools_methods["create_spreadsheet"] = self._tool_create_spreadsheet

        logger.info(f"Registered {len(self.tools_registry)} tools in unified system")
    
    def register_tool(self, name: str, description: str, 
                     required_params: Optional[List[str]] = None,
                     optional_params: Optional[Dict[str, Any]] = None,
                     category: str = "general"):
        """–†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è –Ω–æ–≤–æ–≥–æ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞"""
        signature = ToolSignature(
            name=name,
            description=description,
            required_params=required_params or [],
            optional_params=optional_params or {},
            category=category
        )
        self.tools_registry[name] = signature
    
    def validate_tool_call(self, tool_name: str, **kwargs) -> None:
        """üöÄ –£–õ–£–ß–®–ï–ù–ù–ê–Ø –í–ê–õ–ò–î–ê–¶–ò–Ø: –° –¥–µ—Ç–∞–ª—å–Ω—ã–º–∏ —Å–æ–æ–±—â–µ–Ω–∏—è–º–∏ –æ–± –æ—à–∏–±–∫–∞—Ö"""
        if tool_name not in self.tools_registry:
            raise ToolValidationError(
                tool_name=tool_name,
                parameter="tool_name",
                value=tool_name,
                expected_type="registered_tool"
            )
        
        signature = self.tools_registry[tool_name]
        missing = [p for p in signature.required_params if p not in kwargs]
        if missing:
            # üöÄ –î–ï–¢–ê–õ–¨–ù–ê–Ø –û–®–ò–ë–ö–ê: –£–∫–∞–∑—ã–≤–∞–µ–º –∫–∞–∫–æ–π –∏–º–µ–Ω–Ω–æ –ø–∞—Ä–∞–º–µ—Ç—Ä –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç
            for param in missing:
                raise ToolValidationError(
                    tool_name=tool_name,
                    parameter=param,
                    value=None,
                    expected_type="required"
                )
        
        for param, default_value in signature.optional_params.items():
            if param not in kwargs:
                kwargs[param] = default_value
    
    def execute_tool(self, tool_name: str, user_id: str = "anonymous", **kwargs) -> ToolResult:
        """
        üöÄ –ë–ï–ó–û–ü–ê–°–ù–û–ï –í–´–ü–û–õ–ù–ï–ù–ò–ï –ò–ù–°–¢–†–£–ú–ï–ù–¢–ê
        
        Args:
            tool_name: –ò–º—è –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞
            user_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –¥–æ—Å—Ç—É–ø–∞
            **kwargs: –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞
        
        Returns:
            ToolResult —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–º –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
        """
        start_time = datetime.now()
        try:
            # üöÄ –ü–†–û–í–ï–†–ö–ê –î–û–°–¢–£–ü–ê: –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–∞–≤–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            if not self.auth_manager.check_tool_access(user_id, tool_name):
                return ToolResult(
                    status="error",
                    error=f"Access denied for tool {tool_name}",
                    tool_name=tool_name
                )
            
            # Prefer SBERT for RU search by default (better recall)
            if tool_name == "search_rag_database" and "use_sbert" not in kwargs:
                kwargs["use_sbert"] = True
            
            self.validate_tool_call(tool_name, **kwargs)
            if tool_name in self.tools_methods:
                result_data = self.tools_methods[tool_name](**kwargs)
            else:
                result_data = self._execute_legacy_tool(tool_name, **kwargs)
            
            # üöÄ –°–û–•–†–ê–ù–ï–ù–ò–ï –í –ü–ê–ú–Ø–¢–¨: –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
            if result_data:
                memory_content = f"Tool {tool_name} executed by user {user_id}: {str(result_data)[:200]}"
                # –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ –ø–∞–º—è—Ç—å (–Ω–µ –±–ª–æ–∫–∏—Ä—É–µ–º –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ)
                import asyncio
                try:
                    loop = asyncio.get_event_loop()
                    loop.create_task(self.memory_system.store_memory(
                        content=memory_content,
                        metadata={
                            "tool_name": tool_name,
                            "user_id": user_id,
                            "timestamp": datetime.now().isoformat()
                        },
                        tags=["tool_execution", tool_name],
                        importance_score=0.3
                    ))
                except RuntimeError:
                    # –ï—Å–ª–∏ –Ω–µ—Ç event loop, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ –ø–∞–º—è—Ç—å
                    pass
            
            execution_time = (datetime.now() - start_time).total_seconds()
            result = ToolResult(status="success", data=result_data, tool_name=tool_name, execution_time=execution_time)
            self._update_execution_stats(tool_name, True, execution_time)
            return result
        except ToolValidationError as e:
            execution_time = (datetime.now() - start_time).total_seconds()
            self._update_execution_stats(tool_name, False, execution_time)
            return ToolResult(status="error", error=f"Validation error: {str(e)}", tool_name=tool_name, execution_time=execution_time)
        except Exception as e:
            execution_time = (datetime.now() - start_time).total_seconds()
            res = ToolResult(status="error", error=f"Execution error: {str(e)}", tool_name=tool_name, execution_time=execution_time)
            res.set_metadata("traceback", traceback.format_exc())
            self._update_execution_stats(tool_name, False, execution_time)
            return res
    
    def _execute_legacy_tool(self, tool_name: str, **kwargs) -> Any:
        # Delegate to consolidated ToolsSystem with injected RAG/model manager
        legacy = self._ensure_legacy_system()
        return legacy.execute_tool(tool_name, dict(kwargs))
    
    def _ensure_legacy_system(self):
        if self._legacy_tools_system is None:
            from core.tools_system import ToolsSystem
            self._legacy_tools_system = ToolsSystem(rag_system=self.rag_system, model_manager=self.model_manager)
        return self._legacy_tools_system
    
    def _tool_auto_export(self, content: Any, filename: str, format: str, encoding: str = "utf-8") -> Dict[str, Any]:
        """Universal export: writes content to exports/<filename> with selected format.
        Supported formats: txt, md, json, csv, docx (xlsx falls back to csv).
        """
        from pathlib import Path
        import json as _json
        import csv as _csv
        import os as _os
        import re as _re
        outdir = Path("exports")
        outdir.mkdir(parents=True, exist_ok=True)
        fmt = (format or "txt").lower()
        # sanitize filename
        base = _re.sub(r"[^\w\-\.]+", "_", filename.strip()) or "artifact"
        if "." in base:
            stem, ext = base.rsplit(".", 1)
        else:
            stem, ext = base, fmt
        # normalize extension by format
        ext_map = {"md": ".md", "txt": ".txt", "json": ".json", "csv": ".csv", "docx": ".docx", "xlsx": ".xlsx", "pdf": ".pdf"}
        target_ext = ext_map.get(fmt, ".txt")
        p = outdir / f"{stem}{target_ext}"
        # perform write
        if fmt in ("txt", "md"):
            p.write_text(str(content), encoding=encoding)
        elif fmt == "json":
            p.write_text(_json.dumps(content, ensure_ascii=False, indent=2), encoding=encoding)
        elif fmt in ("csv", "xlsx"):
            # xlsx fallback to csv to avoid heavy deps; client can convert if needed
            with p.with_suffix(".csv").open("w", newline="", encoding=encoding) as f:
                if isinstance(content, list) and content and isinstance(content[0], dict):
                    w = _csv.DictWriter(f, fieldnames=list(content[0].keys()))
                    w.writeheader(); w.writerows(content)
                elif isinstance(content, list):
                    for row in content:
                        if isinstance(row, (list, tuple)):
                            f.write(",".join(map(str, row)) + "\n")
                        else:
                            f.write(str(row) + "\n")
                elif isinstance(content, dict):
                    w = _csv.DictWriter(f, fieldnames=list(content.keys()))
                    w.writeheader(); w.writerow(content)
                else:
                    f.write(str(content))
            p = p.with_suffix(".csv")
        elif fmt == "docx":
            try:
                from docx import Document  # type: ignore
                doc = Document()
                def add_block(x: Any):
                    if x is None:
                        return
                    if isinstance(x, str):
                        for line in x.splitlines():
                            doc.add_paragraph(line)
                    elif isinstance(x, (list, tuple)):
                        for it in x:
                            add_block(it)
                    elif isinstance(x, dict):
                        for k, v in x.items():
                            doc.add_paragraph(f"{k}: {v}")
                    else:
                        doc.add_paragraph(str(x))
                add_block(content)
                doc.save(str(p))
            except Exception as e:
                # fallback to txt
                p = p.with_suffix(".txt")
                p.write_text(str(content) + f"\n\n[docx export failed: {e}]", encoding=encoding)
        elif fmt == "pdf":
            # minimal fallback: write markdown/txt and leave as .txt; real pdf gen may require heavy deps
            p = p.with_suffix(".txt")
            p.write_text(str(content) + "\n\n[hint: convert to PDF externally]", encoding=encoding)
        else:
            p = p.with_suffix(".txt")
            p.write_text(str(content), encoding=encoding)
        return {"file_path": str(p)}

    def _tool_create_document(self, content: Any, filename: str, format: str = "docx", encoding: str = "utf-8") -> Dict[str, Any]:
        return self._tool_auto_export(content=content, filename=filename, format=(format or "docx"), encoding=encoding)

    def _tool_create_spreadsheet(self, content: Any, filename: str, format: str = "csv", encoding: str = "utf-8") -> Dict[str, Any]:
        fmt = (format or "csv")
        if fmt.lower() not in ("csv", "xlsx"):
            fmt = "csv"
        return self._tool_auto_export(content=content, filename=filename, format=fmt, encoding=encoding)

    def _update_execution_stats(self, tool_name: str, success: bool, execution_time: float):
        if tool_name not in self.execution_stats:
            self.execution_stats[tool_name] = {
                "total_calls": 0,
                "successful_calls": 0,
                "failed_calls": 0,
                "avg_execution_time": 0.0,
                "total_execution_time": 0.0
            }
        stats = self.execution_stats[tool_name]
        stats["total_calls"] += 1
        stats["total_execution_time"] += execution_time
        stats["avg_execution_time"] = stats["total_execution_time"] / stats["total_calls"]
        if success:
            stats["successful_calls"] += 1
        else:
            stats["failed_calls"] += 1
    
    async def execute_tool_async(self, tool_name: str, timeout_seconds: Optional[int] = None, **kwargs) -> ToolResult:
        """
        üöÄ –ê–°–ò–ù–•–†–û–ù–ù–û–ï –í–´–ü–û–õ–ù–ï–ù–ò–ï –ò–ù–°–¢–†–£–ú–ï–ù–¢–ê –° –¢–ê–ô–ú–ê–£–¢–û–ú
        
        Args:
            tool_name: –ò–º—è –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞
            timeout_seconds: –¢–∞–π–º–∞—É—Ç –≤ —Å–µ–∫—É–Ω–¥–∞—Ö
            **kwargs: –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞
        
        Returns:
            ToolResult —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–º –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
        """
        if not self.async_executor:
            raise ToolResourceError(tool_name, "async_executor", "–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –∏—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—å –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
        
        try:
            # –í–∞–ª–∏–¥–∞—Ü–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
            self.validate_tool_call(tool_name, **kwargs)
            
            # –ü–æ–ª—É—á–∞–µ–º —Ñ—É–Ω–∫—Ü–∏—é –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞
            if tool_name not in self.tools_methods:
                raise ToolDependencyError(tool_name, "tool_method", "–ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω")
            
            tool_func = self.tools_methods[tool_name]
            
            # –í—ã–ø–æ–ª–Ω—è–µ–º –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ —Å —Ç–∞–π–º–∞—É—Ç–æ–º
            result_data = await self.async_executor.execute_with_retries(
                tool_func=tool_func,
                tool_name=tool_name,
                kwargs=kwargs,
                timeout_seconds=timeout_seconds
            )
            
            return ToolResult(
                status="success",
                data=result_data,
                tool_name=tool_name
            )
            
        except ToolExecutionTimeoutError as e:
            return ToolResult(
                status="error",
                error=str(e),
                tool_name=tool_name
            )
        except Exception as e:
            return ToolResult(
                status="error",
                error=f"Execution error: {str(e)}",
                tool_name=tool_name
            )
    
    async def execute_multiple_tools_async(self, 
                                          tool_calls: List[Dict[str, Any]], 
                                          max_concurrent: int = 3) -> Dict[str, ToolResult]:
        """
        üöÄ –ü–ê–†–ê–õ–õ–ï–õ–¨–ù–û–ï –í–´–ü–û–õ–ù–ï–ù–ò–ï –ù–ï–°–ö–û–õ–¨–ö–ò–• –ò–ù–°–¢–†–£–ú–ï–ù–¢–û–í
        
        Args:
            tool_calls: –°–ø–∏—Å–æ–∫ –≤—ã–∑–æ–≤–æ–≤ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤
            max_concurrent: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–π
        
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
        """
        if not self.async_executor:
            raise ToolResourceError("multiple_tools", "async_executor", "–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –∏—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—å –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
        
        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –≤—ã–∑–æ–≤—ã –¥–ª—è –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–≥–æ –∏—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—è
        prepared_calls = []
        for call in tool_calls:
            tool_name = call["tool_name"]
            kwargs = call.get("kwargs", {})
            timeout = call.get("timeout")
            
            if tool_name not in self.tools_methods:
                continue
            
            prepared_calls.append({
                "name": tool_name,
                "func": self.tools_methods[tool_name],
                "kwargs": kwargs,
                "timeout": timeout
            })
        
        # –í—ã–ø–æ–ª–Ω—è–µ–º –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ
        results = await self.async_executor.execute_multiple_tools(
            prepared_calls, max_concurrent
        )
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ ToolResult
        tool_results = {}
        for tool_name, result in results.items():
            if result["status"] == "success":
                tool_results[tool_name] = ToolResult(
                    status="success",
                    data=result["result"],
                    tool_name=tool_name
                )
            else:
                tool_results[tool_name] = ToolResult(
                    status="error",
                    error=result["error"],
                    tool_name=tool_name
                )
        
        return tool_results
    
    def get_tool_info(self, tool_name: str) -> Optional[ToolSignature]:
        return self.tools_registry.get(tool_name)
    
    def list_tools(self, category: Optional[str] = None) -> List[ToolSignature]:
        if category:
            return [sig for sig in self.tools_registry.values() if sig.category == category]
        return list(self.tools_registry.values())
    
    def get_categories(self) -> List[str]:
        return list(set(sig.category for sig in self.tools_registry.values()))
    
    def get_execution_stats(self, tool_name: Optional[str] = None) -> Dict[str, Any]:
        if tool_name:
            return self.execution_stats.get(tool_name, {})
        return self.execution_stats
    
    def _init_tool_methods(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–µ—Ç–æ–¥–æ–≤ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤"""
        self.tools_methods = {
            "search_rag_database": self._search_rag_database,
            "analyze_image": self._analyze_image,
            "transcribe_audio": self._transcribe_audio,
            "create_document": self._create_document,
            "generate_letter": self._generate_letter,
            "auto_budget": self._auto_budget,
            "generate_ppr": self._generate_ppr,
            "create_gpp": self._create_gpp,
            "analyze_tender": self._analyze_tender,
            "comprehensive_analysis": self._comprehensive_analysis,
            "monte_carlo_sim": self._monte_carlo_sim,
            "calculate_financial_metrics": self._calculate_financial_metrics,
            "extract_text_from_pdf": self._extract_text_from_pdf,
            "analyze_bentley_model": self._analyze_bentley_model,
            "autocad_export": self._autocad_export,
        }
    
    def _search_rag_database(self, query: str, **kwargs) -> Dict[str, Any]:
        """–ü–æ–∏—Å–∫ –≤ RAG –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö"""
        try:
            # –ü–æ–ø—Ä–æ–±—É–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å trainer –¥–ª—è —Ä–µ–∞–ª—å–Ω–æ–≥–æ RAG –ø–æ–∏—Å–∫–∞
            try:
                import sys
                import os
                sys.path.append(os.path.dirname(os.path.dirname(__file__)))
                
                # –ü–æ–ø—Ä–æ–±—É–µ–º –ø–æ–ª—É—á–∏—Ç—å trainer –∏–∑ main.py
                from main import trainer
                if trainer and hasattr(trainer, 'query_with_filters'):
                    print(f"üîç –†–µ–∞–ª—å–Ω—ã–π –ø–æ–∏—Å–∫ —á–µ—Ä–µ–∑ trainer: {query}")
                    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º doc_types –≤ —Å–ø–∏—Å–æ–∫ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
                    doc_types = kwargs.get("doc_types", ["norms"])
                    if isinstance(doc_types, str):
                        doc_types = [doc_types]
                    results = trainer.query_with_filters(
                        question=query,
                        k=kwargs.get("k", 5),
                        doc_types=doc_types,
                        threshold=0.3
                    )
                elif trainer and hasattr(trainer, 'query'):
                    print(f"üîç –ü—Ä–æ—Å—Ç–æ–π –ø–æ–∏—Å–∫ —á–µ—Ä–µ–∑ trainer: {query}")
                    results = trainer.query(
                        question=query,
                        k=kwargs.get("k", 5)
                    )
                
                # –ï—Å–ª–∏ trainer —Å—Ä–∞–±–æ—Ç–∞–ª, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
                if 'results' in locals():
                    # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–ª—è UI
                    formatted_results = []
                    for result in results.get("results", []):
                        formatted_results.append({
                            "content": result.get("content", result.get("chunk", "")),
                            "source": result.get("source", result.get("file_path", "–ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π")),
                            "relevance": result.get("score", result.get("relevance", 0.8)),
                            "title": result.get("title", result.get("file_path", "–î–æ–∫—É–º–µ–Ω—Ç"))
                        })
                    
                    return {
                        "status": "success",
                        "query": query,
                        "results": formatted_results,
                        "total_found": len(formatted_results),
                        "execution_time": results.get("execution_time", 0)
                    }
                    
            except Exception as trainer_error:
                print(f"‚ö†Ô∏è Trainer –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {trainer_error}")
            
            # –ï—Å–ª–∏ –µ—Å—Ç—å RAG —Å–∏—Å—Ç–µ–º–∞, –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ—ë
            if self.rag_system and hasattr(self.rag_system, 'search'):
                print(f"üîç –ü–æ–∏—Å–∫ —á–µ—Ä–µ–∑ RAG —Å–∏—Å—Ç–µ–º—É: {query}")
                results = self.rag_system.search(
                    query=query,
                    doc_types=kwargs.get("doc_types", ["norms"]),
                    k=kwargs.get("k", 5),
                    use_sbert=kwargs.get("use_sbert", True)
                )
                # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–ª—è UI
                formatted_results = []
                for result in results.get("results", []):
                    formatted_results.append({
                        "content": result.get("content", result.get("chunk", "")),
                        "source": result.get("source", result.get("file_path", "–ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π")),
                        "relevance": result.get("score", result.get("relevance", 0.8)),
                        "title": result.get("title", result.get("file_path", "–î–æ–∫—É–º–µ–Ω—Ç"))
                    })
                
                return {
                    "status": "success",
                    "query": query,
                    "results": formatted_results,
                    "total_found": len(formatted_results),
                    "execution_time": results.get("execution_time", 0)
                }
            else:
                # Fallback: –ø—Ä–æ—Å—Ç–æ–π –ø–æ–∏—Å–∫ –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º
                print(f"üîç Fallback –ø–æ–∏—Å–∫: {query}")
                
                # –ü–æ–ø—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ —Ä–µ–∞–ª—å–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö
                try:
                    # –ü—Ä–æ—Å—Ç–æ–π —Ç–µ–∫—Å—Ç–æ–≤—ã–π –ø–æ–∏—Å–∫ –ø–æ —Ñ–∞–π–ª–∞–º
                    import os
                    import glob
                    
                    base_dir = os.getenv("BASE_DIR", "I:/docs")
                    search_results = []
                    
                    # –ò—â–µ–º —Ñ–∞–π–ª—ã —Å —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–º–∏ –∫–ª—é—á–µ–≤—ã–º–∏ —Å–ª–æ–≤–∞–º–∏
                    keywords = query.lower().split()
                    relevant_files = []
                    
                    for root, dirs, files in os.walk(base_dir):
                        for file in files:
                            if file.endswith(('.pdf', '.txt', '.doc', '.docx')):
                                file_path = os.path.join(root, file)
                                try:
                                    with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                                        content = f.read(1000).lower()  # –ß–∏—Ç–∞–µ–º –ø–µ—Ä–≤—ã–µ 1000 —Å–∏–º–≤–æ–ª–æ–≤
                                        if any(keyword in content for keyword in keywords):
                                            relevant_files.append({
                                                'file': file,
                                                'path': file_path,
                                                'content': content[:200] + '...' if len(content) > 200 else content
                                            })
                                except:
                                    continue
                    
                    # –§–æ—Ä–º–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
                    for i, file_info in enumerate(relevant_files[:5]):  # –ú–∞–∫—Å–∏–º—É–º 5 —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
                        search_results.append({
                            "content": f"–ù–∞–π–¥–µ–Ω –¥–æ–∫—É–º–µ–Ω—Ç: {file_info['file']}\n{file_info['content']}",
                            "source": file_info['path'],
                            "relevance": 0.9 - (i * 0.1),  # –£–±—ã–≤–∞—é—â–∞—è —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å
                            "title": file_info['file']
                        })
                    
                    if search_results:
                        return {
                            "status": "success",
                            "query": query,
                            "results": search_results,
                            "total_found": len(search_results),
                            "execution_time": 0.1
                        }
                    
                except Exception as e:
                    print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —Ñ–∞–π–ª–æ–≤–æ–≥–æ –ø–æ–∏—Å–∫–∞: {e}")
                
                # –ï—Å–ª–∏ –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∑–∞–≥–ª—É—à–∫—É
                return {
                    "status": "success",
                    "query": query,
                    "results": [
                        {
                            "content": f"–ù–∞–π–¥–µ–Ω–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –ø–æ –∑–∞–ø—Ä–æ—Å—É: {query}",
                            "source": "–ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π",
                            "relevance": 0.8,
                            "title": "–†–µ–∑—É–ª—å—Ç–∞—Ç –ø–æ–∏—Å–∫–∞"
                        }
                    ],
                    "total_found": 1,
                    "execution_time": 0.1
                }
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –≤ RAG: {e}")
            return {
                "status": "error",
                "error": str(e),
                "query": query,
                "results": [],
                "total_found": 0
            }
    
    def _analyze_image(self, image_path: str, **kwargs) -> Dict[str, Any]:
        """‚úÖ –†–ï–ê–õ–¨–ù–ê–Ø –†–ï–ê–õ–ò–ó–ê–¶–ò–Ø: –ê–Ω–∞–ª–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —á–µ—Ä–µ–∑ tools_system"""
        try:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ä–µ–∞–ª—å–Ω—É—é —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—é –∏–∑ tools_system
            from core.tools_system import ToolsSystem
            tools_system = ToolsSystem()
            return tools_system._analyze_image(image_path=image_path, **kwargs)
        except Exception as e:
            # üöÄ –ù–û–í–´–ô –°–¢–ê–ù–î–ê–†–¢: –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π error —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            from core.tools.base_tool import tool_registry
            error_result = tool_registry.create_error_result(
                tool_name="analyze_image",
                error=e
            )
            return error_result.dict()
    
    def _transcribe_audio(self, audio_path: str, **kwargs) -> Dict[str, Any]:
        """‚úÖ –†–ï–ê–õ–¨–ù–ê–Ø –†–ï–ê–õ–ò–ó–ê–¶–ò–Ø: –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è –∞—É–¥–∏–æ —á–µ—Ä–µ–∑ tools_system"""
        try:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ä–µ–∞–ª—å–Ω—É—é —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—é –∏–∑ tools_system
            from core.tools_system import ToolsSystem
            tools_system = ToolsSystem()
            return tools_system._transcribe_audio(audio_path=audio_path, **kwargs)
        except Exception as e:
            return {
                "status": "error", 
                "message": f"‚ùå –û—à–∏–±–∫–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏ –∞—É–¥–∏–æ: {str(e)}", 
                "tool_name": "transcribe_audio",
                "audio_path": audio_path
            }
    
    def _create_document(self, **kwargs) -> Dict[str, Any]:
        """‚úÖ –†–ï–ê–õ–¨–ù–ê–Ø –†–ï–ê–õ–ò–ó–ê–¶–ò–Ø: –°–æ–∑–¥–∞–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞ —á–µ—Ä–µ–∑ tools_system"""
        try:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ä–µ–∞–ª—å–Ω—É—é —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—é –∏–∑ tools_system
            from core.tools_system import ToolsSystem
            tools_system = ToolsSystem()
            return tools_system._create_document(**kwargs)
        except Exception as e:
            return {
                "status": "error", 
                "message": f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–∞: {str(e)}", 
                "tool_name": "create_document"
            }
    
    def _generate_letter(self, **kwargs) -> Dict[str, Any]:
        """‚úÖ –†–ï–ê–õ–¨–ù–ê–Ø –†–ï–ê–õ–ò–ó–ê–¶–ò–Ø: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø–∏—Å—å–º–∞ —á–µ—Ä–µ–∑ tools_system"""
        try:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ä–µ–∞–ª—å–Ω—É—é —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—é –∏–∑ tools_system
            from core.tools_system import ToolsSystem
            tools_system = ToolsSystem()
            return tools_system._generate_letter(**kwargs)
        except Exception as e:
            return {
                "status": "error", 
                "message": f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø–∏—Å—å–º–∞: {str(e)}", 
                "tool_name": "generate_letter"
            }
    
    def _auto_budget(self, **kwargs) -> Dict[str, Any]:
        """‚úÖ –†–ï–ê–õ–¨–ù–ê–Ø –†–ï–ê–õ–ò–ó–ê–¶–ò–Ø: –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –±—é–¥–∂–µ—Ç —á–µ—Ä–µ–∑ tools_system"""
        try:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ä–µ–∞–ª—å–Ω—É—é —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—é –∏–∑ tools_system
            from core.tools_system import ToolsSystem
            tools_system = ToolsSystem()
            return tools_system._auto_budget(**kwargs)
        except Exception as e:
            return {
                "status": "error", 
                "message": f"‚ùå –û—à–∏–±–∫–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –±—é–¥–∂–µ—Ç–∞: {str(e)}", 
                "tool_name": "auto_budget"
            }
    
    def _generate_ppr(self, **kwargs) -> Dict[str, Any]:
        """‚úÖ –†–ï–ê–õ–¨–ù–ê–Ø –†–ï–ê–õ–ò–ó–ê–¶–ò–Ø: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ü–ü–† —á–µ—Ä–µ–∑ tools_system"""
        try:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ä–µ–∞–ª—å–Ω—É—é —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—é –∏–∑ tools_system
            from core.tools_system import ToolsSystem
            tools_system = ToolsSystem()
            return tools_system._generate_ppr(**kwargs)
        except Exception as e:
            return {
                "status": "error", 
                "message": f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ü–ü–†: {str(e)}", 
                "tool_name": "generate_ppr"
            }
    
    def _create_gpp(self, **kwargs) -> Dict[str, Any]:
        """‚úÖ –†–ï–ê–õ–¨–ù–ê–Ø –†–ï–ê–õ–ò–ó–ê–¶–ò–Ø: –°–æ–∑–¥–∞–Ω–∏–µ –ì–ü–ü —á–µ—Ä–µ–∑ tools_system"""
        try:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ä–µ–∞–ª—å–Ω—É—é —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—é –∏–∑ tools_system
            from core.tools_system import ToolsSystem
            tools_system = ToolsSystem()
            return tools_system._create_gpp(**kwargs)
        except Exception as e:
            return {
                "status": "error", 
                "message": f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –ì–ü–ü: {str(e)}", 
                "tool_name": "create_gpp"
            }
    
    def _analyze_tender(self, **kwargs) -> Dict[str, Any]:
        """‚úÖ –†–ï–ê–õ–¨–ù–ê–Ø –†–ï–ê–õ–ò–ó–ê–¶–ò–Ø: –ê–Ω–∞–ª–∏–∑ —Ç–µ–Ω–¥–µ—Ä–∞ —á–µ—Ä–µ–∑ tools_system"""
        try:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ä–µ–∞–ª—å–Ω—É—é —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—é –∏–∑ tools_system
            from core.tools_system import ToolsSystem
            tools_system = ToolsSystem()
            return tools_system._analyze_tender(**kwargs)
        except Exception as e:
            return {
                "status": "error", 
                "message": f"‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ —Ç–µ–Ω–¥–µ—Ä–∞: {str(e)}", 
                "tool_name": "analyze_tender"
            }
    
    def _comprehensive_analysis(self, **kwargs) -> Dict[str, Any]:
        """–ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –∞–Ω–∞–ª–∏–∑"""
        return {"status": "success", "message": "–ê–Ω–∞–ª–∏–∑ –≤—ã–ø–æ–ª–Ω–µ–Ω"}
    
    def _monte_carlo_sim(self, **kwargs) -> Dict[str, Any]:
        """Monte Carlo —Å–∏–º—É–ª—è—Ü–∏—è"""
        return {"status": "success", "message": "–°–∏–º—É–ª—è—Ü–∏—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∞"}
    
    def _calculate_financial_metrics(self, **kwargs) -> Dict[str, Any]:
        """–†–∞—Å—á–µ—Ç —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã—Ö –º–µ—Ç—Ä–∏–∫"""
        return {"status": "success", "message": "–ú–µ—Ç—Ä–∏–∫–∏ —Ä–∞—Å—Å—á–∏—Ç–∞–Ω—ã"}
    
    def _extract_text_from_pdf(self, **kwargs) -> Dict[str, Any]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∏–∑ PDF"""
        return {"status": "success", "message": "–¢–µ–∫—Å—Ç –∏–∑–≤–ª–µ—á–µ–Ω"}
    
    def _analyze_bentley_model(self, **kwargs) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑ –º–æ–¥–µ–ª–∏ Bentley"""
        return {"status": "success", "message": "–ú–æ–¥–µ–ª—å –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞"}
    
    def _autocad_export(self, **kwargs) -> Dict[str, Any]:
        """–≠–∫—Å–ø–æ—Ä—Ç –≤ AutoCAD"""
        return {"status": "success", "message": "–≠–∫—Å–ø–æ—Ä—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω"}

# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä
unified_tools = UnifiedToolsSystem()

# –£—Ç–∏–ª–∏—Ç—ã —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
def execute_tool(tool_name: str, **kwargs) -> ToolResult:
    return unified_tools.execute_tool(tool_name, **kwargs)

def list_available_tools(category: Optional[str] = None) -> List[str]:
    tools = unified_tools.list_tools(category)
    return [tool.name for tool in tools]

def get_tool_signature(tool_name: str) -> Optional[ToolSignature]:
    return unified_tools.get_tool_info(tool_name)


