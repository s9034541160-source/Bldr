import os
import re
import json
import time
import requests
import hashlib
from pathlib import Path
from typing import Dict, List, Optional, Tuple
from dataclasses import dataclass, asdict
import sqlite3
import logging

# Set up logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class NormativeDocument:
    """Data class for normative document information"""
    id: int
    category: str
    code: str
    title: str
    year: int
    status: str
    pdf_url: str
    source_site: str
    description: str
    file_path: Optional[str] = None
    processed_at: Optional[float] = None

class NormativeDatabase:
    """Database for normative technical documentation"""
    
    def __init__(self, db_path: Optional[str] = None, json_path: Optional[str] = None):
        # Use BASE_DIR environment variable or default to I:/docs
        base_dir_env = os.getenv("BASE_DIR", "I:/docs")
        default_db_path = os.path.join(base_dir_env, "norms_db", "ntd_local.db")
        default_json_path = os.path.join(base_dir_env, "norms_db", "ntd_full_db.json")
        
        self.db_path = Path(db_path or default_db_path)
        self.json_path = Path(json_path or default_json_path)
        self.documents: Dict[str, NormativeDocument] = {}
        self.categories = {
            "construction": "–°—Ç—Ä–æ–∏—Ç–µ–ª—å—Å—Ç–≤–æ",
            "finance": "–§–∏–Ω–∞–Ω—Å—ã –∏ –±—é–¥–∂–µ—Ç",
            "safety": "–¢–µ—Ö–Ω–∏–∫–∞ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ –∏ –æ—Ö—Ä–∞–Ω–∞ —Ç—Ä—É–¥–∞",
            "environment": "–≠–∫–æ–ª–æ–≥–∏—è",
            "hr": "HR –∏ –∫–∞–¥—Ä—ã",
            "procurement": "–¢–µ–Ω–¥–µ—Ä—ã, –∫–æ–Ω–∫—É—Ä—Å—ã, –∑–∞–∫—É–ø–∫–∏",
            "contracts": "–î–æ–≥–æ–≤–æ—Ä–∞",
            "documentation": "–ò—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è",
            "materials": "–ú–∞—Ç–µ—Ä–∏–∞–ª—å–Ω–æ–µ —Å–Ω–∞–±–∂–µ–Ω–∏–µ –∏ —Å–∫–ª–∞–¥–∏—Ä–æ–≤–∞–Ω–∏–µ",
            "accounting": "–ë—É—Ö–≥–∞–ª—Ç–µ—Ä—Å–∫–∏–π —É—á–µ—Ç"
        }
        self._init_db()
        self._load_documents()
    
    def _init_db(self):
        """Initialize SQLite database for processed documents tracking"""
        self.db_path.parent.mkdir(parents=True, exist_ok=True)
        self.conn = sqlite3.connect(self.db_path)
        self.conn.execute('''CREATE TABLE IF NOT EXISTS processed_docs 
                            (id INTEGER PRIMARY KEY, 
                             code TEXT UNIQUE, 
                             title TEXT, 
                             file_path TEXT, 
                             processed_at REAL,
                             status TEXT)''')
        self.conn.commit()
    
    def _load_documents(self):
        """Load documents from JSON database"""
        if self.json_path.exists():
            with open(self.json_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
                for doc_data in data:
                    doc = NormativeDocument(**doc_data)
                    self.documents[doc.code] = doc
            logger.info(f"Loaded {len(self.documents)} normative documents from JSON")
        else:
            logger.warning(f"Normative documents JSON not found: {self.json_path}")
    
    def get_document(self, code: str) -> Optional[NormativeDocument]:
        """Get document by code"""
        return self.documents.get(code.upper())
    
    def search_documents(self, query: str, category: Optional[str] = None) -> List[NormativeDocument]:
        """Search documents by query and category"""
        results = []
        query_lower = query.lower()
        
        for doc in self.documents.values():
            if category and doc.category != category:
                continue
            
            if (query_lower in doc.code.lower() or 
                query_lower in doc.title.lower() or
                query_lower in doc.description.lower()):
                results.append(doc)
        
        return results
    
    def is_document_actual(self, code: str) -> bool:
        """Check if document is actual (not outdated)"""
        doc = self.get_document(code)
        if not doc:
            return False
        return doc.status in ["–û–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–π", "–ê–∫—Ç—É–∞–ª—å–Ω—ã–π", "–†–µ–∫–æ–º–µ–Ω–¥–∞—Ç–µ–ª—å–Ω—ã–π"]
    
    def get_replacement_document(self, code: str) -> Optional[NormativeDocument]:
        """Get replacement document if current is outdated"""
        doc = self.get_document(code)
        if not doc or "—É—Å—Ç–∞—Ä–µ–ª" not in doc.status.lower():
            return None
        
        # Search for replacement documents in official databases
        # For now, we'll just return None
        return None
    
    def mark_as_processed(self, code: str, file_path: str, status: str = "processed"):
        """Mark document as processed in database"""
        try:
            self.conn.execute(
                "INSERT OR REPLACE INTO processed_docs (code, title, file_path, processed_at, status) VALUES (?, ?, ?, ?, ?)",
                (code, self.documents[code].title, file_path, time.time(), status)
            )
            self.conn.commit()
        except Exception as e:
            logger.error(f"Error marking document as processed: {e}")
    
    def is_processed(self, code: str) -> bool:
        """Check if document is already processed"""
        try:
            cursor = self.conn.execute("SELECT code FROM processed_docs WHERE code = ?", (code,))
            return cursor.fetchone() is not None
        except Exception as e:
            logger.error(f"Error checking if document is processed: {e}")
            return False

class NormativeChecker:
    """Checker for normative document actuality and processing"""
    
    def __init__(self, normative_db: NormativeDatabase):
        self.normative_db = normative_db
        self.sources = [
            "https://docs.cntd.ru",
            "https://www.minstroyrf.gov.ru",
            "https://meganorm.ru",
            "https://files.stroyinf.ru",
            "https://helpeng.ru",
            "https://gostbank.metaltorg.ru"
        ]
    
    def extract_document_info(self, file_path: str, content: Optional[str] = None) -> Dict:
        """Extract document information from file and content"""
        info = {"code": "", "title": ""}
        
        # Try to extract code from filename
        file_name = Path(file_path).name.lower()
        norm_patterns = [
            # English patterns (SP_, GOST_, etc.)
            r"(sp)[\s_]+[\d\.\-]+",  # SP_25.13330.2020
            r"(gost)[\s_]+[\d\.\-]+",  # GOST_52742-2007
            r"(snip)[\s_]+[\d\.\-]+",  # SNiP_2.02.01-83
            r"(gesn)[\s_]+[\d\.\-]+",  # GESN_01
            r"(mds)[\s_]+[\d\.\-]+",  # MDS_21-1.98
            r"(ppr)[\s_]*",  # PPR_
            r"(pos)[\s_]*",  # POS_
            # Russian patterns
            r"(—Å–ø|—Å–Ω–∏–ø|–≥–æ—Å—Ç|–ø–æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ|–ø—Ä–∏–∫–∞–∑|—Ñ–∑)\s*[\d\.\-]+",
            r"(—Å–ø|—Å–Ω–∏–ø|–≥–æ—Å—Ç|–ø–æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ|–ø—Ä–∏–∫–∞–∑|—Ñ–∑)[\s_]*\d+[\.\-\d]*",
            r"(–≥—ç—Å–Ω|–º–¥—Å)[\s_]*\d+[\.\-\d]*"
        ]
        
        for pattern in norm_patterns:
            match = re.search(pattern, file_name, re.IGNORECASE)
            if match:
                info["code"] = match.group(0).upper().replace("_", " ")
                break
        
        # If content is provided, extract more information
        if content:
            # Search for document codes in content
            content_patterns = [
                r"(?:–°–ü|–°–ù–∏–ü|–ì–û–°–¢|–ü–æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ|–ü—Ä–∏–∫–∞–∑|–§–ó)\s+\d{2,4}[.:]?\d{2,4}[.:]?\d{2,4}[-]?\d{4}",
                r"(?:–°–ü|–°–ù–∏–ü|–ì–û–°–¢|–ü–æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ|–ü—Ä–∏–∫–∞–∑|–§–ó)\s+\d{1,4}-[–§—Ñ][–ó–∑]",
                r"(?:–°–ü|–°–ù–∏–ü|–ì–û–°–¢)\s+\d{2}\-\d{2}\-\d{4}",
                r"(?:–°–ü|–°–ù–∏–ü|–ì–û–°–¢)\s+\d{4}\-\d{4}"
            ]
            
            for pattern in content_patterns:
                matches = re.findall(pattern, content, re.IGNORECASE)
                if matches:
                    info["code"] = matches[0].strip()
                    break
            
            # Search for document titles
            title_patterns = [
                r'(?:–°–ü|–°–ù–∏–ü|–ì–û–°–¢|–ü–æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ|–ü—Ä–∏–∫–∞–∑|–§–ó)\s+[\d\.\-]+\s*[¬´"]([^¬ª"]+)[¬ª"]',
                r'(?:–°–≤–æ–¥\s+–ø—Ä–∞–≤–∏–ª|–°—Ç—Ä–æ–∏—Ç–µ–ª—å–Ω—ã–µ\s+–Ω–æ—Ä–º—ã\s+–∏\s+–ø—Ä–∞–≤–∏–ª–∞|–ì–æ—Å—É–¥–∞—Ä—Å—Ç–≤–µ–Ω–Ω—ã–π\s+—Å—Ç–∞–Ω–¥–∞—Ä—Ç)\s+([^¬ª"]+)',
                r'(?:–°–ü|–°–ù–∏–ü|–ì–û–°–¢)\s+[\d\.\-]+\s*[-‚Äì‚Äî]\s*([^¬ª"]+)'
            ]
            
            for pattern in title_patterns:
                match = re.search(pattern, content, re.IGNORECASE)
                if match:
                    info["title"] = match.group(1).strip()
                    break
        
        return info
    
    def check_document_actual(self, file_path: str, content: Optional[str] = None) -> Dict:
        """Check if document is actual and provide recommendations"""
        result = {
            "file_path": file_path,
            "detected_code": "",
            "detected_title": "",
            "status": "unknown",
            "actual_version": None,
            "recommendations": [],
            "actions": []
        }
        
        # Extract document info
        doc_info = self.extract_document_info(file_path, content)
        result["detected_code"] = doc_info.get("code", "")
        result["detected_title"] = doc_info.get("title", "")
        
        if not doc_info.get("code"):
            result["status"] = "not_found"
            result["recommendations"].append("–ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –∫–æ–¥ –¥–æ–∫—É–º–µ–Ω—Ç–∞")
            return result
        
        # Check if document exists in database
        norm_doc = self.normative_db.get_document(doc_info["code"])
        if not norm_doc:
            result["status"] = "not_in_db"
            result["recommendations"].append(f"–î–æ–∫—É–º–µ–Ω—Ç {doc_info['code']} –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –±–∞–∑–µ –Ω–æ—Ä–º–∞—Ç–∏–≤–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
            return result
        
        # Check if document is actual
        if self.normative_db.is_document_actual(doc_info["code"]):
            result["status"] = "actual"
            result["actual_version"] = asdict(norm_doc)
            result["recommendations"].append(f"–î–æ–∫—É–º–µ–Ω—Ç {doc_info['code']} –∞–∫—Ç—É–∞–ª–µ–Ω")
        else:
            result["status"] = "outdated"
            replacement = self.normative_db.get_replacement_document(doc_info["code"])
            if replacement:
                result["actual_version"] = asdict(replacement)
                result["recommendations"].append(f"–î–æ–∫—É–º–µ–Ω—Ç {doc_info['code']} —É—Å—Ç–∞—Ä–µ–ª, –∑–∞–º–µ–Ω–µ–Ω –Ω–∞ {replacement.code}")
                result["actions"].append({
                    "type": "replace",
                    "old_file": file_path,
                    "new_code": replacement.code,
                    "new_title": replacement.title
                })
            else:
                result["recommendations"].append(f"–î–æ–∫—É–º–µ–Ω—Ç {doc_info['code']} —É—Å—Ç–∞—Ä–µ–ª, –∑–∞–º–µ–Ω—è—é—â–∏–π –¥–æ–∫—É–º–µ–Ω—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω")
        
        return result
    
    def download_document(self, code: str, target_dir: str) -> Optional[str]:
        """Download document PDF from database URL"""
        norm_doc = self.normative_db.get_document(code)
        if not norm_doc or not norm_doc.pdf_url:
            return None
        
        try:
            # Create filename
            file_name = f"{norm_doc.code}_{norm_doc.title.replace(' ', '_')}.pdf"
            file_name = re.sub(r'[\\/*?:"<>|]', "_", file_name)  # Remove invalid characters
            file_path = Path(target_dir) / file_name
            
            # Download file
            response = requests.get(norm_doc.pdf_url, timeout=30)
            if response.status_code == 200:
                with open(file_path, "wb") as f:
                    f.write(response.content)
                return str(file_path)
            else:
                logger.error(f"Error downloading {norm_doc.pdf_url}: {response.status_code}")
                return None
                
        except Exception as e:
            logger.error(f"Error downloading document {code}: {e}")
            return None

def _determine_document_category(file_name_lower: str, content: str) -> str:
    """
    Determine the appropriate –ë–ê–ó–ê category for a document based on filename and content
    Supports all subject areas: construction, finance, accounting, safety, HR, ecology, training
    """
    # Patterns for each category - ORDER MATTERS! More specific patterns first
    category_patterns = {
        # === –°–¢–†–û–ò–¢–ï–õ–¨–°–¢–í–û (most specific first) ===
        "09. –°–¢–†–û–ò–¢–ï–õ–¨–°–¢–í–û - –°–í–û–î–´ –ü–†–ê–í–ò–õ": [
            r"\b—Å–ø[\s_]+\d",  # SP 25.13330.2020
            r"—Å–≤–æ–¥\s+–ø—Ä–∞–≤–∏–ª",
            r"—Å–ø\s+—Ä–∫"
        ],
        "07. –°–¢–†–û–ò–¢–ï–õ–¨–°–¢–í–û - –ì–û–°–¢—ã": [
            r"\b–≥–æ—Å—Ç[\s_]+\d",  # GOST_52742-2007
            r"\b–≥–æ—Å—Ç[\s_]+—Ä",
            r"\b–æ—Å—Ç[\s_]+\d"
        ],
        "08. –°–¢–†–û–ò–¢–ï–õ–¨–°–¢–í–û - –°–ù–∏–ü—ã": [
            r"\b—Å–Ω–∏–∏–ø?[\s_]+\d",  # SNiP_2.02.01-83
            r"\b—Å–Ω[\s_]+\d",
            r"\b–≤—Å—Ö–Ω"
        ],
        "05. –°–¢–†–û–ò–¢–ï–õ–¨–°–¢–í–û - –°–ú–ï–¢–´": [
            r"\b–≥—ç—Å–Ω[\s_]*\d",  # GESN_01
            r"\b—Ñ–µ—Ä[\s_]*\d",
            r"\b—Ç–µ—Ä[\s_]*\d",
            r"—Ä–∞—Å—Ü–µ–Ω–∫",
            r"–Ω–æ—Ä–º–∞—Ç–∏–≤\s+–∑–∞—Ç—Ä–∞—Ç",
            r"—Å–º–µ—Ç–Ω",
            r"–µ–¥–∏–Ω–∏—á–Ω—ã–µ\s+—Ä–∞—Å—Ü–µ–Ω–∫–∏"
        ],
        "02. –°–¢–†–û–ò–¢–ï–õ–¨–°–¢–í–û - –ú–î–°": [
            r"\b–º–¥—Å[\s_]*\d",  # MDS_21-1.98
            r"–º–µ—Ç–æ–¥–∏—á–µ—Å–∫–∏–µ\s+–¥–æ–∫—É–º–µ–Ω—Ç—ã",
            r"–º–µ—Ç–æ–¥–∏—á–µ—Å–∫–∏–µ\s+—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏"
        ],
        "03. –°–¢–†–û–ò–¢–ï–õ–¨–°–¢–í–û - –ü–û–°/–ü–ü–†": [
            r"\b–ø–ø—Ä[\s_]*",  # PPR_
            r"\b–ø–æ—Å[\s_]*",
            r"–ø—Ä–æ–µ–∫—Ç\s+–ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–∞\s+—Ä–∞–±–æ—Ç",
            r"–ø—Ä–æ–µ–∫—Ç\s+–æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏\s+—Å—Ç—Ä–æ–∏—Ç–µ–ª—å—Å—Ç–≤–∞",
            r"—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–∞—è\s+–∫–∞—Ä—Ç–∞",
            r"\b—Ç—Ç–∫[\s_]*",
            r"\b—Ç–∫[\s_]*"
        ],
        "04. –°–¢–†–û–ò–¢–ï–õ–¨–°–¢–í–û - –ü–†–û–ï–ö–¢–´": [
            r"—Ç–∏–ø–æ–≤–æ–π\s+–ø—Ä–æ–µ–∫—Ç",
            r"—Ç–∏–ø–æ–≤—ã–π\s+–ø—Ä–æ–µ–∫—Ç",
            r"–∞–ª—å–±–æ–º",
            r"—Å–µ—Ä–∏—è",
            r"–∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω—ã–π\s+–ø—Ä–æ–µ–∫—Ç"
        ],
        "06. –°–¢–†–û–ò–¢–ï–õ–¨–°–¢–í–û - –û–ë–†–ê–ó–¶–´": [
            r"\b–∞–∫—Ç[\s_]*",
            r"—Å–ø—Ä–∞–≤–∫–∞",
            r"–∑–∞–∫–ª—é—á–µ–Ω–∏–µ",
            r"–ø—Ä–æ—Ç–æ–∫–æ–ª",
            r"–≤–µ–¥–æ–º–æ—Å—Ç—å",
            r"–æ–±—Ä–∞–∑–µ—Ü",
            r"—Ñ–æ—Ä–º–∞",
            r"–±–ª–∞–Ω–∫"
        ],
        
        # === –§–ò–ù–ê–ù–°–´ ===
        "10. –§–ò–ù–ê–ù–°–´ - –ó–ê–ö–û–ù–´": [
            r"–Ω–∞–ª–æ–≥–æ–≤—ã–π\s+–∫–æ–¥–µ–∫—Å",
            r"\b–Ω–∫\s+—Ä—Ñ",
            r"—Ñ–∏–Ω–∞–Ω—Å—ã",
            r"–±—é–¥–∂–µ—Ç",
            r"–Ω–∞–ª–æ–≥"
        ],
        "12. –§–ò–ù–ê–ù–°–´ - –°–¢–ê–ù–î–ê–†–¢–´": [
            r"\b–ø–±—É[\s_]*\d",
            r"\b—Ñ—Å–±—É[\s_]*\d",
            r"\b—Ä—Å–±—É[\s_]*\d",
            r"–º—Å—Ñ–æ",
            r"–ø–æ–ª–æ–∂–µ–Ω–∏–µ\s+–ø–æ\s+–±—É—Ö–≥–∞–ª—Ç–µ—Ä—Å–∫–æ–º—É\s+—É—á–µ—Ç—É"
        ],
        "14. –§–ò–ù–ê–ù–°–´ - –ë–ê–ù–ö–û–í–°–ö–û–ï –î–ï–õ–û": [
            r"—Ü–µ–Ω—Ç—Ä–∞–ª—å–Ω—ã–π\s+–±–∞–Ω–∫",
            r"\b—Ü–±[\s_]*",
            r"–∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è\s+–±–∞–Ω–∫–∞\s+—Ä–æ—Å—Å–∏–∏",
            r"–±–∞–Ω–∫–æ–≤—Å–∫–∞—è",
            r"–∫—Ä–µ–¥–∏—Ç"
        ],
        
        # === –ë–£–•–ì–ê–õ–¢–ï–†–ò–Ø ===
        "16. –ë–£–•–£–ß–ï–¢ - –ó–ê–ö–û–ù–´": [
            r"—Ñ–µ–¥–µ—Ä–∞–ª—å–Ω—ã–π\s+–∑–∞–∫–æ–Ω.*–±—É—Ö–≥–∞–ª—Ç–µ—Ä—Å–∫–æ–º\s+—É—á–µ—Ç–µ",
            r"–±—É—Ö–≥–∞–ª—Ç–µ—Ä—Å–∫–∏–π\s+—É—á–µ—Ç",
            r"–ø—Ä–∏–∫–∞–∑.*–º–∏–Ω—Ñ–∏–Ω"
        ],
        "18. –ë–£–•–£–ß–ï–¢ - –ü–õ–ê–ù –°–ß–ï–¢–û–í": [
            r"–ø–ª–∞–Ω\s+—Å—á–µ—Ç–æ–≤",
            r"–±–∞–ª–∞–Ω—Å–æ–≤—ã–µ\s+—Å—á–µ—Ç–∞",
            r"–∫–æ—Ä—Ä–µ—Å–ø–æ–Ω–¥–µ–Ω—Ü–∏—è\s+—Å—á–µ—Ç–æ–≤"
        ],
        
        # === –ü–†–û–ú–ë–ï–ó–û–ü–ê–°–ù–û–°–¢–¨ ===
        "22. –ü–†–û–ú–ë–ï–ó–û–ü–ê–°–ù–û–°–¢–¨ - –ó–ê–ö–û–ù–´": [
            r"–ø—Ä–æ–º—ã—à–ª–µ–Ω–Ω–∞—è\s+–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å",
            r"—Ä–æ—Å—Ç–µ—Ö–Ω–∞–¥–∑–æ—Ä",
            r"–æ–ø–∞—Å–Ω—ã–µ\s+–ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–µ–Ω–Ω—ã–µ\s+–æ–±—ä–µ–∫—Ç—ã"
        ],
        "23. –ü–†–û–ú–ë–ï–ó–û–ü–ê–°–ù–û–°–¢–¨ - –ü–†–ê–í–ò–õ–ê": [
            r"\b—Ñ–Ω–ø[\s_]*\d",
            r"\b–ø–±[\s_]*\d",
            r"–ø—Ä–∞–≤–∏–ª–∞\s+–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏",
            r"—Ä—É–∫–æ–≤–æ–¥—è—â–∏–π\s+–¥–æ–∫—É–º–µ–Ω—Ç"
        ],
        
        # === –û–•–†–ê–ù–ê –¢–†–£–î–ê ===
        "28. –û–•–†–ê–ù–ê –¢–†–£–î–ê - –ó–ê–ö–û–ù–´": [
            r"–æ—Ö—Ä–∞–Ω–∞\s+—Ç—Ä—É–¥–∞",
            r"—Ç—Ä—É–¥–æ–≤–æ–π\s+–∫–æ–¥–µ–∫—Å",
            r"\b—Ç–∫\s+—Ä—Ñ",
            r"–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å\s+—Ç—Ä—É–¥–∞"
        ],
        "29. –û–•–†–ê–ù–ê –¢–†–£–î–ê - –ü–†–ê–í–ò–õ–ê": [
            r"–ø—Ä–∞–≤–∏–ª–∞.*–æ—Ö—Ä–∞–Ω–µ\s+—Ç—Ä—É–¥–∞",
            r"—Ç–∏–ø–æ–≤—ã–µ\s+–∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏",
            r"–∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è\s+–ø–æ\s+–æ—Ö—Ä–∞–Ω–µ\s+—Ç—Ä—É–¥–∞"
        ],
        "32. –û–•–†–ê–ù–ê –¢–†–£–î–ê - –°–ò–ó": [
            r"—Å—Ä–µ–¥—Å—Ç–≤–∞\s+–∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω–æ–π\s+–∑–∞—â–∏—Ç—ã",
            r"\b—Å–∏–∑\b",
            r"–Ω–æ—Ä–º—ã\s+–≤—ã–¥–∞—á–∏",
            r"—Å–ø–µ—Ü–æ–¥–µ–∂–¥–∞"
        ],
        
        # === HR –ò –ö–ê–î–†–´ ===
        "35. HR - –¢–†–£–î–û–í–û–ï –ü–†–ê–í–û": [
            r"—Ç—Ä—É–¥–æ–≤–æ–µ\s+–ø—Ä–∞–≤–æ",
            r"—Ç—Ä—É–¥–æ–≤–æ–π\s+–¥–æ–≥–æ–≤–æ—Ä",
            r"—Ä–∞–±–æ—á–µ–µ\s+–≤—Ä–µ–º—è",
            r"–æ—Ç–ø—É—Å–∫"
        ],
        "36. HR - –ö–ê–î–†–û–í–û–ï –î–ï–õ–û–ü–†–û–ò–ó–í–û–î–°–¢–í–û": [
            r"–∫–∞–¥—Ä–æ–≤–æ–µ\s+–¥–µ–ª–æ–ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–æ",
            r"–ª–∏—á–Ω–∞—è\s+–∫–∞—Ä—Ç–æ—á–∫–∞",
            r"—Ç—Ä—É–¥–æ–≤–∞—è\s+–∫–Ω–∏–∂–∫–∞",
            r"–ø—Ä–∏–∫–∞–∑\s+–æ\s+–ø—Ä–∏–µ–º–µ"
        ],
        "38. HR - –û–ü–õ–ê–¢–ê –¢–†–£–î–ê": [
            r"–º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π\s+—Ä–∞–∑–º–µ—Ä\s+–æ–ø–ª–∞—Ç—ã\s+—Ç—Ä—É–¥–∞",
            r"\b–º—Ä–æ—Ç\b",
            r"—Ä–∞–π–æ–Ω–Ω—ã–µ\s+–∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç—ã",
            r"–∑–∞—Ä–∞–±–æ—Ç–Ω–∞—è\s+–ø–ª–∞—Ç–∞"
        ],
        
        # === –≠–ö–û–õ–û–ì–ò–Ø ===
        "42. –≠–ö–û–õ–û–ì–ò–Ø - –ó–ê–ö–û–ù–´": [
            r"–æ—Ö—Ä–∞–Ω–∞\s+–æ–∫—Ä—É–∂–∞—é—â–µ–π\s+—Å—Ä–µ–¥—ã",
            r"–≤–æ–¥–Ω—ã–π\s+–∫–æ–¥–µ–∫—Å",
            r"–ª–µ—Å–Ω–æ–π\s+–∫–æ–¥–µ–∫—Å",
            r"—ç–∫–æ–ª–æ–≥–∏—è"
        ],
        "43. –≠–ö–û–õ–û–ì–ò–Ø - –ù–û–†–ú–ê–¢–ò–í–´": [
            r"–ø—Ä–µ–¥–µ–ª—å–Ω–æ\s+–¥–æ–ø—É—Å—Ç–∏–º—ã–µ\s+–∫–æ–Ω—Ü–µ–Ω—Ç—Ä–∞—Ü–∏–∏",
            r"\b–ø–¥–∫\b",
            r"\b–ø–¥–≤\b",
            r"\b–Ω–¥—Å\b",
            r"–ª–∏–º–∏—Ç—ã.*–≤—ã–±—Ä–æ—Å"
        ],
        "47. –≠–ö–û–õ–û–ì–ò–Ø - –û–¢–•–û–î–´": [
            r"—Ñ–µ–¥–µ—Ä–∞–ª—å–Ω—ã–π\s+–∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä\s+–∫–æ–¥–æ–≤\s+–æ—Ç—Ö–æ–¥–æ–≤",
            r"\b—Ñ–∫–∫–æ\b",
            r"–ø–∞—Å–ø–æ—Ä—Ç.*–æ—Ç—Ö–æ–¥",
            r"–æ–±—Ä–∞—â–µ–Ω–∏–µ\s+—Å\s+–æ—Ç—Ö–æ–¥–∞–º–∏"
        ],
        
        # === –û–ë–£–ß–ê–Æ–©–ò–ï –ú–ê–¢–ï–†–ò–ê–õ–´ ===
        "49. –õ–ï–ö–¶–ò–ò –ò –ö–£–†–°–´": [
            r"–ª–µ–∫—Ü–∏—è",
            r"–∫—É—Ä—Å",
            r"—Å–µ–º–∏–Ω–∞—Ä",
            r"–≤–µ–±–∏–Ω–∞—Ä",
            r"–ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏—è",
            r"–æ–±—É—á–µ–Ω–∏–µ"
        ],
        "50. –ö–ù–ò–ì–ò –û–ë–©–ò–ï": [
            r"—É—á–µ–±–Ω–∏–∫",
            r"–ø–æ—Å–æ–±–∏–µ",
            r"—Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫",
            r"–º–æ–Ω–æ–≥—Ä–∞—Ñ–∏—è",
            r"—ç–Ω—Ü–∏–∫–ª–æ–ø–µ–¥–∏—è"
        ],
        "51. –°–¢–ê–ù–î–ê–†–¢–´ –ö–ê–ß–ï–°–¢–í–ê": [
            r"\biso[\s_]*\d",
            r"–≥–æ—Å—Ç\s+—Ä\s+–∏—Å–æ",
            r"—Å–∏—Å—Ç–µ–º–∞\s+–º–µ–Ω–µ–¥–∂–º–µ–Ω—Ç–∞\s+–∫–∞—á–µ—Å—Ç–≤–∞",
            r"–∫–∞—á–µ—Å—Ç–≤–æ"
        ],
        
        # === –û–ë–©–ò–ï –ö–ê–¢–ï–ì–û–†–ò–ò (—Å—Ç—Ä–æ–∏—Ç–µ–ª—å–Ω—ã–µ fallback) ===
        "01. –°–¢–†–û–ò–¢–ï–õ–¨–°–¢–í–û - –ù–¢–î": [
            r"–ø–æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ",
            r"–ø—Ä–∏–∫–∞–∑",
            r"—Ñ–µ–¥–µ—Ä–∞–ª—å–Ω—ã–π\s+–∑–∞–∫–æ–Ω",
            r"\b—Ñ–∑[\-\s]*\d+",
            r"—Å—Ç—Ä–æ–∏—Ç–µ–ª—å–Ω—ã–µ\s+–Ω–æ—Ä–º—ã",
            r"–≥–æ—Å—É–¥–∞—Ä—Å—Ç–≤–µ–Ω–Ω—ã–π\s+—Å—Ç–∞–Ω–¥–∞—Ä—Ç"
        ]
    }
    
    # Check filename first (more reliable)
    for category, patterns in category_patterns.items():
        for pattern in patterns:
            if re.search(pattern, file_name_lower, re.IGNORECASE):
                return category
    
    # If no match in filename, check content (first 1000 chars for speed)
    if content:
        content_sample = content[:1000].lower()
        for category, patterns in category_patterns.items():
            for pattern in patterns:
                if re.search(pattern, content_sample, re.IGNORECASE):
                    return category
    
    # Default category
    return "99. –î–†–£–ì–ò–ï –î–û–ö–£–ú–ï–ù–¢–´"

def organize_normative_documents(base_path: str) -> Dict[str, str]:
    """Organize folder structure for comprehensive knowledge base covering all subject areas"""
    structure = {
        "–ë–ê–ó–ê": {
            # === –°–¢–†–û–ò–¢–ï–õ–¨–°–¢–í–û –ò –ê–†–•–ò–¢–ï–ö–¢–£–†–ê ===
            "01. –°–¢–†–û–ò–¢–ï–õ–¨–°–¢–í–û - –ù–¢–î": ["–°–ü", "–°–ù–∏–ü", "–ì–û–°–¢", "–ü–æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è", "–ü—Ä–∏–∫–∞–∑—ã"],
            "02. –°–¢–†–û–ò–¢–ï–õ–¨–°–¢–í–û - –ú–î–°": ["–ú–î–°", "–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏", "–ü–æ—Å–æ–±–∏—è"],
            "03. –°–¢–†–û–ò–¢–ï–õ–¨–°–¢–í–û - –ü–û–°/–ü–ü–†": ["–ü–û–°", "–ü–ü–†", "–¢–ö", "–¢–¢–ö"],
            "04. –°–¢–†–û–ò–¢–ï–õ–¨–°–¢–í–û - –ü–†–û–ï–ö–¢–´": ["–¢–∏–ø–æ–≤—ã–µ –ø—Ä–æ–µ–∫—Ç—ã", "–ê–ª—å–±–æ–º—ã", "–°–µ—Ä–∏–∏"],
            "05. –°–¢–†–û–ò–¢–ï–õ–¨–°–¢–í–û - –°–ú–ï–¢–´": ["–ì–≠–°–ù", "–§–ï–†", "–¢–ï–†", "–†–∞—Å—Ü–µ–Ω–∫–∏"],
            "06. –°–¢–†–û–ò–¢–ï–õ–¨–°–¢–í–û - –û–ë–†–ê–ó–¶–´": ["–ê–∫—Ç—ã", "–°–ø—Ä–∞–≤–∫–∏", "–ó–∞–∫–ª—é—á–µ–Ω–∏—è"],
            "07. –°–¢–†–û–ò–¢–ï–õ–¨–°–¢–í–û - –ì–û–°–¢—ã": ["–ì–û–°–¢", "–ì–û–°–¢ –†", "–û–°–¢"],
            "08. –°–¢–†–û–ò–¢–ï–õ–¨–°–¢–í–û - –°–ù–∏–ü—ã": ["–°–ù–∏–ü", "–°–ù", "–í–°–•–ù"],
            "09. –°–¢–†–û–ò–¢–ï–õ–¨–°–¢–í–û - –°–í–û–î–´ –ü–†–ê–í–ò–õ": ["–°–ü", "–°–ü –†–ö"],
            
            # === –§–ò–ù–ê–ù–°–´ –ò –≠–ö–û–ù–û–ú–ò–ö–ê ===
            "10. –§–ò–ù–ê–ù–°–´ - –ó–ê–ö–û–ù–´": ["–ù–ö –†–§", "–§–ó", "–ü–æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è", "–†–∞—Å–ø–æ—Ä—è–∂–µ–Ω–∏—è"],
            "11. –§–ò–ù–ê–ù–°–´ - –ú–ï–¢–û–î–ò–ß–ö–ò": ["–ú–µ—Ç–æ–¥–∏—á–µ—Å–∫–∏–µ —É–∫–∞–∑–∞–Ω–∏—è", "–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏", "–†–∞–∑—ä—è—Å–Ω–µ–Ω–∏—è"],
            "12. –§–ò–ù–ê–ù–°–´ - –°–¢–ê–ù–î–ê–†–¢–´": ["–ü–ë–£", "–§–°–ë–£", "–†–°–ë–£", "–ú–°–§–û"],
            "13. –§–ò–ù–ê–ù–°–´ - –§–û–†–ú–´ –û–¢–ß–ï–¢–ù–û–°–¢–ò": ["–ë–∞–ª–∞–Ω—Å", "–û–ü–£", "–î–µ–∫–ª–∞—Ä–∞—Ü–∏–∏", "–°–ø—Ä–∞–≤–∫–∏"],
            "14. –§–ò–ù–ê–ù–°–´ - –ë–ê–ù–ö–û–í–°–ö–û–ï –î–ï–õ–û": ["–ò–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –¶–ë", "–ü–æ–ª–æ–∂–µ–Ω–∏—è", "–£–∫–∞–∑–∞–Ω–∏—è"],
            "15. –§–ò–ù–ê–ù–°–´ - –ö–ù–ò–ì–ò": ["–£—á–µ–±–Ω–∏–∫–∏", "–ü–æ—Å–æ–±–∏—è", "–ú–æ–Ω–æ–≥—Ä–∞—Ñ–∏–∏"],
            
            # === –ë–£–•–ì–ê–õ–¢–ï–†–°–ö–ò–ô –£–ß–ï–¢ ===
            "16. –ë–£–•–£–ß–ï–¢ - –ó–ê–ö–û–ù–´": ["–§–ó –û –±—É—Ö—É—á–µ—Ç–µ", "–ù–ö –†–§", "–ü—Ä–∏–∫–∞–∑—ã –ú–∏–Ω–§–∏–Ω–∞"],
            "17. –ë–£–•–£–ß–ï–¢ - –ü–ë–£/–§–°–ë–£": ["–ü–ë–£", "–§–°–ë–£", "–ú–µ—Ç–æ–¥–∏—á–µ—Å–∫–∏–µ —É–∫–∞–∑–∞–Ω–∏—è"],
            "18. –ë–£–•–£–ß–ï–¢ - –ü–õ–ê–ù –°–ß–ï–¢–û–í": ["–ü–ª–∞–Ω —Å—á–µ—Ç–æ–≤", "–ò–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏", "–ö–æ—Ä—Ä–µ—Å–ø–æ–Ω–¥–µ–Ω—Ü–∏—è"],
            "19. –ë–£–•–£–ß–ï–¢ - –î–û–ö–£–ú–ï–ù–¢–û–û–ë–û–†–û–¢": ["–ü–µ—Ä–≤–∏—á–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã", "–†–µ–≥–∏—Å—Ç—Ä—ã", "–§–æ—Ä–º—ã"],
            "20. –ë–£–•–£–ß–ï–¢ - –û–¢–ß–ï–¢–ù–û–°–¢–¨": ["–§–æ—Ä–º—ã –æ—Ç—á–µ—Ç–Ω–æ—Å—Ç–∏", "–ü–æ—è—Å–Ω–µ–Ω–∏—è", "–ò–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏"],
            "21. –ë–£–•–£–ß–ï–¢ - –ö–ù–ò–ì–ò": ["–£—á–µ–±–Ω–∏–∫–∏", "–ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –ø–æ—Å–æ–±–∏—è", "–°–ø—Ä–∞–≤–æ—á–Ω–∏–∫–∏"],
            
            # === –ü–†–û–ú–´–®–õ–ï–ù–ù–ê–Ø –ë–ï–ó–û–ü–ê–°–ù–û–°–¢–¨ ===
            "22. –ü–†–û–ú–ë–ï–ó–û–ü–ê–°–ù–û–°–¢–¨ - –ó–ê–ö–û–ù–´": ["–§–ó", "–ü–æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è", "–ü—Ä–∏–∫–∞–∑—ã –†–æ—Å—Ç–µ—Ö–Ω–∞–¥–∑–æ—Ä–∞"],
            "23. –ü–†–û–ú–ë–ï–ó–û–ü–ê–°–ù–û–°–¢–¨ - –ü–†–ê–í–ò–õ–ê": ["–§–ù–ü", "–ü–ë", "–†–î", "–ì–û–°–¢ –†"],
            "24. –ü–†–û–ú–ë–ï–ó–û–ü–ê–°–ù–û–°–¢–¨ - –≠–ö–°–ü–ï–†–¢–ò–ó–ê": ["–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è", "–ú–µ—Ç–æ–¥–∏–∫–∏", "–†–µ–≥–ª–∞–º–µ–Ω—Ç—ã"],
            "25. –ü–†–û–ú–ë–ï–ó–û–ü–ê–°–ù–û–°–¢–¨ - –õ–ò–¶–ï–ù–ó–ò–†–û–í–ê–ù–ò–ï": ["–ü–æ–ª–æ–∂–µ–Ω–∏—è", "–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è", "–§–æ—Ä–º—ã"],
            "26. –ü–†–û–ú–ë–ï–ó–û–ü–ê–°–ù–û–°–¢–¨ - –ê–í–ê–†–ò–ò": ["–†–∞—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ", "–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è", "–£—á–µ—Ç"],
            "27. –ü–†–û–ú–ë–ï–ó–û–ü–ê–°–ù–û–°–¢–¨ - –ö–ù–ò–ì–ò": ["–£—á–µ–±–Ω–∏–∫–∏", "–ú–µ—Ç–æ–¥–∏—á–µ—Å–∫–∏–µ –ø–æ—Å–æ–±–∏—è", "–°–ø—Ä–∞–≤–æ—á–Ω–∏–∫–∏"],
            
            # === –û–•–†–ê–ù–ê –¢–†–£–î–ê ===
            "28. –û–•–†–ê–ù–ê –¢–†–£–î–ê - –ó–ê–ö–û–ù–´": ["–¢–ö –†–§", "–§–ó", "–ü–æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è –ü—Ä–∞–≤–∏—Ç–µ–ª—å—Å—Ç–≤–∞"],
            "29. –û–•–†–ê–ù–ê –¢–†–£–î–ê - –ü–†–ê–í–ò–õ–ê": ["–ü—Ä–∞–≤–∏–ª–∞ –ø–æ –û–¢", "–ò–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏", "–ì–û–°–¢ –†"],
            "30. –û–•–†–ê–ù–ê –¢–†–£–î–ê - –û–ë–£–ß–ï–ù–ò–ï": ["–ü—Ä–æ–≥—Ä–∞–º–º—ã –æ–±—É—á–µ–Ω–∏—è", "–ë–∏–ª–µ—Ç—ã", "–¢–µ—Å—Ç—ã"],
            "31. –û–•–†–ê–ù–ê –¢–†–£–î–ê - –ú–ï–î–û–°–ú–û–¢–†–´": ["–ü—Ä–∏–∫–∞–∑—ã –ú–∏–Ω–ó–¥—Ä–∞–≤–∞", "–°–ø–∏—Å–∫–∏", "–§–æ—Ä–º—ã"],
            "32. –û–•–†–ê–ù–ê –¢–†–£–î–ê - –°–ò–ó": ["–ì–û–°–¢—ã", "–°–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç—ã", "–ù–æ—Ä–º—ã –≤—ã–¥–∞—á–∏"],
            "33. –û–•–†–ê–ù–ê –¢–†–£–î–ê - –†–ê–°–°–õ–ï–î–û–í–ê–ù–ò–ï": ["–ü–æ–ª–æ–∂–µ–Ω–∏—è", "–§–æ—Ä–º—ã –∞–∫—Ç–æ–≤", "–ú–µ—Ç–æ–¥–∏–∫–∏"],
            "34. –û–•–†–ê–ù–ê –¢–†–£–î–ê - –ö–ù–ò–ì–ò": ["–£—á–µ–±–Ω–∏–∫–∏", "–ü–æ—Å–æ–±–∏—è", "–°–ø—Ä–∞–≤–æ—á–Ω–∏–∫–∏"],
            
            # === HR –ò –¢–†–£–î–û–í–û–ï –ü–†–ê–í–û ===
            "35. HR - –¢–†–£–î–û–í–û–ï –ü–†–ê–í–û": ["–¢–ö –†–§", "–§–ó", "–ü–æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è –í–° –†–§"],
            "36. HR - –ö–ê–î–†–û–í–û–ï –î–ï–õ–û–ü–†–û–ò–ó–í–û–î–°–¢–í–û": ["–ü—Ä–∏–∫–∞–∑—ã", "–ü–æ–ª–æ–∂–µ–Ω–∏—è", "–ò–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏"],
            "37. HR - –î–û–ö–£–ú–ï–ù–¢–´ –ö–ê–î–†–û–í–´–ï": ["–¢—Ä—É–¥–æ–≤—ã–µ –¥–æ–≥–æ–≤–æ—Ä—ã", "–ü—Ä–∏–∫–∞–∑—ã", "–õ–∏—á–Ω—ã–µ –∫–∞—Ä—Ç–æ—á–∫–∏"],
            "38. HR - –û–ü–õ–ê–¢–ê –¢–†–£–î–ê": ["–ú–†–û–¢", "–†–∞–π–æ–Ω–Ω—ã–µ –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç—ã", "–ù–∞–¥–±–∞–≤–∫–∏"],
            "39. HR - –û–¢–ü–£–°–ö–ê –ò –ë–û–õ–¨–ù–ò–ß–ù–´–ï": ["–†–∞—Å—á–µ—Ç—ã", "–§–æ—Ä–º—ã", "–°–ø—Ä–∞–≤–∫–∏"],
            "40. HR - –ê–¢–¢–ï–°–¢–ê–¶–ò–Ø": ["–ü–æ–ª–æ–∂–µ–Ω–∏—è", "–§–æ—Ä–º—ã", "–ö—Ä–∏—Ç–µ—Ä–∏–∏"],
            "41. HR - –ö–ù–ò–ì–ò": ["–£—á–µ–±–Ω–∏–∫–∏ –ø–æ HR", "–ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –ø–æ—Å–æ–±–∏—è", "–ü—Å–∏—Ö–æ–ª–æ–≥–∏—è"],
            
            # === –≠–ö–û–õ–û–ì–ò–Ø ===
            "42. –≠–ö–û–õ–û–ì–ò–Ø - –ó–ê–ö–û–ù–´": ["–§–ó –û–± –æ—Ö—Ä–∞–Ω–µ –æ–∫—Ä—É–∂–∞—é—â–µ–π —Å—Ä–µ–¥—ã", "–í–æ–¥–Ω—ã–π –∫–æ–¥–µ–∫—Å", "–õ–µ—Å–Ω–æ–π –∫–æ–¥–µ–∫—Å"],
            "43. –≠–ö–û–õ–û–ì–ò–Ø - –ù–û–†–ú–ê–¢–ò–í–´": ["–ü–î–ö", "–ü–î–í", "–ù–î–°", "–õ–∏–º–∏—Ç—ã"],
            "44. –≠–ö–û–õ–û–ì–ò–Ø - –†–ê–ó–†–ï–®–ï–ù–ò–Ø": ["–õ–∏—Ü–µ–Ω–∑–∏–∏", "–†–∞–∑—Ä–µ—à–µ–Ω–∏—è –Ω–∞ –≤—ã–±—Ä–æ—Å—ã", "–ü–ù–û–û–õ–†"],
            "45. –≠–ö–û–õ–û–ì–ò–Ø - –û–¢–ß–ï–¢–ù–û–°–¢–¨": ["2-–¢–ü", "–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞", "–î–µ–∫–ª–∞—Ä–∞—Ü–∏–∏"],
            "46. –≠–ö–û–õ–û–ì–ò–Ø - –ú–û–ù–ò–¢–û–†–ò–ù–ì": ["–ü–≠–ö", "–ü–≠–ú", "–ò–∑–º–µ—Ä–µ–Ω–∏—è", "–ö–æ–Ω—Ç—Ä–æ–ª—å"],
            "47. –≠–ö–û–õ–û–ì–ò–Ø - –û–¢–•–û–î–´": ["–§–ö–ö–û", "–ü–∞—Å–ø–æ—Ä—Ç–∞ –æ—Ç—Ö–æ–¥–æ–≤", "–û–±—Ä–∞—â–µ–Ω–∏–µ —Å –æ—Ç—Ö–æ–¥–∞–º–∏"],
            "48. –≠–ö–û–õ–û–ì–ò–Ø - –ö–ù–ò–ì–ò": ["–£—á–µ–±–Ω–∏–∫–∏", "–°–ø—Ä–∞–≤–æ—á–Ω–∏–∫–∏", "–ú–µ—Ç–æ–¥–∏—á–µ—Å–∫–∏–µ –ø–æ—Å–æ–±–∏—è"],
            
            # === –û–ë–£–ß–ê–Æ–©–ò–ï –ú–ê–¢–ï–†–ò–ê–õ–´ ===
            "49. –õ–ï–ö–¶–ò–ò –ò –ö–£–†–°–´": ["–í–∏–¥–µ–æ–ª–µ–∫—Ü–∏–∏", "–ü—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏–∏", "–ö–æ–Ω—Å–ø–µ–∫—Ç—ã"],
            "50. –ö–ù–ò–ì–ò –û–ë–©–ò–ï": ["–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è –ª–∏—Ç–µ—Ä–∞—Ç—É—Ä–∞", "–°–ø—Ä–∞–≤–æ—á–Ω–∏–∫–∏", "–≠–Ω—Ü–∏–∫–ª–æ–ø–µ–¥–∏–∏"],
            "51. –°–¢–ê–ù–î–ê–†–¢–´ –ö–ê–ß–ï–°–¢–í–ê": ["ISO", "–ì–û–°–¢ –† –ò–°–û", "–°–∏—Å—Ç–µ–º—ã –º–µ–Ω–µ–¥–∂–º–µ–Ω—Ç–∞"],
            "52. –ü–†–û–ï–ö–¢–ò–†–û–í–ê–ù–ò–ï": ["–°–ê–ü–†", "BIM", "–¢–µ—Ö–Ω–æ–ª–æ–≥–∏–∏ –ø—Ä–æ–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"],
            
            # === –ü–†–û–ß–ï–ï ===
            "99. –î–†–£–ì–ò–ï –î–û–ö–£–ú–ï–ù–¢–´": ["–†–∞–∑–Ω–æ–µ", "–ê—Ä—Ö–∏–≤", "–í—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã"]
        }
    }
    
    folder_mapping = {}
    
    # Create folder structure
    for main_folder, subfolders in structure.items():
        main_path = Path(base_path) / main_folder
        main_path.mkdir(parents=True, exist_ok=True)
        folder_mapping[main_folder] = str(main_path)
        
        for subfolder, prefixes in subfolders.items():
            sub_path = main_path / subfolder
            sub_path.mkdir(parents=True, exist_ok=True)
            folder_mapping[subfolder] = str(sub_path)
    
    logger.info(f"Created normative documents folder structure in {base_path}")
    return folder_mapping

def rename_normative_file(file_path: str, doc_info: Dict, normative_db: NormativeDatabase) -> str:
    """Rename normative file with proper naming convention"""
    try:
        if not doc_info.get("code"):
            return file_path
        
        code = doc_info["code"]
        title = doc_info.get("title", "–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è")
        
        # Get document from database
        norm_doc = normative_db.get_document(code)
        if not norm_doc:
            # If not in database, use extracted info
            new_file_name = f"{code}_{title.replace(' ', '_')}.pdf"
        else:
            # Use database info
            new_file_name = f"{norm_doc.code}_{norm_doc.title.replace(' ', '_')}.pdf"
        
        # Remove invalid characters
        new_file_name = re.sub(r'[\\/*?:"<>|]', "_", new_file_name)
        new_file_path = Path(file_path).parent / new_file_name
        
        # Rename file if needed
        if str(new_file_path) != file_path:
            Path(file_path).rename(new_file_path)
            logger.info(f"Renamed file: {Path(file_path).name} -> {new_file_name}")
            return str(new_file_path)
        else:
            return file_path
            
    except Exception as e:
        logger.error(f"Error renaming file: {e}")
        return file_path

def ntd_preprocess(file_path: str, normative_db: NormativeDatabase, normative_checker: NormativeChecker, 
                  target_dir: Optional[str] = None, test_mode: bool = False) -> Optional[str]:
    """
    Stage 0: Pre-process normative document
    This function integrates into the 14-stage RAG pipeline as the initial stage
    for normative technical documentation files
    """
    # Use BASE_DIR environment variable or default to I:/docs
    if target_dir is None:
        base_dir_env = os.getenv("BASE_DIR", "I:/docs")
        target_dir = base_dir_env  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –±–∞–∑–æ–≤—É—é –ø–∞–ø–∫—É –Ω–∞–ø—Ä—è–º—É—é
    
    try:
        logger.info(f"Starting NTD preprocessing for: {file_path}")
        
        # 1. Check if file exists and is readable
        if not Path(file_path).exists():
            logger.error(f"File not found: {file_path}")
            return None
        
        if not os.access(file_path, os.R_OK):
            logger.error(f"Cannot read file: {file_path}")
            return None
        
        # 2. Extract content for analysis (basic text extraction)
        content = ""
        try:
            if file_path.lower().endswith('.pdf'):
                # In test mode, try to read as text first
                if test_mode:
                    try:
                        with open(file_path, 'r', encoding='utf-8') as f:
                            content = f.read()
                    except:
                        # If text read fails, try PDF
                        from PyPDF2 import PdfReader
                        reader = PdfReader(file_path)
                        content = ' '.join(page.extract_text() for page in reader.pages if page.extract_text())
                else:
                    from PyPDF2 import PdfReader
                    reader = PdfReader(file_path)
                    content = ' '.join(page.extract_text() for page in reader.pages if page.extract_text())
            elif file_path.lower().endswith('.txt'):
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
        except Exception as e:
            logger.warning(f"Could not extract text from {file_path}: {e}")
        
        # 3. Check document actuality (skip in test mode)
        if test_mode:
            # In test mode, create mock check result based on extracted info
            doc_info = normative_checker.extract_document_info(file_path, content)
            check_result = {
                "status": "test_mode",
                "detected_code": doc_info.get("code", Path(file_path).stem),
                "detected_title": doc_info.get("title", ""),
                "file_path": file_path
            }
        else:
            check_result = normative_checker.check_document_actual(file_path, content)
            logger.info(f"Document check result: {check_result['status']}")
            
            # 4. If document is outdated, try to download actual version
            if check_result["status"] == "outdated" and check_result.get("actual_version"):
                actual_code = check_result["actual_version"]["code"]
                logger.info(f"Downloading actual version: {actual_code}")
                new_file_path = normative_checker.download_document(actual_code, target_dir)
                if new_file_path:
                    logger.info(f"Downloaded actual version: {new_file_path}")
                    file_path = new_file_path
                    # Re-check the new document
                    content = ""
                    try:
                        if file_path.lower().endswith('.pdf'):
                            from PyPDF2 import PdfReader
                            reader = PdfReader(file_path)
                            content = ' '.join(page.extract_text() for page in reader.pages if page.extract_text())
                    except Exception as e:
                        logger.warning(f"Could not extract text from downloaded file: {e}")
                    
                    check_result = normative_checker.check_document_actual(file_path, content)
                else:
                    logger.warning("Failed to download actual version")
            
            # 5. If document is not found in DB, continue processing anyway
            if check_result["status"] in ["not_found", "not_in_db"]:
                logger.info(f"Document not in NTD database, but continuing processing: {check_result['status']}")
                # Continue processing even if not in NTD database
        
        # 6. Rename file with proper naming convention
        renamed_file_path = rename_normative_file(file_path, check_result, normative_db)
        
        # 7. Move file to appropriate –ë–ê–ó–ê category folder based on document type
        doc_info = normative_checker.extract_document_info(renamed_file_path, content)
        file_name_lower = Path(renamed_file_path).name.lower()
        
        # Determine category based on document type patterns
        category_path = _determine_document_category(file_name_lower, content)
        
        # Create full path: I:/docs/–ë–ê–ó–ê/{category}/
        base_dir_env = os.getenv("BASE_DIR", "I:/docs")
        target_path = Path(base_dir_env) / "–ë–ê–ó–ê" / category_path
        target_path.mkdir(parents=True, exist_ok=True)
        
        # Move file to appropriate category folder
        final_file_path = target_path / Path(renamed_file_path).name
        if str(final_file_path) != renamed_file_path:
            try:
                import shutil
                shutil.move(renamed_file_path, str(final_file_path))
                renamed_file_path = str(final_file_path)
                logger.info(f"üìÅ Moved file to –ë–ê–ó–ê category: {category_path}")
            except Exception as e:
                logger.error(f"Error moving file to category folder: {e}")
                # If move fails, continue with original path
        
        # 8. Mark as processed in database
        if doc_info.get("code"):
            normative_db.mark_as_processed(doc_info["code"], renamed_file_path)
        
        logger.info(f"NTD preprocessing completed: {renamed_file_path}")
        return renamed_file_path
        
    except Exception as e:
        logger.error(f"Error in NTD preprocessing: {e}")
        return None

# Example usage function
def initialize_ntd_system(base_dir: Optional[str] = None) -> Tuple[NormativeDatabase, NormativeChecker]:
    """Initialize NTD system with database and checker"""
    # Use BASE_DIR environment variable or default to I:/docs
    if base_dir is None:
        base_dir_env = os.getenv("BASE_DIR", "I:/docs")
        base_dir = base_dir_env
    
    # Create folder structure
    organize_normative_documents(base_dir)
    
    # Initialize database
    normative_db = NormativeDatabase(
        db_path=os.path.join(base_dir, "norms_db", "ntd_local.db"),
        json_path=os.path.join(base_dir, "norms_db", "ntd_full_db.json")
    )
    
    # Initialize checker
    normative_checker = NormativeChecker(normative_db)
    
    return normative_db, normative_checker

if __name__ == "__main__":
    # Example usage
    normative_db, normative_checker = initialize_ntd_system()
    print(f"Initialized NTD system with {len(normative_db.documents)} documents")
    
    # Example search
    results = normative_db.search_documents("—Å—Ç—Ä–æ–∏—Ç–µ–ª—å—Å—Ç–≤–æ", "construction")
    print(f"Found {len(results)} construction documents")
    
    # Example document check
    # check_result = normative_checker.check_document_actual("example_file.pdf")
    # print(f"Document check result: {check_result}")