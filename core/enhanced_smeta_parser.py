"""
–£–ª—É—á—à–µ–Ω–Ω—ã–π –ø–∞—Ä—Å–µ—Ä —Å–º–µ—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ –Ω–∞—Ä–∞–±–æ—Ç–æ–∫ –∏–∑ I:\–Ω–µ–π—Ä–æ—Å–µ—Ç–∫–∏\—Å—Ç—Ä–æ–π—Ç—ç–∫\–ø—Ä–æ–≥–∞
–ò–Ω—Ç–µ–≥—Ä–∏—Ä—É–µ—Ç –ª—É—á—à–∏–µ –ø—Ä–∞–∫—Ç–∏–∫–∏ –∏–∑ adaptive_estimate_parser.py
"""

import pandas as pd
import re
import uuid
import os
import tempfile
from typing import List, Dict, Any, Optional, Tuple, Set
from pathlib import Path
from enum import Enum
import logging

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º openpyxl –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–º–∏ —è—á–µ–π–∫–∞–º–∏
try:
    import openpyxl
    from openpyxl import load_workbook
    HAS_OPENPYXL = True
except ImportError:
    HAS_OPENPYXL = False
    openpyxl = None
    load_workbook = None

logger = logging.getLogger(__name__)

class EstimateFormat(Enum):
    """–¢–∏–ø—ã —Ñ–æ—Ä–º–∞—Ç–æ–≤ —Ä–æ—Å—Å–∏–π—Å–∫–∏—Ö —Å–º–µ—Ç"""
    GRAND_SMETA = "grand_smeta"
    SMETA_RU = "smeta_ru" 
    AVK5 = "avk5"
    WIN_SMETA = "win_smeta"
    TURBO_SMETKA = "turbo_smetka"
    GOSSTROY_SMETA = "gosstroy_smeta"
    UNKNOWN = "unknown"

class EnhancedSmetaParser:
    """–£–ª—É—á—à–µ–Ω–Ω—ã–π –ø–∞—Ä—Å–µ—Ä –¥–ª—è –≤—Å–µ—Ö —Ä–æ—Å—Å–∏–π—Å–∫–∏—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤ —Å–º–µ—Ç"""
    
    def __init__(self):
        self._init_format_signatures()
        self._init_common_mappings()
        self.detected_format = EstimateFormat.UNKNOWN
        
    def _init_format_signatures(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–∏–≥–Ω–∞—Ç—É—Ä —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤"""
        self.format_signatures = {
            EstimateFormat.GRAND_SMETA: {
                'keywords': ['–≥—Ä–∞–Ω–¥-—Å–º–µ—Ç–∞', '–≤—Å–µ–≥–æ –ø–æ –ø–æ–∑–∏—Ü–∏–∏', '–∏—Ç–æ–≥–æ –ø–æ —Ä–∞—Å—Ü–µ–Ω–∫–µ', '—Å–º—Ä', '–≥—Å', '–≥—Å–Ω', '—Ñ—Å–Ω', '—Ç–µ—Ä', '—Ñ–µ—Ä', '–≥—ç—Å–Ω'],
                'header_patterns': ['–Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ —Ä–∞–±–æ—Ç', '–æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ', '—Å–º–µ—Ç–Ω–∞—è —Å—Ç–æ–∏–º–æ—Å—Ç—å', '—à–∏—Ñ—Ä', '–∫–æ–¥ —Ä–µ—Å—É—Ä—Å–∞', '–µ–¥.–∏–∑–º.', '–µ–¥. –∏–∑–º', '–∫–æ–ª-–≤–æ', '–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ', '—Ü–µ–Ω–∞', '—Å—É–º–º–∞', '–≤—Å–µ–≥–æ'],
                'cost_patterns': ['–±–∞–∑–∏—Å–Ω', '—Ç–µ–∫—É—â', '–∏–Ω–¥–µ–∫—Å', '—Å–º–µ—Ç–Ω', '—Ü–µ–Ω—ã', '—Ä–∞—Å—Ü–µ–Ω–∫'],
                'structure_indicators': ['—Å–ø—Ä–∞–≤–æ—á–Ω–æ', '—Ñ–æ—Ç', '–Ω—Ä', '—Å–ø', '–Ω–¥—Å', '–∏—Ç–æ–≥–æ']
            },
            EstimateFormat.SMETA_RU: {
                'keywords': ['smeta.ru', '–∏—Ç–æ–≥–æ –ø–æ–∑–∏—Ü–∏–∏', '–≤—Å–µ–≥–æ —Ä–∞–±–æ—Ç', '—Å–º–µ—Ç–∞ —Ç–æ—á–∫–∞ —Ä—É', '—Å–º–µ—Ç–∞.—Ä—É', 'smeta', '—Å–º–µ—Ç–∞'],
                'header_patterns': ['—Ä–∞–±–æ—Ç—ã –∏ –∑–∞—Ç—Ä–∞—Ç—ã', '—à–∏—Ñ—Ä –Ω–æ—Ä–º–∞—Ç–∏–≤–∞', '—Å—Ç–æ–∏–º–æ—Å—Ç—å –≤—Å–µ–≥–æ', '–Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ', '–µ–¥. –∏–∑–º.', '–∫–æ–ª-–≤–æ', '—à–∏—Ñ—Ä', '–∫–æ–¥', '–æ–±—ä–µ–º', '—Ü–µ–Ω–∞ –∑–∞ –µ–¥.', '—Å—É–º–º–∞'],
                'cost_patterns': ['—Å—Ç–æ–∏–º–æ—Å—Ç—å –≤ —Ü–µ–Ω–∞—Ö', '–æ–±—â–∞—è —Å—Ç–æ–∏–º–æ—Å—Ç—å', '—Ç–µ–∫—É—â–∏–µ —Ü–µ–Ω—ã', '–±–∞–∑–∏—Å–Ω—ã–µ —Ü–µ–Ω—ã', '—Å–º–µ—Ç–Ω—ã–µ —Ü–µ–Ω—ã', '—Ü–µ–Ω—ã'],
                'structure_indicators': ['–Ω–æ—Ä–º–∞—Ç–∏–≤—ã', '—Ä–∞—Å—Ü–µ–Ω–∫–∏', '–≤—Å–µ–≥–æ –ø–æ –ø–æ–∑–∏—Ü–∏–∏', '–∏—Ç–æ–≥–æ –ø–æ —Ä–∞—Å—Ü–µ–Ω–∫–µ', '—Ñ–æ—Ç', '–Ω—Ä', '—Å–ø']
            },
            EstimateFormat.AVK5: {
                'keywords': ['–∞–≤–∫', '—Å–∏—Å—Ç–µ–º–∞ –∞–≤–∫', '–¥–±–Ω', '–¥—Å—Ç—É', '–∞–≤–∫-5'],
                'header_patterns': ['–Ω–∞–π–º–µ–Ω—É–≤–∞–Ω–Ω—è —Ä–æ–±—ñ—Ç', '–æ–¥–∏–Ω–∏—Ü—è –≤–∏–º—ñ—Ä—É', '–∫—ñ–ª—å–∫—ñ—Å—Ç—å', '—Ü—ñ–Ω–∞', '—Å—É–º–∞', '—à–∏—Ñ—Ä', '–∫–æ–¥'],
                'cost_patterns': ['–≤–∞—Ä—Ç—ñ—Å—Ç—å', '—Å—É–º–∞', '—Ü—ñ–Ω–∞', '—Ü–µ–Ω—ã'],
                'structure_indicators': ['–∑–∞—Ä–æ–±—ñ—Ç–Ω–∞ –ø–ª–∞—Ç–∞', '–º–∞—Ç–µ—Ä—ñ–∞–ª–∏', '–Ω—Ä', '—Å–ø']
            },
            EstimateFormat.WIN_SMETA: {
                'keywords': ['win —Å–º–µ—Ç–∞', '–≤–∏–Ω—Å–º–µ—Ç–∞', '–∏—Ç–æ–≥–æ —Å–º–µ—Ç–∞', 'win—Å–º–µ—Ç–∞'],
                'header_patterns': ['–æ–ø–∏—Å–∞–Ω–∏–µ —Ä–∞–±–æ—Ç', '–µ–¥.–∏–∑–º', '–æ–±—ä–µ–º', '–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ', '—Ü–µ–Ω–∞', '—Å—É–º–º–∞', '—à–∏—Ñ—Ä', '–∫–æ–¥'],
                'cost_patterns': ['—Å—É–º–º–∞', '—Å—Ç–æ–∏–º–æ—Å—Ç—å —Ä—É–±', '—Ü–µ–Ω–∞', '—Å–º–µ—Ç–Ω'],
                'structure_indicators': ['–º–∞—Ç–µ—Ä–∏–∞–ª—å–Ω—ã–µ —Ä–µ—Å—É—Ä—Å—ã', '—Ç—Ä—É–¥–æ–∑–∞—Ç—Ä–∞—Ç—ã', '–Ω—Ä', '—Å–ø']
            }
        }
    
    def _init_common_mappings(self):
        """–û–±—â–∏–µ –º–∞–ø–ø–∏–Ω–≥–∏ –¥–ª—è –≤—Å–µ—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤"""
        self.unit_mappings = {
            # –û–±—ä–µ–º–Ω—ã–µ
            '–º3': '–º¬≥', '–∫—É–±.–º': '–º¬≥', '–º¬≥': '–º¬≥',
            '100 –º3': '–º¬≥', '–º3 –≥—Ä—É–Ω—Ç–∞': '–º¬≥',
            # –ü–ª–æ—â–∞–¥–Ω—ã–µ  
            '–º2': '–º¬≤', '–∫–≤.–º': '–º¬≤', '–º¬≤': '–º¬≤',
            '100 –º2': '–º¬≤',
            # –õ–∏–Ω–µ–π–Ω—ã–µ
            '–º': '–º', '–ø.–º': '–º', '–º.–ø': '–º',
            # –ú–∞—Å—Å–æ–≤—ã–µ
            '–∫–≥': '–∫–≥', '—Ç': '—Ç', '—Ç–æ–Ω–Ω': '—Ç',
            # –®—Ç—É—á–Ω—ã–µ
            '—à—Ç': '—à—Ç', '–∫–æ–º–ø–ª–µ–∫—Ç': '–∫–æ–º–ø–ª–µ–∫—Ç',
            # –í—Ä–µ–º–µ–Ω–Ω—ã–µ
            '—á': '—á', '—á–∞—Å': '—á', '—á–µ–ª.—á–∞—Å': '—á'
        }
        
        self.work_material_codes = {
            'work_prefixes': [
                '–¢–ï–†', '–§–ï–†', '–ì–≠–°–ù', '–ì–≠–°–ù—Ä', '–ì–≠–°–ù–º', '–§–°–≠–ú', '–¢–°–≠–ú',
                '–¢–ï–†–º', '–¢–ï–†–ø', '–§–ï–†–º', '–§–ï–†–ø', '–ì–≠–°–ù-2020', '–§–ï–†-2020', '–¢–ï–†-2020',
                '–§–°–°–¶-TER', '–¢–°–≠–ú-2020', '–§–°–≠–ú-2020', '–ì–≠–°–ù—Ä-2020', '–ì–≠–°–ù–º-2020',
                '–°–°–ù', '–í–°–ù', '–†–î', '–ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è', '–ú–µ—Ç–æ–¥–∏–∫–∞', '–ï–ù–∏–†', '–ì–û–°–¢', '–°–ù–∏–ü',
                '–°–ü', '–°–¢–û', '–¢–£', '–û–°–¢', '–†–î-11-02', '–†–î-11-05', '–ú–î–°', '–í–µ–¥–æ–º—Å—Ç–≤–µ–Ω–Ω—ã–µ',
                '–ú–∏–Ω—Ä–µ–≥–∏–æ–Ω', '–ú–∏–Ω—Å—Ç—Ä–æ–π', '–ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ', '–ü—É–Ω–∫—Ç', '–ß–∞—Å—Ç—å', '–†–∞–∑–¥–µ–ª'
            ],
            'material_prefixes': [
                '–ú–ê–¢', '–ú–ê–¢–ï–†–ò–ê–õ', '–†–ï–°–£–†–°', '–ú–ê–¢–ï–†–ò–ê–õ–¨–ù–´–ï –†–ï–°–£–†–°–´',
                '–ú–ê–¢–ï–†–ò–ê–õ–´', '–ú–ê–¢–ï–†–ò–ê–õ–¨–ù–´–ï –ó–ê–¢–†–ê–¢–´', '–ú–ê–¢–ï–†–ò–ê–õ–¨–ù–´–ï –†–ï–°–£–†–°–´'
            ]
        }
    
    def detect_format(self, file_path: str) -> EstimateFormat:
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ñ–æ—Ä–º–∞—Ç–∞ —Å–º–µ—Ç—ã –ø–æ —Ñ–∞–π–ª—É"""
        try:
            # –ß–∏—Ç–∞–µ–º –ø–µ—Ä–≤—ã–µ —Å—Ç—Ä–æ–∫–∏ —Ñ–∞–π–ª–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            if file_path.endswith(('.xlsx', '.xls')):
                df = pd.read_excel(file_path, nrows=20)
                text_content = ' '.join(df.astype(str).values.flatten())
            elif file_path.endswith('.csv'):
                df = pd.read_csv(file_path, nrows=20, encoding='utf-8')
                text_content = ' '.join(df.astype(str).values.flatten())
            else:
                with open(file_path, 'r', encoding='utf-8') as f:
                    text_content = f.read()[:5000]  # –ü–µ—Ä–≤—ã–µ 5000 —Å–∏–º–≤–æ–ª–æ–≤
            
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–∏–≥–Ω–∞—Ç—É—Ä—ã
            for format_type, signatures in self.format_signatures.items():
                score = 0
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞
                for keyword in signatures['keywords']:
                    if keyword.lower() in text_content.lower():
                        score += 2
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω—ã –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤
                for pattern in signatures['header_patterns']:
                    if pattern.lower() in text_content.lower():
                        score += 1
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω—ã —Å—Ç–æ–∏–º–æ—Å—Ç–∏
                for pattern in signatures['cost_patterns']:
                    if pattern.lower() in text_content.lower():
                        score += 1
                
                # –ï—Å–ª–∏ –Ω–∞–±—Ä–∞–ª–∏ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –æ—á–∫–æ–≤, —Å—á–∏—Ç–∞–µ–º —Ñ–æ—Ä–º–∞—Ç –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–º
                if score >= 3:
                    self.detected_format = format_type
                    logger.info(f"–û–ø—Ä–µ–¥–µ–ª–µ–Ω —Ñ–æ—Ä–º–∞—Ç: {format_type.value} (–æ—á–∫–æ–≤: {score})")
                    return format_type
            
            logger.warning("–ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Ñ–æ—Ä–º–∞—Ç —Å–º–µ—Ç—ã")
            return EstimateFormat.UNKNOWN
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ñ–æ—Ä–º–∞—Ç–∞: {e}")
            return EstimateFormat.UNKNOWN
    
    def _process_merged_cells(self, file_path: str) -> str:
        """üö® –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ô –§–ò–ö–°: –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã—Ö —è—á–µ–µ–∫"""
        if not HAS_OPENPYXL:
            logger.warning("openpyxl –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã—Ö —è—á–µ–µ–∫")
            return file_path
        
        try:
            # 1. –ó–∞–≥—Ä—É–∂–∞–µ–º —Ñ–∞–π–ª —á–µ—Ä–µ–∑ openpyxl
            workbook = load_workbook(file_path, data_only=True)
            sheet = workbook.active
            
            logger.info(f"üîç –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã—Ö —è—á–µ–µ–∫ –≤ —Ñ–∞–π–ª–µ: {file_path}")
            
            # 2. –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –≤—Å–µ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–µ –¥–∏–∞–ø–∞–∑–æ–Ω—ã
            merged_ranges = list(sheet.merged_cells.ranges)
            logger.info(f"üìä –ù–∞–π–¥–µ–Ω–æ {len(merged_ranges)} –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã—Ö –¥–∏–∞–ø–∞–∑–æ–Ω–æ–≤")
            
            for merged_range in merged_ranges:
                # –ü–æ–ª—É—á–∞–µ–º –≥—Ä–∞–Ω–∏—Ü—ã –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω–æ–≥–æ –¥–∏–∞–ø–∞–∑–æ–Ω–∞
                min_row, min_col, max_row, max_col = merged_range.bounds
                
                # –ü–æ–ª—É—á–∞–µ–º –∑–Ω–∞—á–µ–Ω–∏–µ –∏–∑ –ø–µ—Ä–≤–æ–π —è—á–µ–π–∫–∏
                top_left_cell = sheet.cell(row=min_row, column=min_col)
                top_left_value = top_left_cell.value
                
                if top_left_value is not None:
                    # –ü—Ä–∏—Å–≤–∞–∏–≤–∞–µ–º –∑–Ω–∞—á–µ–Ω–∏–µ –≤—Å–µ–º —è—á–µ–π–∫–∞–º –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ
                    for row in range(min_row, max_row + 1):
                        for col in range(min_col, max_col + 1):
                            cell = sheet.cell(row=row, column=col)
                            if cell.value is None:
                                cell.value = top_left_value
                                logger.debug(f"üìù –ó–∞–ø–æ–ª–Ω–µ–Ω–∞ —è—á–µ–π–∫–∞ {cell.coordinate}: {top_left_value}")
            
            # 3. –†–∞–∑—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ —è—á–µ–π–∫–∏
            for merged_range in merged_ranges:
                sheet.unmerge_cells(str(merged_range))
            
            # 4. –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
            temp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.xlsx')
            temp_file_path = temp_file.name
            temp_file.close()
            
            workbook.save(temp_file_path)
            logger.info(f"üíæ –°–æ–∑–¥–∞–Ω –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –±–µ–∑ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã—Ö —è—á–µ–µ–∫: {temp_file_path}")
            
            return temp_file_path
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã—Ö —è—á–µ–µ–∫: {e}")
            return file_path  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π —Ñ–∞–π–ª
    
    def parse_excel_estimate(self, file_path: str) -> Dict[str, Any]:
        """–ü–∞—Ä—Å–∏–Ω–≥ Excel —Å–º–µ—Ç—ã —Å —É–ª—É—á—à–µ–Ω–Ω–æ–π –ª–æ–≥–∏–∫–æ–π"""
        temp_file_path = None
        try:
            # üö® –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ô –§–ò–ö–°: –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–µ —è—á–µ–π–∫–∏
            temp_file_path = self._process_merged_cells(file_path)
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ñ–æ—Ä–º–∞—Ç
            format_type = self.detect_format(temp_file_path)
            
            # –ß–∏—Ç–∞–µ–º Excel —Ñ–∞–π–ª (—Ç–µ–ø–µ—Ä—å –±–µ–∑ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã—Ö —è—á–µ–µ–∫!)
            df = pd.read_excel(temp_file_path, sheet_name=None)
            
            # –í—ã–±–∏—Ä–∞–µ–º –æ—Å–Ω–æ–≤–Ω–æ–π –ª–∏—Å—Ç
            main_sheet = None
            if len(df) == 1:
                main_sheet = list(df.values())[0]
            else:
                # –ò—â–µ–º –ª–∏—Å—Ç —Å –Ω–∞–∏–±–æ–ª—å—à–∏–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –¥–∞–Ω–Ω—ã—Ö
                max_rows = 0
                for sheet_name, sheet_df in df.items():
                    if len(sheet_df) > max_rows:
                        max_rows = len(sheet_df)
                        main_sheet = sheet_df
            
            if main_sheet is None:
                raise ValueError("–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –æ—Å–Ω–æ–≤–Ω–æ–π –ª–∏—Å—Ç —Å –¥–∞–Ω–Ω—ã–º–∏")
            
            # –û—á–∏—â–∞–µ–º –¥–∞–Ω–Ω—ã–µ
            main_sheet = main_sheet.dropna(how='all')
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –∫–æ–ª–æ–Ω–æ–∫
            columns_mapping = self._detect_columns_structure(main_sheet, format_type)
            
            # –ü–∞—Ä—Å–∏–º –ø–æ–∑–∏—Ü–∏–∏
            positions = self._parse_positions(main_sheet, columns_mapping, format_type)
            
            # –í—ã—á–∏—Å–ª—è–µ–º –∏—Ç–æ–≥–∏
            total_cost = sum(pos.get('total_cost', 0) for pos in positions)
            
            return {
                'format': format_type.value,
                'positions': positions,
                'total_cost': total_cost,
                'positions_count': len(positions),
                'metadata': {
                    'file_path': file_path,
                    'parsed_at': pd.Timestamp.now().isoformat(),
                    'columns_mapping': columns_mapping,
                    'merged_cells_processed': temp_file_path != file_path
                }
            }
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ Excel —Ñ–∞–π–ª–∞: {e}")
            return {
                'format': 'unknown',
                'positions': [],
                'total_cost': 0,
                'positions_count': 0,
                'error': str(e)
            }
        finally:
            # üßπ –û—á–∏—â–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
            if temp_file_path and temp_file_path != file_path and os.path.exists(temp_file_path):
                try:
                    os.unlink(temp_file_path)
                    logger.debug(f"üóëÔ∏è –£–¥–∞–ª–µ–Ω –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª: {temp_file_path}")
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª: {e}")
    
    def _detect_columns_structure(self, df: pd.DataFrame, format_type: EstimateFormat) -> Dict[str, str]:
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –∫–æ–ª–æ–Ω–æ–∫"""
        columns_mapping = {}
        
        # –ü–æ–ª—É—á–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏—è –∫–æ–ª–æ–Ω–æ–∫
        columns = df.columns.tolist()
        
        # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –ø–æ–∏—Å–∫–∞ –∫–æ–ª–æ–Ω–æ–∫
        patterns = {
            'code': ['—à–∏—Ñ—Ä', '–∫–æ–¥', '–æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ', '–Ω–æ—Ä–º–∞—Ç–∏–≤', '—Ä–µ—Å—É—Ä—Å'],
            'description': ['–Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ', '–æ–ø–∏—Å–∞–Ω–∏–µ', '—Ä–∞–±–æ—Ç—ã', '–∑–∞—Ç—Ä–∞—Ç—ã', '–Ω–∞–∑–≤–∞–Ω–∏–µ'],
            'unit': ['–µ–¥.–∏–∑–º', '–µ–¥. –∏–∑–º', '–µ–¥–∏–Ω–∏—Ü–∞', '–∏–∑–º–µ—Ä–µ–Ω–∏—è', '–∏–∑–º'],
            'quantity': ['–∫–æ–ª-–≤–æ', '–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ', '–æ–±—ä–µ–º', '–∫-–≤–æ', '–∫–æ–ª'],
            'price': ['—Ü–µ–Ω–∞', '—Å—Ç–æ–∏–º–æ—Å—Ç—å', '—Ä—É–±', '—Ä—É–±–ª–µ–π', '—Ü–µ–Ω–∞ –∑–∞ –µ–¥'],
            'total': ['—Å—É–º–º–∞', '–∏—Ç–æ–≥–æ', '–≤—Å–µ–≥–æ', '–æ–±—â–∞—è —Å—Ç–æ–∏–º–æ—Å—Ç—å', '—Å—Ç–æ–∏–º–æ—Å—Ç—å –≤—Å–µ–≥–æ']
        }
        
        for pattern_name, pattern_list in patterns.items():
            for col in columns:
                col_lower = str(col).lower()
                for pattern in pattern_list:
                    if pattern in col_lower:
                        columns_mapping[pattern_name] = col
                        break
                if pattern_name in columns_mapping:
                    break
        
        return columns_mapping
    
    def _parse_positions(self, df: pd.DataFrame, columns_mapping: Dict[str, str], format_type: EstimateFormat) -> List[Dict[str, Any]]:
        """–ü–∞—Ä—Å–∏–Ω–≥ –ø–æ–∑–∏—Ü–∏–π —Å–º–µ—Ç—ã"""
        positions = []
        
        for idx, row in df.iterrows():
            try:
                # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞–Ω–Ω—ã–µ –ø–æ –º–∞–ø–ø–∏–Ω–≥—É –∫–æ–ª–æ–Ω–æ–∫
                position = {
                    'id': str(uuid.uuid4()),
                    'row_number': idx + 1
                }
                
                # –ö–æ–¥/—à–∏—Ñ—Ä
                if 'code' in columns_mapping:
                    position['code'] = str(row.get(columns_mapping['code'], '')).strip()
                
                # –û–ø–∏—Å–∞–Ω–∏–µ
                if 'description' in columns_mapping:
                    position['description'] = str(row.get(columns_mapping['description'], '')).strip()
                
                # –ï–¥–∏–Ω–∏—Ü–∞ –∏–∑–º–µ—Ä–µ–Ω–∏—è
                if 'unit' in columns_mapping:
                    unit = str(row.get(columns_mapping['unit'], '')).strip()
                    position['unit'] = self.unit_mappings.get(unit, unit)
                
                # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ
                if 'quantity' in columns_mapping:
                    quantity = row.get(columns_mapping['quantity'])
                    if pd.notna(quantity):
                        try:
                            position['quantity'] = float(quantity)
                        except (ValueError, TypeError):
                            position['quantity'] = 0.0
                    else:
                        position['quantity'] = 0.0
                
                # –¶–µ–Ω–∞
                if 'price' in columns_mapping:
                    price = row.get(columns_mapping['price'])
                    if pd.notna(price):
                        try:
                            position['price'] = float(price)
                        except (ValueError, TypeError):
                            position['price'] = 0.0
                    else:
                        position['price'] = 0.0
                
                # –û–±—â–∞—è —Å—Ç–æ–∏–º–æ—Å—Ç—å
                if 'total' in columns_mapping:
                    total = row.get(columns_mapping['total'])
                    if pd.notna(total):
                        try:
                            position['total_cost'] = float(total)
                        except (ValueError, TypeError):
                            position['total_cost'] = 0.0
                    else:
                        position['total_cost'] = 0.0
                
                # –í—ã—á–∏—Å–ª—è–µ–º –æ–±—â—É—é —Å—Ç–æ–∏–º–æ—Å—Ç—å –µ—Å–ª–∏ –Ω–µ —É–∫–∞–∑–∞–Ω–∞
                if position.get('total_cost', 0) == 0 and position.get('quantity', 0) > 0 and position.get('price', 0) > 0:
                    position['total_cost'] = position['quantity'] * position['price']
                
                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –ø–æ–∑–∏—Ü–∏–∏
                position['type'] = self._determine_position_type(position, format_type)
                
                # –§–∏–ª—å—Ç—Ä—É–µ–º –ø—É—Å—Ç—ã–µ –ø–æ–∑–∏—Ü–∏–∏
                if (position.get('description', '').strip() and 
                    position.get('description', '').strip() not in ['', 'nan', 'None']) or \
                   (position.get('code', '').strip() and 
                    position.get('code', '').strip() not in ['', 'nan', 'None']):
                    positions.append(position)
                
            except Exception as e:
                logger.warning(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ —Å—Ç—Ä–æ–∫–∏ {idx + 1}: {e}")
                continue
        
        return positions
    
    def _determine_position_type(self, position: Dict[str, Any], format_type: EstimateFormat) -> str:
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∏–ø–∞ –ø–æ–∑–∏—Ü–∏–∏ (—Ä–∞–±–æ—Ç–∞, –º–∞—Ç–µ—Ä–∏–∞–ª, –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏–µ)"""
        code = position.get('code', '').upper()
        description = position.get('description', '').upper()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–µ—Ñ–∏–∫—Å—ã —Ä–∞–±–æ—Ç
        for prefix in self.work_material_codes['work_prefixes']:
            if code.startswith(prefix) or prefix in description:
                return 'work'
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–µ—Ñ–∏–∫—Å—ã –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤
        for prefix in self.work_material_codes['material_prefixes']:
            if code.startswith(prefix) or prefix in description:
                return 'material'
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º –≤ –æ–ø–∏—Å–∞–Ω–∏–∏
        work_keywords = ['—Ä–∞–±–æ—Ç—ã', '—É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ', '–º–æ–Ω—Ç–∞–∂', '—É—Å—Ç–∞–Ω–æ–≤–∫–∞', '—Å–±–æ—Ä–∫–∞', '–¥–µ–º–æ–Ω—Ç–∞–∂']
        material_keywords = ['–º–∞—Ç–µ—Ä–∏–∞–ª', '–±–µ—Ç–æ–Ω', '—Ü–µ–º–µ–Ω—Ç', '–∞—Ä–º–∞—Ç—É—Ä–∞', '–∫–∏—Ä–ø–∏—á', '–º–µ—Ç–∞–ª–ª']
        
        for keyword in work_keywords:
            if keyword in description:
                return 'work'
        
        for keyword in material_keywords:
            if keyword in description:
                return 'material'
        
        return 'unknown'
    
    def parse_csv_estimate(self, file_path: str) -> Dict[str, Any]:
        """–ü–∞—Ä—Å–∏–Ω–≥ CSV —Å–º–µ—Ç—ã"""
        try:
            # –ß–∏—Ç–∞–µ–º CSV —Ñ–∞–π–ª
            df = pd.read_csv(file_path, encoding='utf-8')
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ñ–æ—Ä–º–∞—Ç
            format_type = self.detect_format(file_path)
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –∫–æ–ª–æ–Ω–æ–∫
            columns_mapping = self._detect_columns_structure(df, format_type)
            
            # –ü–∞—Ä—Å–∏–º –ø–æ–∑–∏—Ü–∏–∏
            positions = self._parse_positions(df, columns_mapping, format_type)
            
            # –í—ã—á–∏—Å–ª—è–µ–º –∏—Ç–æ–≥–∏
            total_cost = sum(pos.get('total_cost', 0) for pos in positions)
            
            return {
                'format': format_type.value,
                'positions': positions,
                'total_cost': total_cost,
                'positions_count': len(positions),
                'metadata': {
                    'file_path': file_path,
                    'parsed_at': pd.Timestamp.now().isoformat(),
                    'columns_mapping': columns_mapping
                }
            }
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ CSV —Ñ–∞–π–ª–∞: {e}")
            return {
                'format': 'unknown',
                'positions': [],
                'total_cost': 0,
                'positions_count': 0,
                'error': str(e)
            }
    
    def parse_text_estimate(self, content: str) -> Dict[str, Any]:
        """–ü–∞—Ä—Å–∏–Ω–≥ —Ç–µ–∫—Å—Ç–æ–≤–æ–π —Å–º–µ—Ç—ã"""
        try:
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ñ–æ—Ä–º–∞—Ç –ø–æ —Å–æ–¥–µ—Ä–∂–∏–º–æ–º—É
            format_type = EstimateFormat.UNKNOWN
            
            # –ò—â–µ–º —Å–∏–≥–Ω–∞—Ç—É—Ä—ã —Ñ–æ—Ä–º–∞—Ç–æ–≤
            for fmt, signatures in self.format_signatures.items():
                score = 0
                for keyword in signatures['keywords']:
                    if keyword.lower() in content.lower():
                        score += 1
                if score >= 2:
                    format_type = fmt
                    break
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø–æ–∑–∏—Ü–∏–∏ –∏–∑ —Ç–µ–∫—Å—Ç–∞
            positions = self._extract_positions_from_text(content, format_type)
            
            # –í—ã—á–∏—Å–ª—è–µ–º –∏—Ç–æ–≥–∏
            total_cost = sum(pos.get('total_cost', 0) for pos in positions)
            
            return {
                'format': format_type.value,
                'positions': positions,
                'total_cost': total_cost,
                'positions_count': len(positions),
                'metadata': {
                    'parsed_at': pd.Timestamp.now().isoformat(),
                    'content_length': len(content)
                }
            }
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ —Ç–µ–∫—Å—Ç–æ–≤–æ–π —Å–º–µ—Ç—ã: {e}")
            return {
                'format': 'unknown',
                'positions': [],
                'total_cost': 0,
                'positions_count': 0,
                'error': str(e)
            }
    
    def _extract_positions_from_text(self, content: str, format_type: EstimateFormat) -> List[Dict[str, Any]]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø–æ–∑–∏—Ü–∏–π –∏–∑ —Ç–µ–∫—Å—Ç–∞"""
        positions = []
        
        # –†–∞–∑–±–∏–≤–∞–µ–º —Ç–µ–∫—Å—Ç –Ω–∞ —Å—Ç—Ä–æ–∫–∏
        lines = content.split('\n')
        
        for line_num, line in enumerate(lines):
            line = line.strip()
            if not line:
                continue
            
            # –ò—â–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω—ã –ø–æ–∑–∏—Ü–∏–π
            position = self._parse_line_as_position(line, line_num + 1)
            if position:
                positions.append(position)
        
        return positions
    
    def _parse_line_as_position(self, line: str, line_num: int) -> Optional[Dict[str, Any]]:
        """–ü–∞—Ä—Å–∏–Ω–≥ —Å—Ç—Ä–æ–∫–∏ –∫–∞–∫ –ø–æ–∑–∏—Ü–∏–∏ —Å–º–µ—Ç—ã"""
        # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö
        patterns = {
            'gesn_code': r'(?:–ì–≠–°–ù|–§–ï–†|–¢–ï–†)\s+(\d+(?:-\d+)*(?:\.\d+)*)',
            'cost': r'(\d+(?:\.\d+)?)\s*(?:—Ä—É–±\.?|—Ä—É–±–ª–µ–π)',
            'quantity': r'(\d+(?:\.\d+)?)\s*(?:–º[¬≤¬≥]|–º2|–º3|—à—Ç|–∫–≥|—Ç|–º|—á)',
            'description': r'([–ê-–Ø–∞-—è\s]+(?:—Ä–∞–±–æ—Ç|—É—Å—Ç—Ä–æ–π—Å—Ç–≤|–º–æ–Ω—Ç–∞–∂|—É—Å—Ç–∞–Ω–æ–≤–∫))'
        }
        
        position = {
            'id': str(uuid.uuid4()),
            'row_number': line_num,
            'description': line
        }
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–æ–¥ –ì–≠–°–ù/–§–ï–†
        gesn_match = re.search(patterns['gesn_code'], line, re.IGNORECASE)
        if gesn_match:
            position['code'] = gesn_match.group(0)
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å—Ç–æ–∏–º–æ—Å—Ç—å
        cost_matches = re.findall(patterns['cost'], line)
        if cost_matches:
            try:
                position['total_cost'] = float(cost_matches[-1])  # –ë–µ—Ä–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é —Å—Ç–æ–∏–º–æ—Å—Ç—å
            except (ValueError, TypeError):
                position['total_cost'] = 0.0
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ
        quantity_match = re.search(patterns['quantity'], line)
        if quantity_match:
            try:
                position['quantity'] = float(quantity_match.group(1))
            except (ValueError, TypeError):
                position['quantity'] = 0.0
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –ø–æ–∑–∏—Ü–∏–∏
        position['type'] = self._determine_position_type(position, EstimateFormat.UNKNOWN)
        
        return position if position.get('code') or position.get('total_cost', 0) > 0 else None

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ —Å —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–π —Å–∏—Å—Ç–µ–º–æ–π
def parse_estimate_enhanced(file_path: str, **kwargs) -> Dict[str, Any]:
    """
    –£–ª—É—á—à–µ–Ω–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –ø–∞—Ä—Å–∏–Ω–≥–∞ —Å–º–µ—Ç—ã
    
    Args:
        file_path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É —Å–º–µ—Ç—ã
        **kwargs: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
        
    Returns:
        –°–ª–æ–≤–∞—Ä—å —Å –¥–∞–Ω–Ω—ã–º–∏ —Å–º–µ—Ç—ã
    """
    parser = EnhancedSmetaParser()
    
    if file_path.endswith(('.xlsx', '.xls')):
        return parser.parse_excel_estimate(file_path)
    elif file_path.endswith('.csv'):
        return parser.parse_csv_estimate(file_path)
    else:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        return parser.parse_text_estimate(content)
