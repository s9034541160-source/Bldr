#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –ø–µ—Ä–µ–Ω–æ—Å–∞ –º–æ–¥–µ–ª–µ–π —Å –¥–∏—Å–∫–∞ C:\\ –Ω–∞ –¥–∏—Å–∫ I:\\
–ù–∞—Ö–æ–¥–∏—Ç —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –º–æ–¥–µ–ª–∏ Hugging Face –∏ –ø–µ—Ä–µ–Ω–æ—Å–∏—Ç –∏—Ö –Ω–∞ –¥–∏—Å–∫ I:\\
"""

import os
import shutil
import sys
from pathlib import Path
import time
from typing import List, Dict, Tuple

def find_huggingface_cache_dirs() -> List[Path]:
    """–ù–∞—Ö–æ–¥–∏—Ç –≤—Å–µ –ø–∞–ø–∫–∏ –∫—ç—à–∞ Hugging Face –Ω–∞ –¥–∏—Å–∫–µ C:\\"""
    cache_dirs = []
    
    # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –ø—É—Ç–∏ –∫—ç—à–∞ Hugging Face
    possible_paths = [
        Path.home() / ".cache" / "huggingface",
        Path.home() / ".cache" / "transformers", 
        Path.home() / ".cache" / "torch",
        Path("C:/Users") / os.getenv("USERNAME", "user") / ".cache" / "huggingface",
        Path("C:/Users") / os.getenv("USERNAME", "user") / ".cache" / "transformers",
        Path("C:/Users") / os.getenv("USERNAME", "user") / ".cache" / "torch",
        Path("C:/") / ".cache" / "huggingface",
        Path("C:/") / ".cache" / "transformers",
    ]
    
    print("–ü–æ–∏—Å–∫ –ø–∞–ø–æ–∫ –∫—ç—à–∞ Hugging Face...")
    
    for path in possible_paths:
        if path.exists() and path.is_dir():
            cache_dirs.append(path)
            print(f"–ù–∞–π–¥–µ–Ω–∞ –ø–∞–ø–∫–∞: {path}")
    
    return cache_dirs

def find_model_directories(cache_dirs: List[Path]) -> List[Tuple[Path, str]]:
    """–ù–∞—Ö–æ–¥–∏—Ç –ø–∞–ø–∫–∏ —Å –º–æ–¥–µ–ª—è–º–∏ –≤ –∫—ç—à–µ"""
    model_dirs = []
    
    # –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è –ø–æ–∏—Å–∫–∞ –º–æ–¥–µ–ª–µ–π
    model_keywords = [
        "qwen", "layoutlm", "rugpt", "sentence-transformers", 
        "microsoft", "ai-forever", "transformers", "models"
    ]
    
    print("\nüîç –ü–æ–∏—Å–∫ –ø–∞–ø–æ–∫ —Å –º–æ–¥–µ–ª—è–º–∏...")
    
    for cache_dir in cache_dirs:
        try:
            for item in cache_dir.rglob("*"):
                if item.is_dir():
                    dir_name = item.name.lower()
                    for keyword in model_keywords:
                        if keyword in dir_name:
                            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä –ø–∞–ø–∫–∏ (–±–æ–ª—å—à–µ 100MB)
                            size_mb = get_directory_size_mb(item)
                            if size_mb > 100:  # –ë–æ–ª—å—à–µ 100MB
                                model_dirs.append((item, f"{size_mb:.1f}MB"))
                                print(f"‚úÖ –ù–∞–π–¥–µ–Ω–∞ –º–æ–¥–µ–ª—å: {item} ({size_mb:.1f}MB)")
                                break
        except PermissionError:
            print(f"‚ö†Ô∏è –ù–µ—Ç –¥–æ—Å—Ç—É–ø–∞ –∫ –ø–∞–ø–∫–µ: {cache_dir}")
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–∏ {cache_dir}: {e}")
    
    return model_dirs

def get_directory_size_mb(path: Path) -> float:
    """–ü–æ–ª—É—á–∞–µ—Ç —Ä–∞–∑–º–µ—Ä –ø–∞–ø–∫–∏ –≤ MB"""
    try:
        total_size = 0
        for file_path in path.rglob("*"):
            if file_path.is_file():
                total_size += file_path.stat().st_size
        return total_size / (1024 * 1024)  # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ MB
    except:
        return 0

def create_destination_dirs():
    """–°–æ–∑–¥–∞–µ—Ç –ø–∞–ø–∫–∏ –Ω–∞–∑–Ω–∞—á–µ–Ω–∏—è –Ω–∞ –¥–∏—Å–∫–µ I:\\"""
    dest_dirs = [
        Path("I:/huggingface_cache"),
        Path("I:/models_cache"),
        Path("I:/huggingface_cache/models"),
        Path("I:/huggingface_cache/datasets"),
        Path("I:/huggingface_cache/tokenizers"),
    ]
    
    print("\nüìÅ –°–æ–∑–¥–∞–Ω–∏–µ –ø–∞–ø–æ–∫ –Ω–∞–∑–Ω–∞—á–µ–Ω–∏—è –Ω–∞ –¥–∏—Å–∫–µ I:\\...")
    
    for dest_dir in dest_dirs:
        try:
            dest_dir.mkdir(parents=True, exist_ok=True)
            print(f"‚úÖ –°–æ–∑–¥–∞–Ω–∞ –ø–∞–ø–∫–∞: {dest_dir}")
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –ø–∞–ø–∫–∏ {dest_dir}: {e}")
            return False
    
    return True

def migrate_models(model_dirs: List[Tuple[Path, str]]) -> Dict[str, bool]:
    """–ü–µ—Ä–µ–Ω–æ—Å–∏—Ç –º–æ–¥–µ–ª–∏ –Ω–∞ –¥–∏—Å–∫ I:\\"""
    results = {}
    
    print(f"\nüöÄ –ù–∞—á–∏–Ω–∞–µ–º –ø–µ—Ä–µ–Ω–æ—Å {len(model_dirs)} –º–æ–¥–µ–ª–µ–π...")
    
    for i, (source_path, size_info) in enumerate(model_dirs, 1):
        print(f"\nüì¶ [{i}/{len(model_dirs)}] –ü–µ—Ä–µ–Ω–æ—Å: {source_path.name} ({size_info})")
        
        try:
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–∞–ø–∫—É –Ω–∞–∑–Ω–∞—á–µ–Ω–∏—è
            if "models" in str(source_path) or any(keyword in source_path.name.lower() 
                                                 for keyword in ["qwen", "layoutlm", "rugpt", "microsoft", "ai-forever"]):
                dest_path = Path("I:/huggingface_cache/models") / source_path.name
            elif "datasets" in str(source_path):
                dest_path = Path("I:/huggingface_cache/datasets") / source_path.name
            elif "tokenizers" in str(source_path):
                dest_path = Path("I:/huggingface_cache/tokenizers") / source_path.name
            else:
                dest_path = Path("I:/huggingface_cache") / source_path.name
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ —É–∂–µ –ø–∞–ø–∫–∞ –Ω–∞–∑–Ω–∞—á–µ–Ω–∏—è
            if dest_path.exists():
                print(f"‚ö†Ô∏è –ü–∞–ø–∫–∞ —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç: {dest_path}")
                results[str(source_path)] = True
                continue
            
            print(f"üìÇ –ò—Å—Ç–æ—á–Ω–∏–∫: {source_path}")
            print(f"üìÇ –ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ: {dest_path}")
            
            # –ü–µ—Ä–µ–Ω–æ—Å–∏–º –ø–∞–ø–∫—É
            start_time = time.time()
            shutil.copytree(source_path, dest_path)
            elapsed = time.time() - start_time
            
            print(f"‚úÖ –£—Å–ø–µ—à–Ω–æ –ø–µ—Ä–µ–Ω–µ—Å–µ–Ω–æ –∑–∞ {elapsed:.1f}—Å")
            results[str(source_path)] = True
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø–µ—Ä–µ–Ω–æ—Å–∞ {source_path}: {e}")
            results[str(source_path)] = False
    
    return results

def update_environment_variables():
    """–û–±–Ω–æ–≤–ª—è–µ—Ç –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –¥–∏—Å–∫–∞ I:\\"""
    print("\nüîß –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è...")
    
    env_vars = {
        "HF_HOME": "I:/huggingface_cache",
        "TRANSFORMERS_CACHE": "I:/huggingface_cache", 
        "HF_DATASETS_CACHE": "I:/huggingface_cache",
        "LLM_CACHE_DIR": "I:/models_cache"
    }
    
    try:
        import winreg
        
        # –û—Ç–∫—Ä—ã–≤–∞–µ–º —Ä–µ–µ—Å—Ç—Ä –¥–ª—è –∑–∞–ø–∏—Å–∏ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        with winreg.OpenKey(winreg.HKEY_CURRENT_USER, "Environment", 0, winreg.KEY_ALL_ACCESS) as key:
            for var_name, var_value in env_vars.items():
                winreg.SetValueEx(key, var_name, 0, winreg.REG_SZ, var_value)
                print(f"‚úÖ –£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è: {var_name}={var_value}")
        
        print("‚úÖ –ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è –æ–±–Ω–æ–≤–ª–µ–Ω—ã –≤ —Ä–µ–µ—Å—Ç—Ä–µ")
        print("üìù –ü–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç–µ —Ç–µ—Ä–º–∏–Ω–∞–ª –¥–ª—è –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è –∏–∑–º–µ–Ω–µ–Ω–∏–π")
        
    except Exception as e:
        print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –æ–±–Ω–æ–≤–∏—Ç—å –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è: {e}")
        print("üìù –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –≤—Ä—É—á–Ω—É—é:")
        for var_name, var_value in env_vars.items():
            print(f"   setx {var_name} \"{var_value}\"")

def cleanup_old_cache(model_dirs: List[Tuple[Path, str]], results: Dict[str, bool]):
    """–û—á–∏—â–∞–µ—Ç —Å—Ç–∞—Ä—ã–µ –ø–∞–ø–∫–∏ –∫—ç—à–∞ –ø–æ—Å–ª–µ —É—Å–ø–µ—à–Ω–æ–≥–æ –ø–µ—Ä–µ–Ω–æ—Å–∞"""
    print("\nüßπ –û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö –ø–∞–ø–æ–∫ –∫—ç—à–∞...")
    
    cleaned_count = 0
    for source_path, _ in model_dirs:
        if results.get(str(source_path), False):
            try:
                if source_path.exists():
                    shutil.rmtree(source_path)
                    print(f"‚úÖ –£–¥–∞–ª–µ–Ω–∞ —Å—Ç–∞—Ä–∞—è –ø–∞–ø–∫–∞: {source_path}")
                    cleaned_count += 1
            except Exception as e:
                print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å {source_path}: {e}")
    
    print(f"‚úÖ –û—á–∏—â–µ–Ω–æ {cleaned_count} —Å—Ç–∞—Ä—ã—Ö –ø–∞–ø–æ–∫")

def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    print("üöÄ –ú–ò–ì–†–ê–¶–ò–Ø –ú–û–î–ï–õ–ï–ô –ù–ê –î–ò–°–ö I:\\")
    print("=" * 50)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å –¥–∏—Å–∫–∞ I:\
    if not Path("I:/").exists():
        print("‚ùå –î–∏—Å–∫ I:\\ –Ω–µ –Ω–∞–π–¥–µ–Ω! –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –¥–∏—Å–∫ –ø–æ–¥–∫–ª—é—á–µ–Ω.")
        return
    
    # 1. –ù–∞—Ö–æ–¥–∏–º –ø–∞–ø–∫–∏ –∫—ç—à–∞
    cache_dirs = find_huggingface_cache_dirs()
    if not cache_dirs:
        print("‚ö†Ô∏è –ü–∞–ø–∫–∏ –∫—ç—à–∞ Hugging Face –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
        print("üí° –í–æ–∑–º–æ–∂–Ω–æ, –º–æ–¥–µ–ª–∏ –µ—â–µ –Ω–µ –∑–∞–≥—Ä—É–∂–∞–ª–∏—Å—å")
        return
    
    # 2. –ù–∞—Ö–æ–¥–∏–º –º–æ–¥–µ–ª–∏
    model_dirs = find_model_directories(cache_dirs)
    if not model_dirs:
        print("‚ö†Ô∏è –ú–æ–¥–µ–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ –∫—ç—à–µ")
        return
    
    print(f"\nüìä –ù–∞–π–¥–µ–Ω–æ {len(model_dirs)} –º–æ–¥–µ–ª–µ–π –¥–ª—è –ø–µ—Ä–µ–Ω–æ—Å–∞")
    
    # 3. –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫–∏ –Ω–∞–∑–Ω–∞—á–µ–Ω–∏—è
    if not create_destination_dirs():
        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –ø–∞–ø–∫–∏ –Ω–∞–∑–Ω–∞—á–µ–Ω–∏—è")
        return
    
    # 4. –ü–µ—Ä–µ–Ω–æ—Å–∏–º –º–æ–¥–µ–ª–∏
    results = migrate_models(model_dirs)
    
    # 5. –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    successful = sum(1 for success in results.values() if success)
    print(f"\nüìä –†–ï–ó–£–õ–¨–¢–ê–¢–´ –ü–ï–†–ï–ù–û–°–ê:")
    print(f"‚úÖ –£—Å–ø–µ—à–Ω–æ –ø–µ—Ä–µ–Ω–µ—Å–µ–Ω–æ: {successful}/{len(model_dirs)}")
    print(f"‚ùå –û—à–∏–±–æ–∫: {len(model_dirs) - successful}")
    
    # 6. –û–±–Ω–æ–≤–ª—è–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
    update_environment_variables()
    
    # 7. –û—á–∏—â–∞–µ–º —Å—Ç–∞—Ä—ã–µ –ø–∞–ø–∫–∏ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
    if successful > 0:
        response = input("\nüßπ –£–¥–∞–ª–∏—Ç—å —Å—Ç–∞—Ä—ã–µ –ø–∞–ø–∫–∏ –∫—ç—à–∞? (y/N): ")
        if response.lower() in ['y', 'yes', '–¥–∞']:
            cleanup_old_cache(model_dirs, results)
    
    print("\nüéâ –ú–ò–ì–†–ê–¶–ò–Ø –ó–ê–í–ï–†–®–ï–ù–ê!")
    print("üìù –ü–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç–µ —Ç–µ—Ä–º–∏–Ω–∞–ª –¥–ª—è –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è")

if __name__ == "__main__":
    main()
