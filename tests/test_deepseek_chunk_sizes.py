#!/usr/bin/env python3
"""
–¢–µ—Å—Ç —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ä–∞–∑–º–µ—Ä–æ–≤ —á–∞–Ω–∫–æ–≤ –¥–ª—è DeepSeek-Coder
"""

import os
import sys
import time
import logging

# –û—Ç–∫–ª—é—á–∞–µ–º –∫—ç—à Python
os.environ['PYTHONDONTWRITEBYTECODE'] = '1'
os.environ['PYTHONUNBUFFERED'] = '1'

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

def test_chunk_sizes():
    """–¢–µ—Å—Ç —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ä–∞–∑–º–µ—Ä–æ–≤ —á–∞–Ω–∫–æ–≤"""
    
    logger.info("=== –¢–ï–°–¢ –†–ê–ó–ú–ï–†–û–í –ß–ê–ù–ö–û–í ===")
    
    try:
        from hybrid_llm_ensemble import HybridLLMEnsemble, HybridLLMConfig
        
        config = HybridLLMConfig.from_env()
        ensemble = HybridLLMEnsemble(config)
        
        if not ensemble.qwen_model:
            logger.error("‚ùå DeepSeek-Coder –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω!")
            return False
        
        # –¢–µ—Å—Ç–æ–≤—ã–µ —Ä–∞–∑–º–µ—Ä—ã —á–∞–Ω–∫–æ–≤
        chunk_sizes = [512, 1024, 2048, 4096, 8192]
        
        for chunk_size in chunk_sizes:
            logger.info(f"üîç –¢–µ—Å—Ç–∏—Ä—É–µ–º —á–∞–Ω–∫ —Ä–∞–∑–º–µ—Ä–æ–º {chunk_size} —Å–∏–º–≤–æ–ª–æ–≤...")
            
            # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–π —Ç–µ–∫—Å—Ç –Ω—É–∂–Ω–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞
            test_text = "–°–ü 158.13330.2014 " * (chunk_size // 20)  # –ü—Ä–∏–º–µ—Ä–Ω–æ –Ω—É–∂–Ω—ã–π —Ä–∞–∑–º–µ—Ä
            test_text = test_text[:chunk_size]  # –û–±—Ä–µ–∑–∞–µ–º –¥–æ —Ç–æ—á–Ω–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞
            
            prompt = f"""–ó–ê–î–ê–ß–ê: –ò—Å–ø—Ä–∞–≤—å —Ç–æ–ª—å–∫–æ –æ—á–µ–≤–∏–¥–Ω—ã–µ –æ—à–∏–±–∫–∏.

–¢–ï–ö–°–¢: {test_text}

–ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ô:"""
            
            start_time = time.time()
            try:
                response = ensemble.qwen_model(
                    prompt,
                    max_tokens=chunk_size,
                    temperature=0.1,
                    stop=["–¢–ï–ö–°–¢:", "–ó–ê–î–ê–ß–ê:"]
                )
                
                elapsed = time.time() - start_time
                result = response['choices'][0]['text'].strip()
                
                logger.info(f"‚úÖ –ß–∞–Ω–∫ {chunk_size}: {elapsed:.2f}s - {len(result)} —Å–∏–º–≤–æ–ª–æ–≤")
                
                # –ï—Å–ª–∏ —á–∞–Ω–∫ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç—Å—è –¥–æ–ª—å—à–µ 10 —Å–µ–∫—É–Ω–¥, —Å—á–∏—Ç–∞–µ–º –µ–≥–æ –ø—Ä–æ–±–ª–µ–º–Ω—ã–º
                if elapsed > 10:
                    logger.warning(f"‚ö†Ô∏è –ß–∞–Ω–∫ {chunk_size} –º–µ–¥–ª–µ–Ω–Ω—ã–π: {elapsed:.2f}s")
                
            except Exception as e:
                logger.error(f"‚ùå –ß–∞–Ω–∫ {chunk_size} –û–®–ò–ë–ö–ê: {e}")
                return False
        
        return True
        
    except Exception as e:
        logger.error(f"‚ùå –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê: {e}")
        return False

def test_optimal_chunk_size():
    """–ü–æ–∏—Å–∫ –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞ —á–∞–Ω–∫–∞"""
    
    logger.info("=== –ü–û–ò–°–ö –û–ü–¢–ò–ú–ê–õ–¨–ù–û–ì–û –†–ê–ó–ú–ï–†–ê –ß–ê–ù–ö–ê ===")
    
    try:
        from hybrid_llm_ensemble import HybridLLMEnsemble, HybridLLMConfig
        
        config = HybridLLMConfig.from_env()
        ensemble = HybridLLMEnsemble(config)
        
        if not ensemble.qwen_model:
            logger.error("‚ùå DeepSeek-Coder –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω!")
            return False
        
        # –¢–µ—Å—Ç–∏—Ä—É–µ–º —Ä–∞–∑–º–µ—Ä—ã –æ—Ç 256 –¥–æ 2048 —Å —à–∞–≥–æ–º 256
        optimal_size = 1024  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é
        best_time = float('inf')
        
        for chunk_size in range(256, 2049, 256):
            logger.info(f"üîç –¢–µ—Å—Ç–∏—Ä—É–µ–º –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä {chunk_size}...")
            
            test_text = "–°–ü 158.13330.2014 " * (chunk_size // 20)
            test_text = test_text[:chunk_size]
            
            prompt = f"""–ó–ê–î–ê–ß–ê: –ò—Å–ø—Ä–∞–≤—å —Ç–æ–ª—å–∫–æ –æ—á–µ–≤–∏–¥–Ω—ã–µ –æ—à–∏–±–∫–∏.

–¢–ï–ö–°–¢: {test_text}

–ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ô:"""
            
            start_time = time.time()
            try:
                response = ensemble.qwen_model(
                    prompt,
                    max_tokens=chunk_size,
                    temperature=0.1,
                    stop=["–¢–ï–ö–°–¢:", "–ó–ê–î–ê–ß–ê:"]
                )
                
                elapsed = time.time() - start_time
                
                if elapsed < best_time and elapsed < 5:  # –ë—ã—Å—Ç—Ä–µ–µ 5 —Å–µ–∫—É–Ω–¥
                    best_time = elapsed
                    optimal_size = chunk_size
                
                logger.info(f"‚úÖ –†–∞–∑–º–µ—Ä {chunk_size}: {elapsed:.2f}s")
                
            except Exception as e:
                logger.error(f"‚ùå –†–∞–∑–º–µ—Ä {chunk_size} –û–®–ò–ë–ö–ê: {e}")
                continue
        
        logger.info(f"üéØ –û–ü–¢–ò–ú–ê–õ–¨–ù–´–ô –†–ê–ó–ú–ï–† –ß–ê–ù–ö–ê: {optimal_size} —Å–∏–º–≤–æ–ª–æ–≤ ({best_time:.2f}s)")
        return optimal_size
        
    except Exception as e:
        logger.error(f"‚ùå –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê: {e}")
        return 1024

if __name__ == "__main__":
    logger.info("üöÄ –ó–ê–ü–£–°–ö –¢–ï–°–¢–û–í –†–ê–ó–ú–ï–†–û–í –ß–ê–ù–ö–û–í")
    
    # –¢–µ—Å—Ç 1: –†–∞–∑–ª–∏—á–Ω—ã–µ —Ä–∞–∑–º–µ—Ä—ã
    success1 = test_chunk_sizes()
    
    if success1:
        # –¢–µ—Å—Ç 2: –ü–æ–∏—Å–∫ –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞
        optimal_size = test_optimal_chunk_size()
        logger.info(f"üéØ –†–ï–ö–û–ú–ï–ù–î–£–ï–ú–´–ô –†–ê–ó–ú–ï–† –ß–ê–ù–ö–ê: {optimal_size}")
    else:
        logger.error("‚ùå –¢–µ—Å—Ç—ã —Ä–∞–∑–º–µ—Ä–æ–≤ —á–∞–Ω–∫–æ–≤ –Ω–µ –ø—Ä–æ—à–ª–∏!")
    
    logger.info("üèÅ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –ó–ê–í–ï–†–®–ï–ù–û")
